#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Wed Jul  3 15:36:52 2024@author: magalipondsThis code runs through the following operations:    SCOPE: Plot histograms for larger sets, comparing OGGM modelled to Hugonnet data    Cell 1a: Load the Hugonnet data    Cell 1b: Load RGI dataset and reformat RGI-notation    Cell 2: Filter the Hugonnet data according to availability in the RGI       Cell 3a: Plot histogram from Hugonnet input data (# glaciers vs B)    Cell 3b: Plot histogram from Hugonnet input data (# glaciers vs B)    Cell 4a: Gdirs for the region (based on Hugonnet sample glacier dataset)    Cell 4b: Save gdirs from OGGM    Cell 4c: Load gdirs from OGGM (saved in 4b)    Cell 5: Run the MB model for the glaciers     Cell 6: Create a histogram with the MB data    Cell 7: Analyse glacier statistics      """# -*- coding: utf-8 -*-import oggm# from OGGM_data_processing import process_perturbation_dataimport oggmfrom oggm import utils, cfg, workflow, tasks, DEFAULT_BASE_URL, graphics, global_tasksfrom oggm.core import massbalance, flowlinefrom oggm.utils import floatyear_to_date, hydrodate_to_calendardatefrom oggm.sandbox import distribute_2dfrom oggm.sandbox.edu import run_constant_climate_with_biasimport geopandas as gpdimport matplotlib.pyplot as pltimport matplotlib.cm as cmimport matplotlib.colors as clrsimport xarray as xrimport osimport seaborn as snsimport salemfrom matplotlib.ticker import FuncFormatterimport pandas as pdimport numpy as npfrom matplotlib import animationfrom IPython.display import HTML, displayimport matplotlib.pyplot as pltimport cartopy.crs as ccrsimport cartopy.feature as cfeatureimport geopandas as gpdimport pandas as pdfrom scipy.optimize import curve_fitfrom tqdm import tqdmimport pickleimport sysimport textwrapfrom matplotlib.colors import LinearSegmentedColormap, TwoSlopeNormfunction_directory = "/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/src/03. Glacier simulations"sys.path.append(function_directory)colors = {    "W5E5": ["#000000"],  # "#000000"],  # Black    # Darker to lighter shades of purple    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],    # Darker to lighter shades of pink    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],    # Darker to lighter shades of orange    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],    "IPSL-CM6": ["#FFB000"]  # Dark purple to lighter shades}members = [1, 3, 4, 6, 1]members_averages = [1, 2, 3, 5]models = ["IPSL-CM6", "E3SM", "CESM2", "CNRM", "W5E5"]models_shortlist = ["IPSL-CM6", "E3SM", "CESM2", "CNRM"]timeframe = "monthly"# %% Cell 0: Initialize OGGM with the preferred model parameter set upfolder_path = '/Users/magaliponds/Documents/00. Programming'wd_path = f'{folder_path}/03. Modelled perturbation-glacier interactions - R13-15 A+5km2/'os.makedirs(wd_path, exist_ok=True)cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=False)# make a sum dirsum_dir = os.path.join(wd_path, 'summary')os.makedirs(sum_dir, exist_ok=True)# make a logging directorylog_dir = os.path.join(wd_path, "log")os.makedirs(log_dir, exist_ok=True)# Make a pkl directorypkls = os.path.join(wd_path, "pkls")os.makedirs(pkls, exist_ok=True)cfg.initialize(logging_level='WARNING')cfg.PARAMS['baseline_climate'] = "GSWP3-W5E5"cfg.PARAMS['use_multiprocessing'] = Falsecfg.PARAMS['store_model_geometry'] = Truey0_clim = 1985ye_clim = 2014# %% Cell 1a: Load Hugonnet data - 2000-2020 year average# Hugonnet data source: Harry via Teams# Hugonnet_path = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/04. Reference/01. Climate data/Hugonnet/aggregated_2000_2020/13_mb_glspec.dat'Hugonnet_path = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/04. Reference/01. Climate data/Hugonnet/aggregated_2000_2010/13_mb_glspec.dat'df_raw = pd.read_csv(Hugonnet_path)# Convert the pandas DataFrame to an Xarray Datasetds = xr.Dataset.from_dataframe(df_raw)# Load the data variables, as they are listed in the first rowvar_index = ds.coords['index'].valuesheader_str = var_index[1]  # Set the var_index as the header stringdata_rows_str = var_index[2:]  # Set the datarows# # print(header_str, data_rows_str)# # split data input in such a way that it is loaded as dataframe with columns headers and data in table belowheader = header_str.split()# # Transform the data type from string values to integers for the relevant columnsdata_rows = [row.split() for row in data_rows_str]def str_to_float(value):    return float(value)df = pd.DataFrame(data_rows, columns=header)for col in df.columns:    if col != 'RGI-ID':  # Exclude column 'B'        df[col] = df[col].apply(str_to_float)# # # create a dataset from the transformed data in order to select the required glaciersdf.rename(columns={'RGI-ID': 'rgi_id'})ds = xr.Dataset.from_dataframe(df)# # df.to_csv("/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/04. Reference/Hugonnet/aggregated_2000_2020/13_mb_glspec-edited.csv")# %% Cell 1b: Load RGI dataset and reformat RGI-notation# downloaded from GLIMSRGI_data = "/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/01. Input files/03. Shapefile/RGI/General Area/RGI2000-v7.0-C-13_central_asia/RGI2000-v7.0-C-13_central_asia.shp"rgis = gpd.read_file(RGI_data)# transform identifier to right formatdef transform_identifier(identifier):    num = int(identifier.split('-')[-1])    return f'RGI60-13.{str(num).zfill(5)}'# reformat the rgi_id column such that it is standard annotationrgis['rgi_id'] = rgis['rgi_id'].apply(transform_identifier)# %% Cell 2: Filter the Hugonnet data according to availability in the RGIhugo_filtered = ds.where(ds['RGI-ID'].isin(rgis['rgi_id']), drop=True)# %% Cell 2b Create master dataset containing all info from Hugonnet and RGI# reset the indices for both dataset so that they can be merged using xarrayhugo_ds = hugo_filtered.rename({'RGI-ID': 'rgi_id'})hugo_ds = hugo_ds.to_dataframe()hugo_ds = hugo_ds.set_index('rgi_id').to_xarray()rgis_copy = rgisrgis_copy = rgis_copy.set_index('rgi_id')rgis_ds = rgis_copy.to_xarray()rgis_ds['rgi_id_rgis'] = rgis_ds['rgi_id']hugo_ds['rgi_id_hugo'] = hugo_ds['rgi_id']# hugo_ds = hugo_ds.reset_index('index', drop=True)master_ds = xr.merge([rgis_ds, hugo_ds], join='inner')master_ds['area_dif'] = master_ds['Area']-master_ds['area_km2']plt.scatter(np.arange(0, len(master_ds.area_dif), 1), master_ds.area_dif)plt.ylabel("$\Delta$ Area (Hugonnet - RGI)")plt.xlabel("Glacier index #")master_df = master_ds.to_dataframe()master_df['Volume Change'] = master_df['Area'] * master_df['B']# master_df.to_csv(f"{wd_path}/region13_RGI_master_rgi_hugo_2000_2010.csv")master_df.to_csv(f"{wd_path}/region13_RGI_master_rgi_hugo.csv")# %% Cell 3a: Plot histogram from Hugonnet input data (# glaciers A>10km2 vs B)""" Find glaciers with most postive MB and other conditions"""# create a copy of hugo_ds, where the non RGI glaciers have been filtered outhugo_ds_filtered = master_dsconditions = {    # 'B': ds_filtered['B'] >= 0,    # 'errB': ds_filtered['errB'] < 0.2,    # 'area_km2': hugo_ds_filtered['area_km2'] > 10 #filter for rgis area is larger than 10 km2    # filter for Hugonnet area is larger than 10 km2    'Area': hugo_ds_filtered['Area'] > 10}for var, condition in conditions.items():    hugo_ds_filtered = hugo_ds_filtered.where(condition, drop=True)# create a pandas dataframe of the filtered glaciers in order to sort them on Areahugo_df_filtered = hugo_ds_filtered.to_dataframe().reset_index()hugo_df_filtered = hugo_df_filtered.sort_values(by='B', ascending=False)# df_filtered_subset=df_filtered[1:11]plt.figure(figsize=(10, 5))n, bins, patches = plt.hist(hugo_df_filtered['B'], bins=np.linspace(hugo_df_filtered['B'].min(), hugo_df_filtered['B'].max(), int(len(hugo_df_filtered['B'])/7)), align='left', rwidth=0.8, color='green')# plt.xlim((0,1.25))plt.ylabel("# of glaciers [-]")plt.xlabel("B")# Color the binsfor patch, bin_edge in zip(patches, bins):    if bin_edge < 0:        patch.set_facecolor('red')    else:        patch.set_facecolor('green')plt.xlim((-2, 2))plt.ylabel("# of glaciers [-]")plt.xlabel("B (m w.e.)")def gaussian(x, mu, sigma, A):    return A * np.exp(-(x - mu)**2 / (2 * sigma**2))bin_centers = (bins[:-1] + bins[1:]) / 2# Fit the Gaussian curve to the histogram dataparams_hugo, covariance_hugo = curve_fit(gaussian, bin_centers, n, p0=[np.mean(    hugo_df_filtered['B']), np.std(hugo_df_filtered['B']), np.max(n)])x = np.linspace(hugo_df_filtered['B'].min(), hugo_df_filtered['B'].max(), 100)plt.plot(x, gaussian(x, *params_hugo), color='black',         label='Fitted Gaussian Hugonnet')# plt.plot(x, gaussian(x, *params), color='grey', label='Fitted Gaussian OGGM')# plt.title('Hugonnet derived B')total_glaciers = len(hugo_df_filtered['B'].values)plt.annotate(f"Total number of glaciers: {total_glaciers}", xy=(    0.05, 0.95), xycoords='axes fraction', fontsize=12, verticalalignment='top')plt.annotate(f"Std: {round(np.std(hugo_df_filtered['B']),2)}", xy=(    0.05, 0.9), xycoords='axes fraction', fontsize=12, verticalalignment='top')plt.legend()# (f"{wd_path}/region13_RGI_master_rgi_hugo_filtered_area.csv")# hugo_ds_filtered.to_csv(f"{wd_path}/region13_RGI_master_rgi_hugo_filtered_area_2000_2010.csv")hugo_ds_filtered.to_csv(    f"{wd_path}/region13_RGI_master_rgi_hugo_filtered_area.csv")