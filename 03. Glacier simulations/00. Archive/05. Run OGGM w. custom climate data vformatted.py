""" This script runs the OGGM step by step guide to a preprocessed directory"""#%% Cell 1: Load the required directoriesimport oggmfrom oggm import cfg, utils, workflow, tasks, DEFAULT_BASE_URLimport geopandas as gpdimport numpy as npimport osfrom oggm.shop import rgitopofrom oggm import GlacierDirectoryfrom oggm.core import massbalance, flowline# Libsimport xarray as xrimport matplotlib.pyplot as pltimport matplotlib.cm as cmfrom oggm.shop import cru, w5e5from oggm.tasks import process_w5e5_dataimport matplotlib.pyplot as pltfrom oggm import graphicsimport pandas as pdimport loggingimport shutilimport argparseimport timeimport loggingimport json#%% Cell 1: Set climate data parameters     timeframe="monthly"model="CNRM"member = 0  #%% Cell 2: Set up the model with your own climate datacfg.initialize(logging_level='WARNING')cfg.PARAMS['baseline_climate']=''# Use W5E5 datafolder_path_local='/Users/magaliponds/Documents/00. Programming/'folder_path='/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/05. OGGM Working Directories'wd_path=f'{folder_path}/05. OGGM model baseline/{model}'wd_path_local=f'{folder_path_local}/01. OGGM model baseline'wd_path_large=f'{folder_path_local}/01. OGGM model baseline regional'y0=1980ye=2019period = slice(f'{y0}-01-01', f'{ye}-12-31')# Local working directory (where OGGM will write its output)cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=False)# cfg.PATHS['working_dir'] = utils.mkdir(wd_path_local, reset=True)base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.nc"# cfg.PATHS['climate_file'] = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/01. Input files/W5E5/format_datafile_histalp_merged_hef.nc'# cfg.PATHS['climate_file'] = '/path/to/your/climate_data.nc'ds = xr.open_dataset(f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.nc")#%% Cell 3: Download the RGI inventory and set up the glacier directories# Specify the RGI region you are interested in, for example, region 13 (Central Asia)rgi_ids = ["RGI60-13.40102", # Area >10km2    "RGI60-13.39195", # Area >10km2    "RGI60-13.36881", # Area >10km2    "RGI60-13.38969", # Area >10km2    "RGI60-13.37184", # Area >10km2    "RGI60-13.00967", # Area <10km2    "RGI60-13.40982", # Area <10km2    "RGI60-13.41891", # WGMS observation    "RGI60-13.23659", # WGMS observation] rgi_reg = '13'  # this must fit to example glacier(s), if starting from level 0sample_id='sample_glaciers'# Initialize glacier directories# We use a recent gdir setting, calibated on a glacier per glacier basisbase_url = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/')#initialize glacier directories from scratch, You have to explicitly indicate the url from where you want to start fromgdirs = workflow.init_glacier_directories(rgi_ids, from_prepro_level=3, prepro_base_url=base_url)# Go - re-open the pre-processed glacier directories from what's there, but with the list of glaviers# gdirs = workflow.init_glacier_directories(rgi_ids)sum_dir=os.path.join(wd_path, 'summary')os.makedirs(sum_dir, exist_ok=True)#%% Cell 3b: Zipping and reopening glacier directories#If deserable store your gdirs to tar:   # workflow.execute_entity_task(utils.gdir_to_tar, gdirs, delete=False);#then tar the bundles# utils.base_dir_to_tar(WORKING_DIR, delete=True)#%% Cell 4a: Glacier statsopath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))utils.compile_glacier_statistics(gdirs, path=opath_g)opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))utils.compile_climate_statistics(gdirs, path=opath_c)opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_b)#%% Cell 4b: Plot fixed geometry mass balance & Climate statisticscmap=cm.get_cmap('bone')colors=[cmap(i / 9) for i in range(10)]glacier_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_g))climate_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_c))massbalance_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_b).reset_index().rename(columns={'index':'year'}))for (i,rgi_id) in enumerate(rgi_ids):    plt.plot(massbalance_stats.year[79:]+1901, massbalance_stats[f'{rgi_id}'][79:], color=colors[i])       #print the years of climate info available    # y0=gdirs[i].get_climate_info()['baseline_yr_0']    # ye=gdirs[i].get_climate_info()['baseline_yr_1']+1    # print(y0, ye)#%% Cell 5: Process custom climate data def process_custom_climate_data(gdir):    print(gdir.rgi_id)    # Assuming you have a NetCDF with 'temp' and 'prcp' variables    climate_file = cfg.PATHS.get('climate_file', None)    if climate_file is None:        raise ValueError("The path to the climate file is not specified in cfg.PATHS['climate_file']")    try:        with utils.ncDataset(climate_file) as nc:            time = nc.variables['time'][:]            temp = nc.variables['temp'][:]            prcp = nc.variables['prcp'][:]            heights = nc.variables['hgt'][:]                    mean_height = np.nanmean(heights)                ref_pix_lon = gdir.cenlon #take center longitude for reference        ref_pix_lat = gdir.cenlon  #take center latitude for reference        ref_pix_hgt = mean_height        # ref_pix_hgt = heights[lat_idx]        output_dir = os.path.dirname(gdir.get_filepath('climate_historical'))        if not os.path.exists(output_dir):            os.makedirs(output_dir, exist_ok=True)        # Process and write to glacier directory        gdir.write_monthly_climate_file(time, temp, prcp, ref_pix_hgt, ref_pix_lon, ref_pix_lat, source='gswp3-w5e5')        print(f"Climate data processed and written for glacier directory {gdir.dir}")    except PermissionError as e:        raise PermissionError(f"Permission denied: {e}")    except Exception as e:        raise RuntimeError(f"An error occurred while processing the climate data: {e}")# # Process climate data for each gdirworkflow.execute_entity_task(tasks.process_custom_climate_data, gdirs, output_filesuffix=f'_{model}_processed_output_sample_glaciers')# #%% Cell 5b: Test the processed climate dataset# # TO DO: Remake for other modelsds2=xr.open_dataset("/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/05. OGGM Working Directories/05. OGGM model baseline/{}/per_glacier/RGI60-13/RGI60-13.00/RGI60-13.00967/climate_historical_{}_processed_output_sample_glaciers.nc".format(model))#%% Cell 6: Run the model simulation before dynamic calibration# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Example parameters for run_from_climate_datays = 1985  # Start yearye = 2014  # End yearstore_monthly_step = True# climate_filename = f'{model}_climate_output'climate_filename=f'_{model}_processed_output_sample_glaciers' #set ice dynamics model to be updated monthly for monthly output and monthly processesworkflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output_sample_glaciers'.format(model),                             output_filesuffix='',                             mb_elev_feedback='annual'                             )#and compile the outputopath_out = os.path.join(sum_dir, '{}_historical_run_output_sample_glaciers.nc'.format(model))#input filesuffix here is the output file suffix from the run from custom climate data functionutils.compile_run_output(gdirs, path=opath_out, input_filesuffix='') #%%  Cell 6a: Plot MB comparison before dynamic calibrationcfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(3,3, figsize=(20, 12), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)     # First check the parameters used for running the flmod model per flowline    for flmod in mbmod.flowline_mb_models:        print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')            fls = gdir.read_pickle('model_flowlines') #model_flowlines_dyn_melt_f_calib.pkl    B = mbmod.get_specific_mb(fls=fls, year=years)    mb['B'] = B        # Load & plot Hugonnet data for 2000-2010    mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]    mean_mb_2010_2020 = mb_2010_2020['B'].mean()    sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000       # Load & plot Hugonnet data for 2000-2010    _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]    axes_mb[i].fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='C0')    axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2010')        # Plot (mean) modelled data     axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')    # axes_mb[i].plot([2010, 2020], [mean_mb_2020, mean_mb_2020], color='C1', linestyle='dashed', label='OGGM modelled mean 2010-2020')    axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs    axes_mb[i].set_title(gdir.rgi_id, fontsize=20)    axes_mb[i].annotate(panels[i],xy=(0.98, 0.98), xycoords='axes fraction',                                    fontsize=24, weight='medium', ha='right', va='top')#,                                    #bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))    # axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        if i % 3 == 0:  # Only set ylabel on the left column        axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=20)    axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=3)plt.show()#%% Cell 6b: Open model diagnostics file before dynamic spinupds_diag = xr.open_dataset(opath_out)#%% Cell 7: conduct dynamic spinup if wantedye=2020dynamic_spinup = "area/dmdtda"err_dmdtda_scaling_factor=0.2dynamic_spinup_start_year=1979if y0 > dynamic_spinup_start_year:    dynamic_spinup_start_year = y0minimise_for = dynamic_spinup.split('/')[0]### CHECK IF IT CREATES A NEW FILE IN GLACIER DIRECTORYmelt_f_max = cfg.PARAMS['melt_f_max']workflow.execute_entity_task(    tasks.run_dynamic_melt_f_calibration, gdirs,    err_dmdtda_scaling_factor=err_dmdtda_scaling_factor,    ys=dynamic_spinup_start_year, ye=ye, #ye must be 2020 to match Hugonnet    melt_f_max=melt_f_max,    kwargs_run_function={'minimise_for': minimise_for},    ignore_errors=True,    kwargs_fallback_function={'minimise_for': minimise_for},    output_filesuffix='_{}_spinup_historical'.format(model))# Now compile the outputopath = os.path.join(sum_dir, '{}_spinup_historical_run_output.nc'.format(model))utils.compile_run_output(gdirs, path=opath,                         input_filesuffix='_{}_spinup_historical'.format(model))# Glacier statistics we recompute here for error analysisopath = os.path.join(sum_dir, '{}_spinup_glacier_statistics_sample_glaciers.csv'.format(model))utils.compile_glacier_statistics(gdirs, path=opath)#%% Cell 8: Recompile glacier statistics and extended files#save a new flowline file - is this really needed?# workflow.execute_entity_task(tasks.init_present_time_glacier, gdirs, filesuffix='_after_spinup')pf = os.path.join(sum_dir, '{}_spinup_historical_run_output.nc'.format(model))# We have copied the files abovemf = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))sf = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))opath = os.path.join(sum_dir, '{}_spinup_historical_run_output_extended_sample_glaciers.nc'.format(model))#extend past run files for the past run file, creating an extended output fileutils.extend_past_climate_run(past_run_file=pf,                              fixed_geometry_mb_file=mf,                              glacier_statistics_file=sf,                              path=opath)#%% Cell 8a: Open historical run output]# Why no valid volume file?? opath = os.path.join(sum_dir, '{}_spinup_historical_run_output_extended_sample_glaciers.nc'.format(model))ds_diag_ext = xr.open_dataset(opath)ds_diag_ext.volume_m3.plot(); plt.title('Volume evolution');plt.show()#%% Cell 9: Create a functio to add new files to basenamesdef add_to_basenames(basename, filename, docstr=''):    """Add an entry to the list of BASENAMES.    BASENAMES are access keys to files available at the gdir level.    Parameters    ----------    basename : str        the key (e.g. 'dem', 'model_flowlines')    filename : str        the associated filename (e.g. 'dem.tif', 'model_flowlines.pkl')    docstr : str        the associated docstring (for documentation)    """    global BASENAMES    if '.' not in filename:        raise ValueError('The filename needs a proper file suffix!')    cfg.BASENAMES[basename] = (filename, docstr)#%%cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')   #%% Cell 10:  Convert the directories to tar fileslevel_base_dir = os.path.join(wd_path, 'output tars')workflow.execute_entity_task(utils.gdir_to_tar, gdirs, delete=False,                                     base_dir=level_base_dir)utils.base_dir_to_tar(level_base_dir)#%% Cell 11: Analyze the output - glacier domainprint(gdirs[0])for gdir in gdirs:    gfig, ax = plt.subplots()    graphics.plot_domain(gdir, ax=ax)  # Using a different method to plot    ax.set_title(gdir.rgi_id)    plt.show()    #%% Cell11b: Plot flowlines# for (i,gdir) in enumerate(gdirs):#     gfig, axs = plt.subplots()#     fls = gdir.read_pickle('model_flowlines')#     graphics.plot_modeloutput_section(fls, ax=axs)    # cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')fig, axs = plt.subplots(3, 3, figsize=(15, 10))for i, gdir in enumerate(gdirs):    # Determine the position of the subplot (i.e., row and column)    row = i // 3    col = i % 3        # Get the specific axis for the subplot    ax = axs[row, col]        # Read the pickle file and plot    fls = gdir.read_pickle('model_flowlines')    fls2 = gdir.read_pickle('model_flowlines_dyn_melt_f_calib')    graphics.plot_modeloutput_section(fls, ax=ax)    # ax.set_title(gdir.rgi_id)# Adjust layout to prevent overlapping# plt.tight_layout()# Show the combined plotplt.show()    #%%  Cell 12: Plot MB comparisoncfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(3,3, figsize=(20, 12), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)     # First check the parameters used for running the flmod model per flowline    for flmod in mbmod.flowline_mb_models:        print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl    B = mbmod.get_specific_mb(fls=fls, year=years)    mb['B'] = B        # Load & plot Hugonnet data for 2000-2010    mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]    mean_mb_2010_2020 = mb_2010_2020['B'].mean()    sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000       # Load & plot Hugonnet data for 2000-2010    _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]    axes_mb[i].fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='C0')    axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2010')        # Plot (mean) modelled data     axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')    # axes_mb[i].plot([2010, 2020], [mean_mb_2020, mean_mb_2020], color='C1', linestyle='dashed', label='OGGM modelled mean 2010-2020')    axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs    axes_mb[i].set_title(gdir.rgi_id, fontsize=20)    axes_mb[i].annotate(panels[i],xy=(0.98, 0.98), xycoords='axes fraction',                                    fontsize=24, weight='medium', ha='right', va='top')#,                                    #bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))    # axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        if i % 3 == 0:  # Only set ylabel on the left column        axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)    axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=3)plt.show()#%%  Cell 12a: Plot MB comparison - zoom in to 2 glaciers with changes before and after dynamic spinupcfg.PARAMS['store_model_geometry']=Truembdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(1,2, figsize=(10, 3), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingchanged_ids = ['RGI60-13.00967', 'RGI60-13.40982']changed_gdirs = [gdir for gdir in gdirs if gdir.rgi_id in changed_ids]for (i, gdir) in enumerate(changed_gdirs):    # for j, model_type in enumerate(['model_flowlines', 'model_flowlines_dyn_melt_f_calib']):        mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         fls = gdir.read_pickle('model_flowlines')         B = mbmod.get_specific_mb(fls=fls, year=years)        mb['B'] = B                # Load & plot Hugonnet data for 2000-2010        mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]        mean_mb_2010_2020 = mb_2010_2020['B'].mean()        sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000                # Load & plot Hugonnet data for 2000-2020        _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]        axes_mb[i].fill_between([2000, 2020], [_mb - _err, _mb - _err], [_mb + _err, _mb + _err], alpha=0.5, color='C0')        axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2020')        # Plot (mean) modelled data        axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')        axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs        axes_mb[i].set_title(f"{gdir.rgi_id} ", fontsize=20)        if (i) % 2 == 0:  # Only set ylabel on the left column            axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)        axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.1, -0.3), ncols=3)plt.show()#%%  Cell 12b: PlotFlowlines in 9x9 subplotcfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(2010, 2015) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_fls, axes_fls = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_fls = axes_fls.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):    for j in years:                mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         # First check the parameters used for running the flmod model per flowline                    fls = gdir.read_pickle('model_flowlines')         heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=j)        # units kg ice per second to mm w.e. per year:        mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']                 # Plot        axes_fls[i].plot(mb, heights, '-', label=j);                            if i==3:        axes_fls[i].set_ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=10)plt.show()#%% Cell 13: Run model for glacier statistics# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output_sample_glaciers'.format(model),                             output_filesuffix='_{}_output_run_after_spinup_sample_glaciers'.format(model),                             mb_elev_feedback='annual'                             )#%% cell 13a: Plot volume evolution of the glaciers# add_to_basenames('model_diagnostics_W5E5_spinup_historical.nc', #basename#                   'model_diagnostics.nc') #filename) #docstr=''                 fig_vol, axes_vol = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_vol = axes_vol.flatten() for (i,gdir) in enumerate(gdirs):    ds_diag = xr.open_dataset(gdir.get_filepath('model_diagnostics'))    axes_vol[i].plot(ds_diag.calendar_year,ds_diag.volume_m3); axes_vol[i].set_title(f'{gdir.rgi_id}');    if i==3:        axes_vol[i].set_ylabel('Volume [m$^3$]')