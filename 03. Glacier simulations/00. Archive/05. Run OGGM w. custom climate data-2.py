""" This script runs the OGGM step by step guide to a preprocessed directory"""#%% Cell 1: Load the required directoriesimport oggmfrom oggm import cfg, utils, workflow, tasks, DEFAULT_BASE_URLimport geopandas as gpdimport numpy as npimport osfrom oggm.shop import rgitopofrom oggm import GlacierDirectoryfrom oggm.core import massbalance, flowline# Libsimport xarray as xrimport matplotlib.pyplot as pltimport matplotlib.cm as cmfrom oggm.shop import cru, w5e5from oggm.tasks import process_w5e5_dataimport matplotlib.pyplot as pltfrom oggm import graphicsimport pandas as pdimport loggingimport shutilimport argparseimport timeimport loggingimport json#%% Cell 1: Initiate OGGM using own climate datadef initiate_OGGM(timeframe, model, member, reset, wd_path):    cfg.initialize(logging_level='WARNING')    cfg.PARAMS['baseline_climate']=''            # Open working directory (where OGGM will write its output)    if model=="W5E5":        cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=reset)    else:        cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=False)        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"    cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.degC.nc"        return    # ds = xr.open_dataset(f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.nc")#%% Cell 2: Create a function to compile glacier stats for baseline climatedef compile_statistics(sample_id, sum_dir):    sum_dir=os.path.join(wd_path, 'summary')    os.makedirs(sum_dir, exist_ok=True)        opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    utils.compile_glacier_statistics(gdirs, path=opath_g)    opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))    utils.compile_climate_statistics(gdirs, path=opath_c)    opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))    utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_b)        return#%% Cell 2b: Function to plot statisticsdef plot_glacier_stats(sample_id, sum_dir):    opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))    opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))        glacier_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_g))    climate_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_c))    massbalance_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_b).reset_index().rename(columns={'index':'year'}))    for (i,rgi_id) in enumerate(rgi_ids):        plot = plt.plot(massbalance_stats.year[79:]+1901, massbalance_stats[f'{rgi_id}'][79:], color=colors[i])               #print the years of climate info available        # y0=gdirs[i].get_climate_info()['baseline_yr_0']        # ye=gdirs[i].get_climate_info()['baseline_yr_1']+1        # print(y0, ye)    return plot#%% Cell 3: Process custom climate data function# def process_custom_climate_data(gdir):   #     print('')#     print(gdir.rgi_id)    #     print('using climate file: ', cfg.PATHS['climate_file'])#     print('')#     # Assuming you have a NetCDF with 'temp' and 'prcp' variables    #     climate_file = cfg.PATHS.get('climate_file', None)#     if climate_file is None:#         raise ValueError("The path to the climate file is not specified in cfg.PATHS['climate_file']")#     try:#         with utils.ncDataset(climate_file) as nc:#             time = nc.variables['time'][:]#             temp = nc.variables['temp'][:]#             prcp = nc.variables['prcp'][:]#             heights = nc.variables['hgt'][:]#         mean_height = np.nanmean(heights)#         ref_pix_lon = gdir.cenlon #take center longitude for reference#         ref_pix_lat = gdir.cenlon  #take center latitude for reference#         ref_pix_hgt = mean_height#         # ref_pix_hgt = heights[lat_idx]#         output_dir = os.path.dirname(gdir.get_filepath('climate_historical_{}'.format(sample_id)))#         if not os.path.exists(output_dir):#             os.makedirs(output_dir, exist_ok=True)#         # Process and write to glacier directory#         gdir.write_monthly_climate_file(time, temp, prcp, ref_pix_hgt, ref_pix_lon, ref_pix_lat, source='gswp3-w5e5')#         print(f"Climate data processed and written for glacier directory {gdir.dir}")#     except PermissionError as e:#         raise PermissionError(f"Permission denied: {e}")#     except Exception as e:#         raise RuntimeError(f"An error occurred while processing the climate data: {e}")#%% Cell 9: Create a functio to add new files to basenamesdef add_to_basenames(basename, filename, docstr=''):    """Add an entry to the list of BASENAMES.    BASENAMES are access keys to files available at the gdir level.    Parameters    ----------    basename : str        the key (e.g. 'dem', 'model_flowlines')    filename : str        the associated filename (e.g. 'dem.tif', 'model_flowlines.pkl')    docstr : str        the associated docstring (for documentation)    """    global BASENAMES    if '.' not in filename:        raise ValueError('The filename needs a proper file suffix!')    cfg.BASENAMES[basename] = (filename, docstr)# cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')   #%% Cell 7: conduct dynamic spinup def run_dynamic_spinup(sum_dir, gdirs, sample_id, y0, ye):            dynamic_spinup = "area/dmdtda"    err_dmdtda_scaling_factor=0.2    # dynamic_spinup_start_year=y0        # if y0 > dynamic_spinup_start_year:    #     dynamic_spinup_start_year = y0        minimise_for = dynamic_spinup.split('/')[0]    ### CHECK IF IT CREATES A NEW FILE IN GLACIER DIRECTORY    melt_f_max = cfg.PARAMS['melt_f_max']    workflow.execute_entity_task(        tasks.run_dynamic_melt_f_calibration, gdirs,        err_dmdtda_scaling_factor=err_dmdtda_scaling_factor,        ys=y0, ye=ye, #ye must be 2020 to match Hugonnet        melt_f_max=melt_f_max,        kwargs_run_function={'minimise_for': minimise_for},        ignore_errors=True,        kwargs_fallback_function={'minimise_for': minimise_for},        output_filesuffix='_spinup_historical_{}'.format(sample_id))    # Now compile the output    opath = os.path.join(sum_dir,'spinup_historical_run_output_{}.nc'.format(sample_id))    utils.compile_run_output(gdirs, path=opath,                             input_filesuffix='_spinup_historical_{}'.format(sample_id))        # Glacier statistics we recompute here for error analysis    opath = os.path.join(sum_dir, 'spinup_glacier_statistics_{}.csv'.format(sample_id))    utils.compile_glacier_statistics(gdirs, path=opath)    return#%% Cell 8: Recompile glacier statistics and extended files# def recompile_extend_glacier_stats(sample_id, gdirs):#     #save a new flowline file - is this really needed?#     workflow.execute_entity_task(tasks.init_present_time_glacier, gdirs, filesuffix='_after_spinup')    #     pf = os.path.join(sum_dir, 'spinup_historical_run_output_W5E5.000.nc') #copy the dynamix spinup output #     # We have copied the files above#     mf = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))#     opath = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(rgi_reg))#     utils.compile_glacier_statistics(gdirs, path=opath)    #     sf = os.path.join(sum_dir, 'spinup_glacier_statistics_sample_glaciers_{}.csv'.format(sample_id))#     opath = os.path.join(sum_dir, 'spinup_historical_extended_run_output_{}.nc'.format(sample_id))    #     #extend past run files for the past run file, creating an extended output file#     utils.extend_past_climate_run(past_run_file=pf,#                                   fixed_geometry_mb_file=mf,#                                   glacier_statistics_file=sf,#                                   path=opath#                                   )#     return#%% Cell 10: Provide modelling parameters for OGGM# Use W5E5 data# folder_path='/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/05. OGGM Working Directories'folder_path='/Users/magaliponds/Documents/00. Programming'wd_path=f'{folder_path}/06. Modelled perturbation-glacier interactions/'y0_clim=1985ye_clim=2014y0_spinup=1980ye_spinup=2020cmap=cm.get_cmap('bone')colors=[cmap(i / 9) for i in range(10)]# Specify the RGI region you are interested in, for example, region 13 (Central Asia)rgi_reg = '13'  # this must fit to example glacier(s), if starting from level 0rgi_ids = ["RGI60-13.40102", # Area >10km2    "RGI60-13.39195", # Area >10km2    "RGI60-13.36881", # Area >10km2    "RGI60-13.38969", # Area >10km2    "RGI60-13.37184", # Area >10km2    "RGI60-13.00967", # Area <10km2    "RGI60-13.40982", # Area <10km2    "RGI60-13.41891", # WGMS observation    "RGI60-13.23659", # WGMS observation] base_url = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/')prepro_level=3sum_dir=os.path.join(wd_path, 'summary')#Provide output names:#%% Cell 11: Run OGGMmembers=[1,3,4,6,1]models = "W5E5","E3SM","CESM2","CNRM","IPSL-CM6"timeframe="monthly"download_gdirs=Falsereset=False            for m, model in enumerate(models):    for i in range(members[m]):        #Create a sample-id tag to list model restuls        sample_id= f"{model}.00{i}" #provide label for all run output                #initiate the model with custom climate data (model-member combination)        initiate_OGGM(timeframe, model, i, reset, wd_path)                 #Dowload or reopen the gdirs        if model=="W5E5":            if download_gdirs==True:                gdirs = workflow.init_glacier_directories(rgi_ids, from_prepro_level=prepro_level, prepro_base_url=base_url)            else:                gdirs = workflow.init_glacier_directories(rgi_ids)                    # Process the climate data        workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs, output_filesuffix=f'_{sample_id}') #process climate data for all gdirs                compile_statistics(sample_id, sum_dir) #compile         if model=="W5E5":  #run the model with the baseline            run_dynamic_spinup(sum_dir, gdirs, sample_id, y0_spinup, ye_spinup) #run dynamic spinup only for the baseline climate                    # We want to use these flowline files for the AAR (see later)        cfg.PARAMS['store_fl_diagnostics'] = True        # Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)        workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                                     ys=y0_clim, ye=ye_clim,                                      init_model_yr=y0_clim,                                     climate_filename='climate_historical',                                     climate_input_filesuffix='_{}'.format(sample_id),                                     output_filesuffix='_{}_output_climate_run'.format(sample_id),                                     mb_elev_feedback='monthly',                                     store_monthly_step=True                                     )                # Compile the run output        spinup_input_filesuffix = f'_spinup_historical_W5E5.000'        opath = os.path.join(sum_dir, f'climate_run_{sample_id}.nc')        utils.compile_run_output(gdirs, path=opath, input_filesuffix=spinup_input_filesuffix)        # Recompute glacier statistics        statistics_path = os.path.join(sum_dir, f'climate_run_glacier_statistics_{sample_id}.csv')        utils.compile_glacier_statistics(gdirs, path=statistics_path)                            #%% Cell 8a: Plot historical run output extended for all modelsmembers=[1,3,4,6,1]models = "W5E5","E3SM","CESM2","CNRM","IPSL-CM6"for r, rgi_id in enumerate(rgi_ids):    plt.figure()    for m, model in enumerate(models):        for i in range(members[m]):            #Create a sample-id tag to list model restuls            sample_id= f"{model}.00{i}" #p            # Why no valid volume file??             opath = os.path.join(sum_dir, 'climate_run_{}.nc'.format(sample_id))            ds_diag_ext = xr.open_dataset(opath).sel(rgi_id=rgi_id)                            # print(ds_diag_ext.data_vars)            ds_diag_ext.volume.plot(label=sample_id)    plt.legend(loc='upper left', ncols=2)                        # plt.title(f'Volume evolution {sample_id}');            # plt.xticks(rotation=90)            # # plt.show()#%% Plot temperature and precipitationcolors = {    "W5E5": ["#000000"],  # Black    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],  # Darker to lighter shades of purple    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],  # Darker to lighter shades of pink    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],  # Darker to lighter shades of orange    "IPSL-CM6": ["#FFB000"]  # Dark purple to lighter shades}members=[3,4,6,1,1]models = ["E3SM","CESM2","CNRM","IPSL-CM6","W5E5"]markers=["o","x"]for v,var in enumerate(["prcp", "temp"]):    fig,axes=plt.subplots(3,3,figsize=(15,8))    for r, rgi_id in enumerate(rgi_ids):        row = r // axes.shape[1]        col = r % axes.shape[1]        for m, model in enumerate(models):            for i in range(members[m]):                #Create a sample-id tag to list model restuls                sample_id= f"{model}.00{i}" #p                # Why no valid volume file??                 opath = os.path.join(wd_path, "per_glacier", rgi_id[:-6], rgi_id[:-3],rgi_id, 'climate_historical_{}.nc'.format(sample_id))                # ds_diag_ext = pd.read_csv(opath)                # ds_diag_ext = xr.Dataset.from_dataframe(ds_diag_ext)                ds_diag_ext=xr.open_dataset(opath)                axes[row,col].scatter(ds_diag_ext["time"], ds_diag_ext[var], label=sample_id, marker=markers[v], color=colors[model][i])                axes[row,col].set_title(rgi_id)                if r == 3:                    axes[row,col].set_ylabel(ds_diag_ext[var].long_name+" ["+ds_diag_ext[var].units+"]")                if r >= 6:                    axes[row, col].set_xlabel("Time [year]")                # print(ds_diag_ext["time"])    # Adjust the legend    handles, labels = axes[0, 0].get_legend_handles_labels()    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=5)    plt.tight_layout()    plt.show()#%% Plot MB output# Define the members and modelsmembers = [3, 4, 6, 1,1]# members=[1,1,1,1,1,]models = ["E3SM", "CESM2", "CNRM", "IPSL-CM6", "W5E5"]# Define the colors for each model's memberscolors = {    "W5E5": ["#000000"],  # Black    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],  # Darker to lighter shades of purple    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],  # Darker to lighter shades of pink    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],  # Darker to lighter shades of orange    "IPSL-CM6": ["#FFB000"]  # Dark purple to lighter shades}# Create the figure and axesfig, axes = plt.subplots(3,3, figsize=(15, 8))for r, rgi_id in enumerate(rgi_ids):    row = r // axes.shape[1]    col = r % axes.shape[1]    axes[row, col].set_title(rgi_id)    if r == 0 or r == 3 or r == 6:        axes[row, col].set_ylabel("Volume [m3]")    if r >= 6:        axes[row, col].set_xlabel("Time [year]")    for m, model in enumerate(models):        for i in range(members[m]):            # Create a sample-id tag to list model results            sample_id = f"{model}.00{i}"             # Define the output path            opath = os.path.join(wd_path, "per_glacier", rgi_id[:-6], rgi_id[:-3], rgi_id, 'model_diagnostics_{}_output_climate_run.nc'.format(sample_id))                        # Load the dataset            ds_diag_ext = xr.open_dataset(opath)                        # Plot the data with the appropriate color            if m==4:                axes[row, col].plot(ds_diag_ext["time"], ds_diag_ext["volume_m3"], label=sample_id, color=colors[model][i], linewidth=3)              elif i==0:                axes[row, col].plot(ds_diag_ext["time"], ds_diag_ext["volume_m3"], label=sample_id, color=colors[model][i], linewidth=3, alpha=1)            else:                axes[row, col].plot(ds_diag_ext["time"], ds_diag_ext["volume_m3"], label=sample_id, color=colors[model][i], linewidth=3, linestyle="dotted")# Adjust the legendhandles, labels = axes[0, 0].get_legend_handles_labels()fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=5)plt.tight_layout()plt.show()#%% Same code but now per modelmembers = [3, 4, 6, 1]# members=[1,1,1,1,1,]models = ["E3SM", "CESM2", "CNRM", "IPSL-CM6"]# Define the colors for each model's memberscolors = {    "W5E5": ["#000000"],  # Black    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],  # Darker to lighter shades of purple    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],  # Darker to lighter shades of pink    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],  # Darker to lighter shades of orange    "IPSL-CM6": ["#FFB000"]  # Dark purple to lighter shades}for m, model in enumerate(models):    fig,axes = plt.subplots(3,3,figsize=(10, 6))        for r, rgi_id in enumerate(rgi_ids):        row = r // axes.shape[1]        col = r % axes.shape[1]        axes[row, col].set_title(rgi_id)        if r == 0 or r == 3 or r == 6:            axes[row, col].set_ylabel("Volume [m3]")        if r >= 6:            axes[row, col].set_xlabel("Time [year]")        opath = os.path.join(wd_path, "per_glacier", rgi_id[:-6], rgi_id[:-3], rgi_id, 'model_diagnostics_W5E5.000_output_climate_run.nc')        ds_baseline = xr.open_dataset(opath)        axes[row,col].plot(ds_baseline["time"], ds_baseline["volume_m3"], label="W5E5.000", color="black", linewidth=3)        for i in range(members[m]):            sample_id = f"{model}.00{i}"             # Create a sample-id tag to list model results            # Plot the baseline (W5E5)                                # Define the output path            opath = os.path.join(wd_path, "per_glacier", rgi_id[:-6], rgi_id[:-3], rgi_id, f'model_diagnostics_{sample_id}_output_climate_run.nc')                        # Load the dataset            ds_diag_ext = xr.open_dataset(opath)                        # Plot the data with the appropriate color and style                        linestyle = 'dotted' if i > 0 else '-'            axes[row,col].plot(ds_diag_ext["time"], ds_diag_ext["volume_m3"], label=f'{sample_id}', color=colors[model][i], linewidth=3, linestyle=linestyle)    # Adjust the legend    handles, labels = axes[0, 0].get_legend_handles_labels()    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 0), ncol=5)    plt.tight_layout()    plt.show()#%% path = os.path.join(wd_path, 'per_glacier', 'RGI60-13', 'RGI60-13.41', 'RGI60-13.41891', 'model_diagnostics_CNRM.000_output_climate_run.nc')ds = xr.open_dataset(path)ds.volume_m3.values#%% Cell11b: Plot flowlines# for (i,gdir) in enumerate(gdirs):#     gfig, axs = plt.subplots()#     fls = gdir.read_pickle('model_flowlines')#     graphics.plot_modeloutput_section(fls, ax=axs)    # cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')fig, axs = plt.subplots(3, 3, figsize=(15, 10))for i, gdir in enumerate(gdirs):    # Determine the position of the subplot (i.e., row and column)    row = i // 3    col = i % 3        # Get the specific axis for the subplot    ax = axs[row, col]        # Read the pickle file and plot    fls = gdir.read_pickle('model_flowlines')    fls2 = gdir.read_pickle('model_flowlines_dyn_melt_f_calib')    graphics.plot_modeloutput_section(fls, ax=ax)    # ax.set_title(gdir.rgi_id)# Adjust layout to prevent overlapping# plt.tight_layout()# Show the combined plotplt.show()    #%%  Cell 12: Plot MB comparisoncfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(3,3, figsize=(20, 12), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)     # First check the parameters used for running the flmod model per flowline    for flmod in mbmod.flowline_mb_models:        print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl    B = mbmod.get_specific_mb(fls=fls, year=years)    mb['B'] = B        # Load & plot Hugonnet data for 2000-2010    mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]    mean_mb_2010_2020 = mb_2010_2020['B'].mean()    sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000       # Load & plot Hugonnet data for 2000-2010    _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]    axes_mb[i].fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='C0')    axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2010')        # Plot (mean) modelled data     axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')    # axes_mb[i].plot([2010, 2020], [mean_mb_2020, mean_mb_2020], color='C1', linestyle='dashed', label='OGGM modelled mean 2010-2020')    axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs    axes_mb[i].set_title(gdir.rgi_id, fontsize=20)    axes_mb[i].annotate(panels[i],xy=(0.98, 0.98), xycoords='axes fraction',                                    fontsize=24, weight='medium', ha='right', va='top')#,                                    #bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))    # axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        if i % 3 == 0:  # Only set ylabel on the left column        axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)    axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=3)plt.show()#%%  Cell 12a: Plot MB comparison - zoom in to 2 glaciers with changes before and after dynamic spinupcfg.PARAMS['store_model_geometry']=Truembdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(1,2, figsize=(10, 3), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingchanged_ids = ['RGI60-13.00967', 'RGI60-13.40982']changed_gdirs = [gdir for gdir in gdirs if gdir.rgi_id in changed_ids]for (i, gdir) in enumerate(changed_gdirs):    # for j, model_type in enumerate(['model_flowlines', 'model_flowlines_dyn_melt_f_calib']):        mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         fls = gdir.read_pickle('model_flowlines')         B = mbmod.get_specific_mb(fls=fls, year=years)        mb['B'] = B                # Load & plot Hugonnet data for 2000-2010        mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]        mean_mb_2010_2020 = mb_2010_2020['B'].mean()        sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000                # Load & plot Hugonnet data for 2000-2020        _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]        axes_mb[i].fill_between([2000, 2020], [_mb - _err, _mb - _err], [_mb + _err, _mb + _err], alpha=0.5, color='C0')        axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2020')        # Plot (mean) modelled data        axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')        axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs        axes_mb[i].set_title(f"{gdir.rgi_id} ", fontsize=20)        if (i) % 2 == 0:  # Only set ylabel on the left column            axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)        axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.1, -0.3), ncols=3)plt.show()#%%  Cell 12b: PlotFlowlines in 9x9 subplotcfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(2010, 2015) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_fls, axes_fls = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_fls = axes_fls.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):    for j in years:                mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         # First check the parameters used for running the flmod model per flowline                    fls = gdir.read_pickle('model_flowlines')         heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=j)        # units kg ice per second to mm w.e. per year:        mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']                 # Plot        axes_fls[i].plot(mb, heights, '-', label=j);                            if i==3:        axes_fls[i].set_ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=10)plt.show()#%% Cell 13: Run model for glacier statistics# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output'.format(sample_id),                             output_filesuffix='_{}_output_run_after_spinup'.format(sample_id),                             mb_elev_feedback='monthly',                             store_monthly_step=True                             )#%% cell 13a: Plot volume evolution of the glaciers# add_to_basenames('model_diagnostics_W5E5_spinup_historical.nc', #basename#                   'model_diagnostics.nc') #filename) #docstr=''                 fig_vol, axes_vol = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_vol = axes_vol.flatten() for (i,gdir) in enumerate(gdirs):    ds_diag = xr.open_dataset(gdir.get_filepath('model_diagnostics'))    axes_vol[i].plot(ds_diag.calendar_year,ds_diag.volume_m3); axes_vol[i].set_title(f'{gdir.rgi_id}');    if i==3:        axes_vol[i].set_ylabel('Volume [m$^3$]')