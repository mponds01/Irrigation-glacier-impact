""" This script runs the OGGM step by step guide to a preprocessed directory"""#%% Cell 1: Load the required directoriesimport oggmfrom oggm import cfg, utils, workflow, tasks, DEFAULT_BASE_URLimport geopandas as gpdimport numpy as npimport osfrom oggm.shop import rgitopofrom oggm import GlacierDirectoryfrom oggm.core import massbalance, flowline# Libsimport xarray as xrimport matplotlib.pyplot as pltimport matplotlib.cm as cmfrom oggm.shop import cru, w5e5from oggm.tasks import process_w5e5_dataimport matplotlib.pyplot as pltfrom oggm import graphicsimport pandas as pdimport loggingimport shutilimport argparseimport timeimport loggingimport json#%% Cell 1: Initiate OGGM using own climate datadef initiate_OGGM(timeframe, model, member, reset):    cfg.initialize(logging_level='WARNING')    cfg.PARAMS['baseline_climate']=''            # Open working directory (where OGGM will write its output)    cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=reset)        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"    cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.nc"    return    # ds = xr.open_dataset(f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.nc")#%% Cell 2: Create a function to compile glacier stats for baseline climatedef compile_statistics(sample_id):    sum_dir=os.path.join(wd_path, 'summary')    os.makedirs(sum_dir, exist_ok=True)        opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    utils.compile_glacier_statistics(gdirs, path=opath_g)    opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))    utils.compile_climate_statistics(gdirs, path=opath_c)    opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))    utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_b)        return#%% Cell 2b: Function to plot statisticsdef plot_glacier_stats(sample_id, sum_dir):    opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))    opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))        glacier_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_g))    climate_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_c))    massbalance_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_b).reset_index().rename(columns={'index':'year'}))    for (i,rgi_id) in enumerate(rgi_ids):        plot = plt.plot(massbalance_stats.year[79:]+1901, massbalance_stats[f'{rgi_id}'][79:], color=colors[i])               #print the years of climate info available        # y0=gdirs[i].get_climate_info()['baseline_yr_0']        # ye=gdirs[i].get_climate_info()['baseline_yr_1']+1        # print(y0, ye)    return plot#%% Cell 3: Process custom climate data functiondef process_custom_climate_data(gdir):    print(gdir.rgi_id)    # Assuming you have a NetCDF with 'temp' and 'prcp' variables    climate_file = cfg.PATHS.get('climate_file', None)    if climate_file is None:        raise ValueError("The path to the climate file is not specified in cfg.PATHS['climate_file']")    try:        with utils.ncDataset(climate_file) as nc:            time = nc.variables['time'][:]            temp = nc.variables['temp'][:]            prcp = nc.variables['prcp'][:]            heights = nc.variables['hgt'][:]        mean_height = np.nanmean(heights)                ref_pix_lon = gdir.cenlon #take center longitude for reference        ref_pix_lat = gdir.cenlon  #take center latitude for reference        ref_pix_hgt = mean_height        # ref_pix_hgt = heights[lat_idx]        output_dir = os.path.dirname(gdir.get_filepath('climate_historical'))        if not os.path.exists(output_dir):            os.makedirs(output_dir, exist_ok=True)        # Process and write to glacier directory        gdir.write_monthly_climate_file(time, temp, prcp, ref_pix_hgt, ref_pix_lon, ref_pix_lat, source='gswp3-w5e5')        print(f"Climate data processed and written for glacier directory {gdir.dir}")    except PermissionError as e:        raise PermissionError(f"Permission denied: {e}")    except Exception as e:        raise RuntimeError(f"An error occurred while processing the climate data: {e}")#%% Cell 6: OPTIONAL Run the model simulation before dynamic calibration# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Example parameters for run_from_climate_datays = 1985  # Start yearye = 2014  # End yearstore_monthly_step = True# climate_filename = f'{model}_climate_output'climate_filename=f'_{sample_id}_processed_output' #set ice dynamics model to be updated monthly for monthly output and monthly processesworkflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output'.format(sample_id),                             output_filesuffix='_{}_output_run_after_spinup'.format(sample_id),                             mb_elev_feedback='monthly',                             store_monthly_step=True                             )#and compile the outputopath_out = os.path.join(sum_dir, '{}_historical_run_output.nc'.format(sample_id))#input filesuffix here is the output file suffix from the run from custom climate data functionutils.compile_run_output(gdirs, path=opath_out, input_filesuffix='') ds_diag = xr.open_dataset(opath_out)#%% Cell 7: conduct dynamic spinup def run_dynamic_spinup(sum_dir, gdirs):        ye=2020        dynamic_spinup = "area/dmdtda"    err_dmdtda_scaling_factor=0.2    dynamic_spinup_start_year=1979        if y0 > dynamic_spinup_start_year:        dynamic_spinup_start_year = y0        minimise_for = dynamic_spinup.split('/')[0]    ### CHECK IF IT CREATES A NEW FILE IN GLACIER DIRECTORY    melt_f_max = cfg.PARAMS['melt_f_max']    workflow.execute_entity_task(        tasks.run_dynamic_melt_f_calibration, gdirs,        err_dmdtda_scaling_factor=err_dmdtda_scaling_factor,        ys=dynamic_spinup_start_year, ye=ye, #ye must be 2020 to match Hugonnet        melt_f_max=melt_f_max,        kwargs_run_function={'minimise_for': minimise_for},        ignore_errors=True,        kwargs_fallback_function={'minimise_for': minimise_for},        output_filesuffix='_{}_spinup_historical'.format(model))    # Now compile the output    opath = os.path.join(sum_dir, '{}_spinup_historical_run_output.nc'.format(sample_id))    utils.compile_run_output(gdirs, path=opath,                             input_filesuffix='_{}_spinup_historical'.format(sample_id))        # Glacier statistics we recompute here for error analysis    opath = os.path.join(sum_dir, '{}_spinup_glacier_statistics_sample_glaciers.csv'.format(sample_id))    utils.compile_glacier_statistics(gdirs, path=opath)    return#%% Cell 8: Recompile glacier statistics and extended filesdef recompile_extend_glacier_stats(sample_id):    #save a new flowline file - is this really needed?    workflow.execute_entity_task(tasks.init_present_time_glacier, gdirs, filesuffix='_after_spinup')        pf = os.path.join(sum_dir, '{}_spinup_historical_run_output.nc'.format(sample_id))    # We have copied the files above    mf = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))    sf = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    opath = os.path.join(sum_dir, '{}_spinup_historical_extended_run_output.nc'.format(sample_id))        #extend past run files for the past run file, creating an extended output file    utils.extend_past_climate_run(past_run_file=pf,                                  fixed_geometry_mb_file=mf,                                  glacier_statistics_file=sf,                                  path=opath                                  )    return#%% Cell 9: Create a functio to add new files to basenamesdef add_to_basenames(basename, filename, docstr=''):    """Add an entry to the list of BASENAMES.    BASENAMES are access keys to files available at the gdir level.    Parameters    ----------    basename : str        the key (e.g. 'dem', 'model_flowlines')    filename : str        the associated filename (e.g. 'dem.tif', 'model_flowlines.pkl')    docstr : str        the associated docstring (for documentation)    """    global BASENAMES    if '.' not in filename:        raise ValueError('The filename needs a proper file suffix!')    cfg.BASENAMES[basename] = (filename, docstr)# cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')   #%% Cell 10: Provide modelling parameters for OGGM# Use W5E5 datafolder_path='/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/05. OGGM Working Directories'wd_path=f'{folder_path}/06. Modelled perturbation-glacier interactions/'y0=1980ye=2019period = slice(f'{y0}-01-01', f'{ye}-12-31')cmap=cm.get_cmap('bone')colors=[cmap(i / 9) for i in range(10)]# Specify the RGI region you are interested in, for example, region 13 (Central Asia)rgi_reg = '13'  # this must fit to example glacier(s), if starting from level 0rgi_ids = ["RGI60-13.40102", # Area >10km2    "RGI60-13.39195", # Area >10km2    "RGI60-13.36881", # Area >10km2    "RGI60-13.38969", # Area >10km2    "RGI60-13.37184", # Area >10km2    "RGI60-13.00967", # Area <10km2    "RGI60-13.40982", # Area <10km2    "RGI60-13.41891", # WGMS observation    "RGI60-13.23659", # WGMS observation] base_url = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/')prepro_level=3#Provide output names:sum_dir=os.path.join(wd_path, 'summary')#Download the RGI inventory and set up the glacier directoriesgdirs = workflow.init_glacier_directories(rgi_ids, from_prepro_level=prepro_level, prepro_base_url=base_url)# Go - re-open the pre-processed glacier directories from what's there, but with the list of glaviers# gdirs = workflow.init_glacier_directories(rgi_ids)#%% Cell 11: Run OGGMmembers=[1,3,4,6,1]models = "W5E5","E3SM","CESM2","CNRM","IPSL-CM6"timeframe="monthly"for m, model in enumerate(models):    for i in range(members[m]):        sample_id= f"{model}-00{i}" #provide label for all run output        initiate_OGGM(timeframe, model, i, True) #initiate the model with custom climate data (model-member combination)        # compile_statistics(sample_id) #compile baseline glacier statistics        # plot_glacier_stats(sample_id, sum_dir)        workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs, output_filesuffix=f'_{sample_id}_processed_output') #process climate data for all gdirs        if m==0 and model=="W5E5":  #run the model with the baseline            run_dynamic_spinup(sum_dir, gdirs) #run dynamic spinup only for the baseline climate            compile_statistics(sample_id) #compile                     # We want to use these flowline files for the AAR (see later)        cfg.PARAMS['store_fl_diagnostics'] = True        # Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)        workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                                     ys=y0, ye=ye, #store_monthly_step=store_monthly_step,                                     climate_filename='climate_historical',                                     climate_input_filesuffix='_{}_processed_output'.format(sample_id),                                     output_filesuffix='_{}_output_run_after_spinup'.format(sample_id),                                     mb_elev_feedback='monthly',                                     store_monthly_step=True                                     )        recompile_extend_glacier_stats(sample_id)                            #%% Cell 8a: Plot historical run output extended# Why no valid volume file?? # opath = os.path.join(sum_dir, '{}_spinup_historical_extended_run_output.nc'.format(sample_id))ds_diag_ext = xr.open_dataset(opath)ds_diag_ext.volume_m3.plot(); plt.title('Volume evolution');plt.show()#%% Cell11b: Plot flowlines# for (i,gdir) in enumerate(gdirs):#     gfig, axs = plt.subplots()#     fls = gdir.read_pickle('model_flowlines')#     graphics.plot_modeloutput_section(fls, ax=axs)    # cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')fig, axs = plt.subplots(3, 3, figsize=(15, 10))for i, gdir in enumerate(gdirs):    # Determine the position of the subplot (i.e., row and column)    row = i // 3    col = i % 3        # Get the specific axis for the subplot    ax = axs[row, col]        # Read the pickle file and plot    fls = gdir.read_pickle('model_flowlines')    fls2 = gdir.read_pickle('model_flowlines_dyn_melt_f_calib')    graphics.plot_modeloutput_section(fls, ax=ax)    # ax.set_title(gdir.rgi_id)# Adjust layout to prevent overlapping# plt.tight_layout()# Show the combined plotplt.show()    #%%  Cell 12: Plot MB comparisoncfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(3,3, figsize=(20, 12), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)     # First check the parameters used for running the flmod model per flowline    for flmod in mbmod.flowline_mb_models:        print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl    B = mbmod.get_specific_mb(fls=fls, year=years)    mb['B'] = B        # Load & plot Hugonnet data for 2000-2010    mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]    mean_mb_2010_2020 = mb_2010_2020['B'].mean()    sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000       # Load & plot Hugonnet data for 2000-2010    _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]    axes_mb[i].fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='C0')    axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2010')        # Plot (mean) modelled data     axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')    # axes_mb[i].plot([2010, 2020], [mean_mb_2020, mean_mb_2020], color='C1', linestyle='dashed', label='OGGM modelled mean 2010-2020')    axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs    axes_mb[i].set_title(gdir.rgi_id, fontsize=20)    axes_mb[i].annotate(panels[i],xy=(0.98, 0.98), xycoords='axes fraction',                                    fontsize=24, weight='medium', ha='right', va='top')#,                                    #bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))    # axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        if i % 3 == 0:  # Only set ylabel on the left column        axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)    axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=3)plt.show()#%%  Cell 12a: Plot MB comparison - zoom in to 2 glaciers with changes before and after dynamic spinupcfg.PARAMS['store_model_geometry']=Truembdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(1,2, figsize=(10, 3), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingchanged_ids = ['RGI60-13.00967', 'RGI60-13.40982']changed_gdirs = [gdir for gdir in gdirs if gdir.rgi_id in changed_ids]for (i, gdir) in enumerate(changed_gdirs):    # for j, model_type in enumerate(['model_flowlines', 'model_flowlines_dyn_melt_f_calib']):        mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         fls = gdir.read_pickle('model_flowlines')         B = mbmod.get_specific_mb(fls=fls, year=years)        mb['B'] = B                # Load & plot Hugonnet data for 2000-2010        mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]        mean_mb_2010_2020 = mb_2010_2020['B'].mean()        sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000                # Load & plot Hugonnet data for 2000-2020        _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]        axes_mb[i].fill_between([2000, 2020], [_mb - _err, _mb - _err], [_mb + _err, _mb + _err], alpha=0.5, color='C0')        axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2020')        # Plot (mean) modelled data        axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')        axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs        axes_mb[i].set_title(f"{gdir.rgi_id} ", fontsize=20)        if (i) % 2 == 0:  # Only set ylabel on the left column            axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)        axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.1, -0.3), ncols=3)plt.show()#%%  Cell 12b: PlotFlowlines in 9x9 subplotcfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(2010, 2015) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_fls, axes_fls = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_fls = axes_fls.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):    for j in years:                mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         # First check the parameters used for running the flmod model per flowline                    fls = gdir.read_pickle('model_flowlines')         heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=j)        # units kg ice per second to mm w.e. per year:        mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']                 # Plot        axes_fls[i].plot(mb, heights, '-', label=j);                            if i==3:        axes_fls[i].set_ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=10)plt.show()#%% Cell 13: Run model for glacier statistics# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output'.format(sample_id),                             output_filesuffix='_{}_output_run_after_spinup'.format(sample_id),                             mb_elev_feedback='monthly',                             store_monthly_step=True                             )#%% cell 13a: Plot volume evolution of the glaciers# add_to_basenames('model_diagnostics_W5E5_spinup_historical.nc', #basename#                   'model_diagnostics.nc') #filename) #docstr=''                 fig_vol, axes_vol = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_vol = axes_vol.flatten() for (i,gdir) in enumerate(gdirs):    ds_diag = xr.open_dataset(gdir.get_filepath('model_diagnostics'))    axes_vol[i].plot(ds_diag.calendar_year,ds_diag.volume_m3); axes_vol[i].set_title(f'{gdir.rgi_id}');    if i==3:        axes_vol[i].set_ylabel('Volume [m$^3$]')