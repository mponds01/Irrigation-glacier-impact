""" This script runs the OGGM step by step guide to a preprocessed directory"""#%% Cell 1: Load the required directoriesimport oggmfrom oggm import cfg, utils, workflow, tasks, DEFAULT_BASE_URLimport geopandas as gpdimport numpy as npimport osfrom oggm.shop import rgitopofrom oggm import GlacierDirectoryfrom oggm.core import massbalance, flowline# Libsimport xarray as xrimport matplotlib.pyplot as pltimport matplotlib.cm as cmfrom oggm.shop import cru, w5e5from oggm.tasks import process_w5e5_datafrom oggm.core.climate import matplotlib.pyplot as pltfrom oggm import graphicsimport pandas as pdimport loggingimport shutilimport argparseimport timeimport loggingimport jsonimport csv    #%% Print iput datamodel="W5E5"member="0"timeframe="monthly"y0 = 1901base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"ds = xr.open_dataset(f"{base_folder_in}/{model}.00{member}.{y0}_2014.{timeframe}.perturbed.climate.input.degC.nc")print(ds.prcp.values)#%% Cell 1: Create a functio to add new files to basenamesdef add_to_basenames(basename, filename, docstr=''):    """Add an entry to the list of BASENAMES.    BASENAMES are access keys to files available at the gdir level.    Parameters    ----------    basename : str        the key (e.g. 'dem', 'model_flowlines')    filename : str        the associated filename (e.g. 'dem.tif', 'model_flowlines.pkl')    docstr : str        the associated docstring (for documentation)    """    global BASENAMES    if '.' not in filename:        raise ValueError('The filename needs a proper file suffix!')    cfg.BASENAMES[basename] = (filename, docstr)# cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')   #%% Cell 2: Provide modelling parameters for OGGM# Use W5E5 data# folder_path='/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/05. OGGM Working Directories'folder_path='/Users/magaliponds/Documents/00. Programming'wd_path=f'{folder_path}/06. Modelled perturbation-glacier interactions/'y0_clim=1985ye_clim=2014y0_spinup=1980ye_spinup=2020cmap=cm.get_cmap('bone')colors=[cmap(i / 9) for i in range(10)]# Specify the RGI region you are interested in, for example, region 13 (Central Asia)rgi_reg = '13'  # this must fit to example glacier(s), if starting from level 0rgi_ids = ["RGI60-13.40102", # Area >10km2    "RGI60-13.39195", # Area >10km2    "RGI60-13.36881", # Area >10km2    "RGI60-13.38969", # Area >10km2    "RGI60-13.37184", # Area >10km2    "RGI60-13.00967", # Area <10km2|    "RGI60-13.40982", # Area <10km2    "RGI60-13.41891", # WGMS observation    "RGI60-13.23659", # WGMS observation] base_url_elev = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/')base_url_center = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/centerlines/W5E5/')prepro_level=3sum_dir=os.path.join(wd_path, 'summary')border=80#Provide output names:print(DEFAULT_BASE_URL)#%% Cell 2a: Run Dyanmic spinupmembers=[1,3,4,6,1]models = ["W5E5","E3SM","CESM2","CNRM","IPSL-CM6"]timeframe="monthly"download_gdirs=Falsereset=False    years = np.arange(y0_clim, ye_clim)         cfg.initialize(logging_level='WARNING')cfg.PARAMS['baseline_climate']="CUSTOM"cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=reset)cfg.PARAMS['use_multiprocessing']=Falsefor m, model in enumerate(["W5E5"]):    for member in range(1):            #Create a sample-id tag to list model restuls        sample_id= f"{model}.00{member}" #provide label for all run output                # Dowload or reopen the gdirs        if download_gdirs==True:            gdirs = workflow.init_glacier_directories(rgi_ids,                                                       from_prepro_level=3,                                                       prepro_base_url=base_url_elev, prepro_border=border)        else:            gdirs = workflow.init_glacier_directories(rgi_ids)                    #Create a summary folder            os.makedirs(sum_dir, exist_ok=True)            #initiate the model with custom climate data (model-member combination)        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"        cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1901_2014.{timeframe}.perturbed.climate.input.degC_test.nc"        # Process the climate data        # workflow.execute_entity_task(tasks.process_climate_data, gdirs, output_filesuffix='_L3') #process climate data for all gdirs        workflow.execute_entity_task(tasks.process_climate_data, gdirs, output_filesuffix=f'_{sample_id}_ext') #process climate data for all gdirs        info=[]        # for gdir in gdirs:         #     rgi_id = gdir.rgi_id        #     lon =  gdir.get_climate_info()['baseline_climate_ref_pix_lon']        #     lat =  gdir.get_climate_info()['baseline_climate_ref_pix_lat']        #     hgt =  gdir.get_climate_info()['baseline_climate_ref_hgt']        #     info.append((rgi_id, lon, lat, hgt))        # print(info)        #Create log file        # utils.compile_task_log(gdirs)                # #initiate the model with a present time glacer        # workflow.execute_entity_task(tasks.init_present_time_glacier, gdirs)                    #TO DO: Determine temperature bias, precipitation factor and melt factor        # workflow.execute_entity_task(tasks.mb_calibration_from_geoditic_mb,         #                              gdirs, informed_threestep=True)                 #Include run dynamic spinup        # workflow.execute_entity_task(tasks.run_dynamic_spinup, gdirs,         #                               init_model_filesuffix=None, init_model_yr=None,         #                               init_model_fls=None, climate_input_filesuffix=f'_{sample_id}_ext',         #                               evolution_model=None, mb_model_historical=None,         #                               mb_model_spinup=None, spinup_period=20, spinup_start_yr=None,         #                               min_spinup_period=10, spinup_start_yr_max=None,         #                               target_yr=2020, target_value=None, minimise_for='area',         #                               precision_percent=2, #precision_absolute=1,         #                               min_ice_thickness=None, first_guess_t_bias=-2,         #                               t_bias_max_step_length=2, maxiter=30,         #                               output_filesuffix='_dynamic_spinup',         #                               store_model_geometry=True, store_fl_diagnostics=True,         #                               store_model_evolution=True, ignore_errors=False,         #                               return_t_bias_best=False, ye=None,         #                               model_flowline_filesuffix='',         #                               add_fixed_geometry_spinup=False)                # minimise_for = "area"        # melt_f_max = cfg.PARAMS['melt_f_max']        # workflow.execute_entity_task(        #     tasks.run_dynamic_melt_f_calibration, gdirs,        #     err_dmdtda_scaling_factor=0.2,        #     ys=1901, #first year that data is available         #     ye=2020,        #     melt_f_max=melt_f_max,        #     kwargs_run_function={'minimise_for': minimise_for},        #     ignore_errors=True,        #     kwargs_fallback_function={'minimise_for': minimise_for},        #     output_filesuffix='_spinup_historical')        #     # init_model_filesuffix='_spinup_historical')                # # # Now compile the output        # opath = os.path.join(sum_dir, 'spinup_historical_run_output_after_W5E5.000.nc')        # utils.compile_run_output(gdirs, path=opath,        #                              input_filesuffix='_spinup_historical')                # opath_g = os.path.join(sum_dir, 'glacier_statistics_ref_{}.csv'.format(sample_id))        # utils.compile_glacier_statistics(gdirs, path=opath_g)        # opath_massbalance = os.path.join(sum_dir, 'historical_run_massbalance_output.csv')        # utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_massbalance, climate_filename='climate_historical',        #                                           ys=y0_clim, ye=ye_clim,         #                                           # climate_input_filesuffix='_{}_ext'.format(sample_id)         #                                           # use_inversion_flowlines=False        #                                           )                         #%% Celll 2b: Test plot volume evolution from dynamic spinupopath = os.path.join(sum_dir,'spinup_historical_run_output_after_W5E5.000.nc')ds_spinup = xr.open_dataset(opath)spinup_period = []for r, rgi_id in enumerate(rgi_ids):        data = ds_spinup.sel(rgi_id=rgi_id).dropna(dim='time', subset=['volume'])    start_year = data.time[0].values    end_year = data.time[-1].values    spinup_period.append((rgi_id, start_year, end_year))        plt.scatter(ds_spinup.time, ds_spinup.sel(rgi_id=rgi_id).volume*10**-9, label=rgi_id)title=ds_spinup.volume.description + " [ km$^3$]"plt.ylabel(title)plt.legend(ncols=3, loc="lower center", bbox_to_anchor=(0.5,-0.4))with open(f'{wd_path}/spinup_periods.csv', mode='w', newline='') as file:    writer = csv.writer(file)    writer.writerow(['rgi_id', 'start_year', 'end_year'])  # Write the header    writer.writerows(spinup_period)     #%% Test plot dynamic spinup mb outputfor m, model in enumerate(["W5E5"]):    for i in range(1):            if m==0:            for rgi_id in rgi_ids:                plt.figure()                #Create a sample-id tag to list model restuls                sample_id= f"{model}.00{i}" #provide label for all run output                                # opath=os.path.join(sum_dir,'spinup_historical_run_output_{}.nc'.format(sample_id))                opath=os.path.join(sum_dir,'historical_run_massbalance_before_output.csv')                opath_2=os.path.join(sum_dir,'historical_run_massbalance_output.csv')                ds = pd.read_csv(opath)                ds2 = pd.read_csv(opath_2)                ds = xr.Dataset.from_dataframe(ds).rename({'Unnamed: 0': "time"})                ds2 = xr.Dataset.from_dataframe(ds2).rename({'Unnamed: 0': "time"})                print(ds)                ds2 = ds2.where((ds2.time<=2015) & (ds2.time>=1985), drop=True)                ds = ds.where((ds.time<=2015) & (ds.time>=1985), drop=True)                ds=ds[rgi_id]                ds2=ds2[rgi_id]                # ds = xr.open_dataset(opath)                # ds =ds.sel(rgi_id=rgi_id)                print(ds2)                # years = np.arange(1985, 2015)                 plt.plot(ds.values, 'k')                plt.plot(ds2.values, 'b')                                # mbdf = utils.get_geodetic_mb_dataframe()                # mb = pd.DataFrame({'years': years})                # mb['years'] = pd.to_datetime(mb['years'], format='%Y')                # sel = mbdf.loc[rgi_id].set_index('period')*1000                               # # Load & plot Hugonnet data for 2000-2010                # _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]                # plt.fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='gray')                # plt.plot([2000, 2020], [_mb, _mb], color='gray', label='Hugonnet 2000-2010')                plt.title(rgi_id)                        #%%# cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')cfg.initialize(logging_level='WARNING')cfg.PARAMS['baseline_climate']='CUSTOM'cfg.PATHS['working_dir'] = utils.mkdir(wd_path)members=[1, 3,4,6,1]models = ["IPSL-CM6","E3SM","CESM2","CNRM", "W5E5"]timeframe = "monthly"for m, model in enumerate(models):    for member in range(members[m]):                # Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)        sample_id= f"{model}.00{member}" #provide label for all run output        gdirs = workflow.init_glacier_directories(rgi_ids)                utils.compile_task_log(gdirs)        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"        cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.degC.nc"                workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs, output_filesuffix=f'_{sample_id}') #process climate data for all gdirs                workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                                      ys=y0_clim,                                       ye=ye_clim,                                       min_ys=None,                                       max_ys=None,                                      fixed_geometry_spinup_yr=None,                                      store_monthly_step=False,                                      climate_filename='climate_historical',                                      climate_input_filesuffix='_{}'.format(sample_id),                                      output_filesuffix='_{}_output_climate_run'.format(sample_id),                                      init_model_filesuffix='_spinup_historical',                                      init_model_yr=1985, #when the dynamic spinup started                                      init_model_fls=None)                opath = os.path.join(sum_dir,'climate_run_output_{}.nc'.format(sample_id))        utils.compile_run_output(gdirs, path=opath,input_filesuffix='_{}_output_climate_run'.format(sample_id))                # compile_statistics(sample_id, sum_dir)                workflow.execute_entity_task(tasks.fixed_geometry_mass_balance, gdirs,                                               # use_inversion_flowlines=False,                                              ys=y0_clim, ye=ye_clim,                                               monthly_step=False, #not available yet                                              climate_filename='climate_historical',                                              climate_input_filesuffix='_{}'.format(sample_id))                opath_mb = os.path.join(sum_dir, 'compiled_mass_balance_output_{}.csv'.format(sample_id))                utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_mb, climate_filename='climate_historical',                                                  climate_input_filesuffix='_{}'.format(sample_id)                                                   # ys=y0_clim, ye=ye_clim,                                                  # use_inversion_flowlines=False                                                  )                opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))        utils.compile_glacier_statistics(gdirs, path=opath_g)        opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))        utils.compile_climate_statistics(gdirs, path=opath_c)        opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))        utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_b,                                                   climate_filename='climate_historical',                                                  climate_input_filesuffix='_{}'.format(sample_id))                #%%for ds in [pf]:    data = xr.open_dataset(ds).time    print(ds, data)    for ds in [mf_shortened,sf]:    data = pd.read_csv(ds)    if ds==mf_shortened:        data = data['Unnamed: 0']        print(ds, data)                #%%for gd in gdirs:    for m, model in enumerate(models):        for i in range(members[m]):                          print(model, i)              params = gd.read_json('mb_calib')              print("melt_f: ", params['melt_f'])              print("temp_bias: ", params['temp_bias'])              print("prcp_fac: ", params['prcp_fac'])#%% derive mass balacne for the different climate filesfor (i, gdir) in enumerate(gdirs):    plt.figure()    for m, model in enumerate(models):        for i in range(members[m]):            #Create a sample-id tag to list model restuls                        sample_id= f"{model}.00{i}" #provide label for all run output                        #initiate the model with custom climate data (model-member combination)            initiate_OGGM(timeframe, model, i, reset, wd_path)             gdirs = workflow.init_glacier_directories(rgi_ids)                        mbdf = utils.get_geodetic_mb_dataframe()            mb = pd.DataFrame({'years': years})            mb['years'] = pd.to_datetime(mb['years'], format='%Y')                                            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)             # First check the parameters used for running the flmod model per flowline            # for flmod in mbmod.flowline_mb_models:                # print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')                            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl            # fls=xr.open_dataset(os.path.join(wd_path, "per_glacier", rgi_id[:-6], rgi_id[:-3],rgi_id, "fl_diagnostics_CESM2.002_output_climate_run.nc"))            B = mbmod.get_specific_mb(fls=fls, year=years)            mb['B'] = B            plt.plot(mb.years, mb.B)                                                                                       #%% Cell 8a: Plot historical run output extended for all modelsmembers=[1,3,4,6,1]models = "W5E5","E3SM","CESM2","CNRM","IPSL-CM6"for r, rgi_id in enumerate(rgi_ids):    plt.figure()    for m, model in enumerate(models):        for i in range(members[m]):            #Create a sample-id tag to list model restuls            sample_id= f"{model}.00{i}" #p            # Why no valid volume file??             opath = os.path.join(sum_dir, f'fixed_geometry_mass_balance_climate_{sample_id}.csv')            pd.read_csv(opath)            ds_diag_ext = pd.read_csv(opath)            ds_diag_ext = xr.Dataset.from_dataframe(ds_diag_ext)            ds_diag_ext=ds_diag_ext[rgi_id]            # ds_diag_ext = xr.open_dataset(opath).sel(rgi_id=rgi_id)            # print(ds_diag_ext.data_vars)                            # print(ds_diag_ext.data_vars)            ds_diag_ext.plot(label=sample_id)            plt.legend(loc='upper left', ncols=2)                        # plt.title(f'Volume evolution {sample_id}');            # plt.xticks(rotation=90)            # # plt.show()#%% path = os.path.join(wd_path, 'per_glacier', 'RGI60-13', 'RGI60-13.41', 'RGI60-13.41891', 'climate_run_CNRM.000_output_climate_run.nc')ds = xr.open_dataset(path)ds.data_vars#%%path = os.path.join(sum_dir, 'climate_run_CNRM.000.nc')ds = xr.open_dataset(path)ds.data_varsplotds=ds.where(ds.rgi_id=="RGI60-13.23659")plt.plot(plotds.time, plotds.volume)#%% Cell11b: Plot flowlines# for (i,gdir) in enumerate(gdirs):#     gfig, axs = plt.subplots()#     fls = gdir.read_pickle('model_flowlines')#     graphics.plot_modeloutput_section(fls, ax=axs)    # fig, axs = plt.subplots(3, 3, figsize=(15, 10))# for i, gdir in enumerate(gdirs):#     # Determine the position of the subplot (i.e., row and column)#     row = i // 3#     col = i % 3    #     # Get the specific axis for the subplot#     ax = axs[row, col]    #     # Read the pickle file and plot#     fls = gdir.read_pickle('model_flowlines')#     fls2 = gdir.read_pickle('model_flowlines_dyn_melt_f_calib')#     graphics.plot_modeloutput_section(fls, ax=ax)#     # ax.set_title(gdir.rgi_id)# # Adjust layout to prevent overlapping# # plt.tight_layout()# # Show the combined plot# plt.show()    #%%  Cell 12: Plot MB comparisoncfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')cfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(3,3, figsize=(20, 12), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)     # First check the parameters used for running the flmod model per flowline    for flmod in mbmod.flowline_mb_models:        print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl    B = mbmod.get_specific_mb(fls=fls, year=years)    mb['B'] = B        # Load & plot Hugonnet data for 2000-2010    mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]    mean_mb_2010_2020 = mb_2010_2020['B'].mean()    sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000       # Load & plot Hugonnet data for 2000-2010    _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]    axes_mb[i].fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='C0')    axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2010')        # Plot (mean) modelled data     axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')    # axes_mb[i].plot([2010, 2020], [mean_mb_2020, mean_mb_2020], color='C1', linestyle='dashed', label='OGGM modelled mean 2010-2020')    axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs    axes_mb[i].set_title(gdir.rgi_id, fontsize=20)    axes_mb[i].annotate(panels[i],xy=(0.98, 0.98), xycoords='axes fraction',                                    fontsize=24, weight='medium', ha='right', va='top')#,                                    #bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))    # axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        if i % 3 == 0:  # Only set ylabel on the left column        axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)    axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=3)plt.show()#%%  Cell 12a: Plot MB comparison - zoom in to 2 glaciers with changes before and after dynamic spinupcfg.PARAMS['store_model_geometry']=Truembdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(1,2, figsize=(10, 3), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingchanged_ids = ['RGI60-13.00967', 'RGI60-13.40982']changed_gdirs = [gdir for gdir in gdirs if gdir.rgi_id in changed_ids]for (i, gdir) in enumerate(changed_gdirs):    # for j, model_type in enumerate(['model_flowlines', 'model_flowlines_dyn_melt_f_calib']):        mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         fls = gdir.read_pickle('model_flowlines')         B = mbmod.get_specific_mb(fls=fls, year=years)        mb['B'] = B                # Load & plot Hugonnet data for 2000-2010        mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]        mean_mb_2010_2020 = mb_2010_2020['B'].mean()        sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000                # Load & plot Hugonnet data for 2000-2020        _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]        axes_mb[i].fill_between([2000, 2020], [_mb - _err, _mb - _err], [_mb + _err, _mb + _err], alpha=0.5, color='C0')        axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2020')        # Plot (mean) modelled data        axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')        axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs        axes_mb[i].set_title(f"{gdir.rgi_id} ", fontsize=20)        if (i) % 2 == 0:  # Only set ylabel on the left column            axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)        axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.1, -0.3), ncols=3)plt.show()#%%  Cell 12b: PlotFlowlines in 9x9 subplotcfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(2010, 2015) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_fls, axes_fls = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_fls = axes_fls.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):    for j in years:                mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         # First check the parameters used for running the flmod model per flowline                    fls = gdir.read_pickle('model_flowlines')         heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=j)        # units kg ice per second to mm w.e. per year:        mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']                 # Plot        axes_fls[i].plot(mb, heights, '-', label=j);                            if i==3:        axes_fls[i].set_ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=10)plt.show()#%% Cell 13: Run model for glacier statistics# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output'.format(sample_id),                             output_filesuffix='_{}_output_run_after_spinup'.format(sample_id),                             mb_elev_feedback='monthly',                             store_monthly_step=True                             )#%% cell 13a: Plot volume evolution of the glaciers# add_to_basenames('model_diagnostics_W5E5_spinup_historical.nc', #basename#                   'model_diagnostics.nc') #filename) #docstr=''                 fig_vol, axes_vol = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_vol = axes_vol.flatten() for (i,gdir) in enumerate(gdirs):    ds_diag = xr.open_dataset(gdir.get_filepath('model_diagnostics'))    axes_vol[i].plot(ds_diag.calendar_year,ds_diag.volume_m3); axes_vol[i].set_title(f'{gdir.rgi_id}');    if i==3:        axes_vol[i].set_ylabel('Volume [m$^3$]')