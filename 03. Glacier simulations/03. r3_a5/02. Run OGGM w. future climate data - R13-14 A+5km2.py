import multiprocessingfrom multiprocessing import Pool, set_start_method, get_contextfrom multiprocessing import Processimport concurrent.futuresfrom matplotlib.lines import Line2Dimport oggmfrom oggm import utils, cfg, workflow, tasks, DEFAULT_BASE_URL, graphics, global_tasksfrom oggm.core import massbalance, flowlinefrom oggm.utils import floatyear_to_date, hydrodate_to_calendardatefrom oggm.sandbox import distribute_2dfrom oggm.sandbox.edu import run_constant_climate_with_biasfrom oggm.tasks import process_cmip_dataimport geopandas as gpdimport matplotlib.pyplot as pltimport matplotlib.cm as cmimport matplotlib.colors as clrsimport xarray as xrimport osimport seaborn as snsimport salemfrom matplotlib.ticker import FuncFormatterimport pandas as pdimport numpy as npfrom matplotlib import animationfrom IPython.display import HTML, displayimport cartopy.crs as ccrsimport cartopy.feature as cfeaturefrom scipy.optimize import curve_fitfrom tqdm import tqdmimport pickleimport textwrapimport matplotlib.patches as mpatchesimport matplotlib.lines as mlinesfrom matplotlib.colors import LinearSegmentedColormap, TwoSlopeNormimport sysfrom xarray.coding.times import CFDatetimeCoderfrom OGGM_data_processing import process_perturbation_data,custom_process_cmip_data,custom_process_gcm_datafunction_directory = "/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/src/03. Glacier simulations"sys.path.append(function_directory)# %% Cell 0: Set base parameterscolors_models = {    "W5E5": ["#000000"],  # "#000000"],  # Black    # Darker to lighter shades of purple    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],    # Darker to lighter shades of pink    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],    # Darker to lighter shades of orange    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],    "IPSL-CM6": ["#FFB000"]  # Dark purple to lighter shades}members = [1, 3, 4, 6, 4, 1]members_averages = [1, 2, 3, 5, 3]models = ["IPSL-CM6", "E3SM", "CESM2", "CNRM", "NorESM", "W5E5"]models_shortlist = ["IPSL-CM6", "E3SM", "CESM2", "CNRM", "NorESM"]timeframe = "monthly"y0_clim = 1985ye_clim = 2014y0_cf = 1901ye_cf = 1985fig_path = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/04. Figures/02. OGGM simulations/01. Modelled output/3r_a5/'# %% Cell 1: Initialize OGGM with the preferred model parameter set upfolder_path = '/Users/magaliponds/Documents/00. Programming'wd_path = f'{folder_path}/03. Modelled perturbation-glacier interactions - R13-15 A+5km2/'wd_path_fut = f'{folder_path}/03. Modelled perturbation-glacier interactions Future - R13-15 A+5km2/'os.makedirs(wd_path, exist_ok=True)os.makedirs(wd_path_fut, exist_ok=True)cfg.initialize(logging_level='WARNING')cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=False)# make a sum dirsum_dir = os.path.join(wd_path_fut, 'summary')os.makedirs(sum_dir, exist_ok=True)# make a logging directorylog_dir = os.path.join(wd_path_fut, "log")os.makedirs(log_dir, exist_ok=True)# Make a pkl directorypkls = os.path.join(wd_path_fut, "pkls")os.makedirs(pkls, exist_ok=True)cfg.PARAMS['baseline_climate'] = "GSWP3-W5E5"cfg.PARAMS['store_model_geometry'] = True# %% Cell 2: Save gdirs_3r_a5 to pkl (fastest way to get started)pkls_fut = os.path.join(wd_path_fut, "pkls_subset_success")os.makedirs(pkls_fut, exist_ok=True)# Save each gdir individuallyfor gdir in gdirs_3r_a5: #loaded from below    gdir_path = os.path.join(pkls_fut, f'{gdir.rgi_id}.pkl')    with open(gdir_path, 'wb') as f:        pickle.dump(gdir, f)        #%% Cell 2b: Load gdirs_3r_a5 from pklwd_path_pkls_fut = f'{wd_path_fut}/pkls_subset_success/'gdirs_3r_a5 = []for filename in os.listdir(wd_path_pkls_fut):    if filename.endswith('.pkl'):        # f'{gdir.rgi_id}.pkl')        file_path = os.path.join(wd_path_pkls_fut, filename)        with open(file_path, 'rb') as f:            gdir = pickle.load(f)            gdirs_3r_a5.append(gdir)print(len(gdirs_3r_a5))#%% Cell 3: Process the future climate datacfg.initialize()cfg.PATHS['working_dir'] = utils.mkdir(wd_path_fut, reset=False)members = [4]models = ["CESM2"]timeframe = "monthly"ssps = ["126","370"]#"126",exp = ["IRR", "NOI"]y0=2015ye=2074# opath_climate = os.path.join(sum_dir, 'climate_historical.nc')# utils.compile_climate_input(#     gdirs_3r_a5, path=opath_climate, filename='climate_historical')# if you get a long error log saying that "columns" can not be renamed it is often related to multiprocessingcfg.PARAMS['use_multiprocessing'] = Truecfg.PARAMS['core'] = 9 # ðŸ”§ set number of coresdef main():    remake="False"    for m, model in enumerate(models):        for member in range(members[m]):            for s, ssp in enumerate(ssps):                for e, ex in enumerate(exp):                    if member >= 1: #skip 0                        sample_id = f"{model}.00{member}"                        print(sample_id, ex, "SSP",ssp)                        if remake=="True":                                                    # Provide the path to the perturbation dataset                            # if error with lon.min or ds['time.year'] check if lon>0 in creating input dataframe                            i_folder_ptb = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/01. Input files/01. Climate data/{model}/{y0}/"                            ds_path = f"{i_folder_ptb}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total.nc"                            # ds_path = f"{i_folder_ptb}/{model}.00{member}.{y0_cf}_{ye_cf}.{timeframe}.perturbation.input.%.degC.counterfactual.nc"                            ds = xr.open_dataset(ds_path)                                                        #add the original timeline for bias correction (reference period 1961-1990)                            i_folder_ptb_og = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/01. Input files/01. Climate data/{model}/1985/"                            ds_path_og = f"{i_folder_ptb_og}/{model}.{ex}.00{member}.1985_2014_selparam_monthly_total.nc"                            ds_og = xr.open_dataset(ds_path_og)                            ds = ds.assign_coords(lat=ds_og.lat) #assign ds with the coords of ds_og (3e-6 difference)                            ds_combined = xr.concat([ds_og,ds], dim="time")                                                        ds_combined[['pr','sn','tas']] = ds_combined[['pr','sn','tas']].fillna(-1e9) #fill na values with very small nr                            # ds_combined = ds_combined.rename({'time_bnds': 'bnds'})                            # ds_combined = ds_combined.set_coords('bnds')                                                       time64_combined = pd.to_datetime([t.isoformat() for t in ds_combined['time'].values])                            ds_combined = ds_combined.assign_coords(time=('time', time64_combined))                                                        all_prcp = (ds_combined.pr + ds_combined.sn) #convert mm/s to mm/day in function, already summed for days in month                            all_prcp = all_prcp.to_dataset(name='pr')                            all_prcp.pr.attrs['units'] = "kg m-2 s-1"                            all_prcp["time"] = xr.decode_cf(all_prcp).time                            # all_prcp['time.month'] = ('time', all_prcp['time'].dt.month.data)                                                        tas = ds_combined.tas.to_dataset(name='tas')                            tas.tas.attrs['units'] = "degc"                            tas["time"] = xr.decode_cf(tas).time                            tas = tas.sortby('time')                            # tas['time.month'] = ('time', tas['time'].dt.month.data)                                                        o_folder = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/03. Future climate data/"                            ds_p_path = f"{o_folder}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total_P_processed.nc"                            ds_t_path = f"{o_folder}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total_T_processed.nc"                            os.makedirs(o_folder, exist_ok=True)                            all_prcp.to_netcdf(ds_p_path)                            tas.to_netcdf(ds_t_path)                        else:                            o_folder = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/03. Future climate data/"                            ds_p_path = f"{o_folder}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total_P_processed.nc"                            ds_t_path = f"{o_folder}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total_T_processed.nc"                                                        all_prcp = xr.open_dataset(f"{o_folder}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total_P_processed.nc")                            tas = xr.open_dataset(f"{o_folder}/{model}.SSP{ssp}.{ex}.00{member}.{y0}_{ye}_selparam_monthly_total_T_processed.nc")                                                output_filesuffix = f"_SSP{ssp}_{ex}.00{member}"                        # print(tas["time.month"])                                                time_vals = tas['lat'].values                        duplicates = pd.Series(time_vals)[pd.Series(time_vals).duplicated()]                                                # Provide the sample ID to provide the processed pertrubations with the correct output suffix                        workflow.execute_entity_task(custom_process_cmip_data, gdirs_3r_a5,                                                                         fpath_temp=ds_t_path, fpath_precip=ds_p_path,                                                                          y0=1986, y1=2073, filesuffix='', #files must start in januari                                                                         output_filesuffix=output_filesuffix)                        # print(all_prcp)                                               # opath_perturbations = os.path.join(                        #     sum_dir, f'climate_historical_perturbation_{sample_id}.nc')                        # # opath_perturbations = os.path.join(                                    # utils.compile_climate_input(gdirs_3r_a5, path=opath_perturbations, filename='climate_historical',                        #                             # input_filesuffix=f'_perturbation_{sample_id}_counterfactual',                        #                             input_filesuffix=f'_perturbation_{sample_id}',                        #                             use_compression=True)if __name__ == '__main__':    multiprocessing.set_start_method('spawn', force=True)    main()                 #%%           members = [4]models = ["CESM2"]timeframe = "monthly"ssps = ["126","370"]#"126",exp = ["IRR", "NOI"]y0=2015ye=2074# opath_climate = os.path.join(sum_dir, 'climate_historical.nc')# utils.compile_climate_input(#     gdirs_3r_a5, path=opath_climate, filename='climate_historical')remake="False"# if you get a long error log saying that "columns" can not be renamed it is often related to multiprocessingcfg.PARAMS['use_multiprocessing'] = Falsefor m, model in enumerate(models):    for member in range(members[m]):        for s, ssp in enumerate(ssps):            for e, ex in enumerate(exp):                if member >= 1: #skip 0                    sample_id = f"{model}.00{member}"                    print(sample_id, ex, "SSP",ssp)                    input_filesuffix = f"_SSP{ssp}_{ex}.00{member}"                    if ex = "IRR":                                            else:                        init_model_suffix = f'_perturbed_CESM2.00{member}'                                        workflow.execute_entity_task(tasks.run_from_climate_data, gdirs_3r_a5,                                                 ys=y0, ye=ye,  # min_ys=None,                                                 max_ys=None, fixed_geometry_spinup_yr=None,                                                 store_monthly_step=False, store_model_geometry=True,                                                 store_fl_diagnostics=True, climate_filename='gcm_data',                                                 climate_input_filesuffix=input_filesuffix,                                                 output_filesuffix=out_id,                                                 zero_initial_glacier=False, bias=0,                                                 temperature_bias=None, precipitation_factor=None,                                                 init_model_filesuffix=init_model_suffix,                                                 init_model_yr=y0_clim)  