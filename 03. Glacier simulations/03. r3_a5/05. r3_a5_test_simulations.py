# -*- coding: utf-8 -*-import oggmimport datetimefrom multiprocessing import Pool, set_start_method, get_contextfrom multiprocessing import Processimport concurrent.futuresfrom matplotlib.lines import Line2Dimport oggmfrom oggm import utils, cfg, workflow, tasks, DEFAULT_BASE_URL, graphics, global_tasksfrom oggm.core import massbalance, flowlinefrom oggm.utils import floatyear_to_date, hydrodate_to_calendardatefrom oggm.sandbox import distribute_2dfrom oggm.sandbox.edu import run_constant_climate_with_biasimport geopandas as gpdimport matplotlib.pyplot as pltimport matplotlib.cm as cmimport matplotlib.colors as clrsimport xarray as xrimport osimport seaborn as snsimport salemfrom matplotlib.ticker import FuncFormatterimport pandas as pdimport numpy as npfrom matplotlib import animationfrom IPython.display import HTML, displayimport cartopy.crs as ccrsimport cartopy.feature as cfeaturefrom scipy.optimize import curve_fitfrom tqdm import tqdmimport pickleimport textwrapimport matplotlib.patches as mpatchesimport matplotlib.lines as mlinesfrom matplotlib.colors import LinearSegmentedColormap, TwoSlopeNorm# from OGGM_data_processing import process_perturbation_dataimport sysimport datetimefunction_directory = "/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/src/03. Glacier simulations"sys.path.append(function_directory)# %% Cell 0: Set base parameterscolors_models = {    "W5E5": ["#000000"],  # "#000000"],  # Black    # Darker to lighter shades of purple    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],    # Darker to lighter shades of pink    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],    # Darker to lighter shades of orange    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],    "IPSL-CM6": ["#FFB000"]  # Dark purple to lighter shades}members = [1, 3, 4, 6, 4]members_averages = [1, 2, 3, 5]models = ["IPSL-CM6", "E3SM", "CESM2", "CNRM", "W5E5"]models_shortlist = ["IPSL-CM6", "E3SM", "CESM2", "CNRM"]timeframe = "monthly"y0_clim = 1985ye_clim = 2014y0_cf = 1901ye_cf = 1985fig_path = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/04. Figures/02. OGGM simulations/01. Modelled output/3r_a5/'# %% Cell 1: Initialize OGGM with the preferred model parameter set upfolder_path = '/Users/magaliponds/Documents/00. Programming'wd_path = f'{folder_path}/03. Modelled perturbation-glacier interactions - R13-15 A+5km2/'# os.makedirs(wd_path, exist_ok=True)cfg.initialize()cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=False)# make a sum dirsum_dir = os.path.join(wd_path, 'summary')os.makedirs(sum_dir, exist_ok=True)# make a logging directorylog_dir = os.path.join(wd_path, "log")os.makedirs(log_dir, exist_ok=True)# Make a pkl directorypkls = os.path.join(wd_path, "pkls")os.makedirs(pkls, exist_ok=True)cfg.initialize(logging_level='WARNING')cfg.PARAMS['baseline_climate'] = "GSWP3-W5E5"cfg.PARAMS['store_model_geometry'] = True# %% Load successful gdirswd_path_pkls = f'{wd_path}/pkls_subset_success/'gdirs_3r_a5 = []for filename in os.listdir(wd_path_pkls):    if filename.endswith('.pkl'):        # f'{gdir.rgi_id}.pkl')        file_path = os.path.join(wd_path_pkls, filename)        with open(file_path, 'rb') as f:            gdir = pickle.load(f)            gdirs_3r_a5.append(gdir)# # print(gdirs)# %%rgi_ids = pd.read_csv("/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/05. Support/241128 Comitted Mass Loss Rodrigo/Glacier ids/Overview_rgi_ids_all.csv", index_col=0).rgi_id# OGGM optionsoggm.cfg.PATHS['working_dir'] = utils.mkdir(wd_path_test, reset=False)oggm.cfg.PARAMS['store_model_geometry'] = True# cfg.PARAMS['use_multiprocessing'] = Truecfg.PARAMS['use_multiprocessing'] = Falsegdirs_test = workflow.init_glacier_directories(    rgi_ids,    prepro_base_url=DEFAULT_BASE_URL,    from_prepro_level=5,    prepro_border=80)stats = utils.compile_glacier_statistics(gdirs_test, filesuffix='_test', path=os.path.join(    sum_dir, "prepro_stats.csv"), inversion_only=False, apply_func=None)# %% Compile and analyse the statistics, exclude gdirs for failurestatistics = pd.read_csv(os.path.join(sum_dir, "prepro_stats.csv"))failed = statistics[statistics.run_dynamic_spinup_success == False]failed_rgi_ids = set(failed['rgi_id'])failed_rgi_ids.add("RGI60-13.36875")gdirs_test_filtered = [    gdir for gdir in gdirs_test if gdir.rgi_id not in failed_rgi_ids]# %% Cell 2c: Save gdirs_3r from OGGM as a pkl file (Save at the end of every working session)# Save each gdir individuallyfor gdir in gdirs_test_filtered:    gdir_path = os.path.join(pkls, f'{gdir.rgi_id}.pkl')    with open(gdir_path, 'wb') as f:        pickle.dump(gdir, f)# %% Cell 2d: Load gdirs_3r from pkl (fastest way to get started)# wd_path_pkls = f'{wd_path}/pkls/'gdirs_test_filtered = []for filename in os.listdir(pkls):    if filename.endswith('.pkl'):        # f'{gdir.rgi_id}.pkl')        file_path = os.path.join(pkls, filename)        with open(file_path, 'rb') as f:            gdir = pickle.load(f)            gdirs_test_filtered.append(gdir)# %%# gdir = gdirs_3r_a5[0]y0_clim = 1985ye_clim = 2014workflow.execute_entity_task(    tasks.init_present_time_glacier, gdirs_test_filtered)#         # out_id = f'_perturbed_{sample_id}_counterfactual'# # %% #run dynamic spinup# workflow.execute_entity_task(tasks.run_dynamic_spinup, gdirs_test_filtered[:100],#                               climate_input_filesuffix='',#                               spinup_period=30, #how long the spinup should run (target_yr-spinup_period)#                               spinup_start_yr=None, min_spinup_period=20, #is tried if 30 fails#                               spinup_start_yr_max=None, target_yr=None, target_value=None,#                               minimise_for='area', precision_percent=3, precision_absolute=1,#                               min_ice_thickness=None,#                               maxiter=50, output_filesuffix='_dynamic_spinup',#                               store_model_geometry=True,store_fl_diagnostics=True, store_model_evolution=True)# %%# And run the climate model with reference datacfg.PARAMS['border'] = 240workflow.execute_entity_task(tasks.run_from_climate_data, gdirs_test_filtered,                             ys=y0_clim, ye=ye_clim,                             climate_filename='climate_historical',                             output_filesuffix='_baseline_W5E5.000_test',                             init_model_filesuffix='_spinup_historical',                             init_model_yr=y0_clim, store_fl_diagnostics=True,                             )opath_base = os.path.join(    sum_dir, 'climate_run_output_baseline_W5E5.000_test.nc')df_stats = utils.compile_glacier_statistics(    # gdirs_test_filtered, filesuffix="cst_comitted_W5E5.000_test")    gdirs_test_filtered[:100], path=os.path.join(log_dir, 'stats_climate_run_W5E5.000.csv'))ds_base = utils.compile_run_output(    gdirs_test_filtered[:100], input_filesuffix='_baseline_W5E5.000_test', path=opath_base)# %%       Run random climate# gdirs_test_filtered = gdirs_test_filtered[:100]y0_comitted = 2014halfsize = 14.5out_id_climate_run = '_baseline_W5E5.000_test'out_id = '_baseline_W5E5.000_test'cfg.PARAMS['border'] = 240workflow.execute_entity_task(tasks.run_constant_climate, gdirs_test_filtered[:100],                             nyears=1000,  # nr of years to simulate                             ys=y0_comitted,  # start year of simulation                             halfsize=halfsize,  # half size applied to random climate distriubtion                             # applying the perturbation from year 1985 onward  - else try +30, starting from the moment its finished                             y0=y0_comitted-halfsize,                             ye=None, bias=0,  # bias to correction of climate data set to 0                             seed=2,  # initializing the random nr generator with number, so every time the same number applies                             # set to true if you want to store monthly output                             precipitation_factor=None, store_monthly_step=False,                             # might be useful for MB output later                             store_model_geometry=None, store_fl_diagnostics=True,                             # mb_model_class=<class 'oggm.core.massbalance.MonthlyTIModel'>,                             climate_filename='climate_historical',  # using the perturbed gcm data                             # climate_input_filesuffix='_perturbed_{}_counterfactual'.format(sample_id),                             output_filesuffix=out_id,  # adding file suffix                             init_model_filesuffix=out_id_climate_run,                             init_model_yr=y0_comitted,                             continue_on_error=True                             )df_stats = utils.compile_glacier_statistics(    # gdirs_test_filtered, filesuffix="cst_comitted_W5E5.000_test")    gdirs_test_filtered[:100], path=os.path.join(sum_dir, 'glacier_stats_comitted.csv'), filesuffix="_W5E5.000_comitted_test")opath_base = os.path.join(    sum_dir, 'climate_run_output_baseline_W5E5.000_comitted.nc')ds_base = utils.compile_run_output(    gdirs_test_filtered[:100], input_filesuffix=out_id, path=opath_base)  # gdirs_3r_a5,# %% run constant climate# gdirs_test_filtered = gdirs_test_filtered[:100]y0_comitted = 2014halfsize = 14.5out_id_climate_run = '_baseline_W5E5.000_test'out_id = '_baseline_W5E5.000_test_cst'cfg.PARAMS['border'] = 240workflow.execute_entity_task(tasks.run_constant_climate, gdirs_test_filtered[:100],                             nyears=200,  # nr of years to simulate                             ys=y0_comitted,  # start year of simulation                             halfsize=halfsize,  # half size applied to random climate distriubtion                             # applying the perturbation from year 1985 onward  - else try +30, starting from the moment its finished                             y0=y0_comitted-halfsize,                             ye=None, bias=0,  # bias to correction of climate data set to 0                             # seed=2,  # initializing the random nr generator with number, so every time the same number applies                             # set to true if you want to store monthly output                             precipitation_factor=None, store_monthly_step=False,                             # might be useful for MB output later                             store_model_geometry=None, store_fl_diagnostics=True,                             # mb_model_class=<class 'oggm.core.massbalance.MonthlyTIModel'>,                             climate_filename='climate_historical',  # using the perturbed gcm data                             # climate_input_filesuffix='_perturbed_{}_counterfactual'.format(sample_id),                             output_filesuffix=out_id,  # adding file suffix                             init_model_filesuffix=out_id_climate_run,                             init_model_yr=y0_comitted,                             continue_on_error=True                             )# %%df_stats = utils.compile_glacier_statistics(    # gdirs_test_filtered, filesuffix="cst_comitted_W5E5.000_test")    gdirs_test_filtered[:100], path=os.path.join(sum_dir, 'glacier_stats_comitted.csv'), filesuffix="_W5E5.000_comitted_test_cst")opath_base = os.path.join(    sum_dir, 'climate_run_output_baseline_W5E5.000_comitted_cst.nc')ds_base = utils.compile_run_output(    gdirs_test_filtered[:100], input_filesuffix=out_id, path=opath_base)  # gdirs_3r_a5,# %%# W5E5 centerlinesurl = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/centerlines/W5E5/RGI62/b_080/L5/summary/'# this can take some timedf = []for rgi_reg in range(13, 14, 15):    fpath = utils.file_downloader(        url + f'glacier_statistics_{rgi_reg:02d}.csv')    df.append(pd.read_csv(fpath, index_col=0, low_memory=False))df = pd.concat(df, sort=False).sort_index()# %%       Run random climate# gdirs_test_filtered = gdirs_test_filtered[:100]y0_comitted = 2014halfsize = 14.5out_id_climate_run = '_baseline_W5E5.000_test'out_id = '_baseline_W5E5.000_test_cst'cfg.PARAMS['border'] = 240workflow.execute_entity_task(tasks.run_constant_climate, gdirs_test_filtered[:100],                             nyears=1000,  # nr of years to simulate                             ys=y0_comitted,  # start year of simulation                             halfsize=halfsize,  # half size applied to random climate distriubtion                             # applying the perturbation from year 1985 onward  - else try +30, starting from the moment its finished                             y0=y0_comitted-halfsize,                             ye=None, bias=0,  # bias to correction of climate data set to 0                             # seed=2,  # initializing the random nr generator with number, so every time the same number applies                             # set to true if you want to store monthly output                             precipitation_factor=None, store_monthly_step=False,                             # might be useful for MB output later                             store_model_geometry=None, store_fl_diagnostics=True,                             # mb_model_class=<class 'oggm.core.massbalance.MonthlyTIModel'>,                             climate_filename='climate_historical',  # using the perturbed gcm data                             # climate_input_filesuffix='_perturbed_{}_counterfactual'.format(sample_id),                             output_filesuffix=out_id,  # adding file suffix                             init_model_filesuffix=out_id_climate_run,                             init_model_yr=y0_comitted,                             continue_on_error=True                             )df_stats = utils.compile_glacier_statistics(    # gdirs_test_filtered, filesuffix="cst_comitted_W5E5.000_test")    gdirs_test_filtered[:100], path=os.path.join(sum_dir, 'glacier_stats_comitted.csv'), filesuffix="_W5E5.000_comitted_test_cst")opath_base = os.path.join(    sum_dir, 'climate_run_output_baseline_W5E5.000_comitted_cst.nc')ds_base = utils.compile_run_output(    gdirs_test_filtered[:100], input_filesuffix=out_id, path=opath_base)  # gdirs_3r_a5,#%%sns.countplot(y="error_task", data=df)print("% area errors all sources: {:.2f}%".format(    df.loc[~df['error_task'].isnull()].rgi_area_km2.sum() / df.rgi_area_km2.sum() * 100))print("% failing glaciers all sources: {:.2f}%".format(    df.loc[~df['error_task'].isnull()].rgi_area_km2.count() / df.rgi_area_km2.count() * 100))dfe = df.loc[~df['error_task'].isnull()]dfe = dfe.loc[~dfe['error_task'].isin(    ['mb_calibration_from_scalar_mb', 'flowline_model_run_historical'])]"% area errors before climate: {:.2f}%".format(    dfe.rgi_area_km2.sum() / df.rgi_area_km2.sum() * 100)# 15 largest glacierslargest = df.loc[~df['error_task'].isnull()].sort_values(by='rgi_area_km2',                                                         ascending=False)[['rgi_area_km2', 'error_task',                                                                           'error_msg']].iloc[:15]df.to_csv(os.path.join(log_dir, "all_glacier_errors.csv"))# %%for sel in gdirs_test_filtered:    if sel.rgi_id == "RGI60-13.53308":        gdir = selfpath0 = gdir.get_filepath('model_geometry', filesuffix=out_id_climate_run)# opath_base = os.path.join(sum_dir, 'climate_run_output_baseline_W5E5.000_test.nc')with xr.open_dataset(fpath0) as ds:    print(ds)    # plt.plot(ds.time, ds.volume.sum(dim="rgi_id"))    # print(ds)    ## %% Check climate run output for area - why not same starting value for cf and normalfactors = [10**-9, 10**-6]# baseline_path = os.path.join(#     wd_path, "summary", filepath)# baseline = xr.open_dataset(baseline_path)subset_gdirs = gdirs_3r_a5[:100]rgi_ids_test = []for gdir in subset_gdirs:    rgi_ids_test.append(gdir.rgi_id)nan_mask = ['RGI60-13.22268', 'RGI60-13.53308',            'RGI60-13.36584', 'RGI60-13.54076', 'RGI60-14.14436',            # ipsl-Cm6            "RGI60-13.38768", "RGI60-13.49191", "RGI60-13.51721", "RGI60-13.54117",            "RGI60-13.25922", "RGI60-13.53485", "RGI60-15.09377", "RGI60-14.11611",            "RGI60-13.05827", "RGI60-13.47433", "RGI60-13.53334", "RGI60-13.44674",            "RGI60-13.37842", "RGI60-15.04860", "RGI60-15.12186", "RGI60-13.32682",            "RGI60-14.08750", "RGI60-13.37507", "RGI60-14.11573", "RGI60-13.08085",            "RGI60-15.12435", "RGI60-13.51641", "RGI60-13.11503", "RGI60-13.13300",            "RGI60-13.05562", "RGI60-13.19177", "RGI60-14.03188", "RGI60-13.12745",            "RGI60-13.38768", "RGI60-13.00585", "RGI60-13.38768", "RGI60-13.54117",            "RGI60-13.00585", "RGI60-13.38768", "RGI60-13.54117"]filtered_data = [rgi_id for rgi_id in rgi_ids_test if rgi_id in nan_mask]# for m, model in enumerate(models_shortlist):#     for i in range(members_averages[m]):#         for f, filepath in enumerate([f"climate_run_output_baseline_W5E5.000.nc", f"climate_run_output_baseline_W5E5.000_comitted.nc"]):#             sample_id=f"{model}.00{i}"#             print(sample_id)#             filepath = [f'climate_run_output_perturbed_{sample_id}.nc',#                         f'climate_run_output_perturbed_{sample_id}_comitted_test.nc'][f]#             # load and plot the data from the climate output run and counterfactual#             climate_run_opath_noirr = os.path.join(#                 sum_dir, filepath)#             if f==0:#                 index=-1#                 climate_run_output_noirr_clim = xr.open_dataset(#                     climate_run_opath_noirr).volume[index]#                 climate_run_output_noirr_clim = climate_run_output_noirr_clim.where(#                     climate_run_output_noirr_clim.rgi_id.isin(rgi_ids_test), drop=True)#             else:#                 index=0#                 climate_run_output_noirr_com = xr.open_dataset(#                     climate_run_opath_noirr).volume[index]#         dif = climate_run_output_noirr_clim-climate_run_output_noirr_com#         print(climate_run_output_noirr_clim)#         print(climate_run_output_noirr_com)#         plt.figure()#         plt.scatter(dif.rgi_id, dif*factors[0], color=colors['noirr'][0])#         plt.title(f"{sample_id} base[-1] - com[0]")#         plt.show()#         # plt.xlabel('rgi_ids')#         # plt.ylabel('volume [km$^3$]')# Create an empty list to store the rows for the final tabledata_rows = []data_rows_2 = []v = 0# Loop through models and files as per your logicfig, ax = plt.subplots(figsize=(7, 8))members_averages = [1, 5]models_shortlist = ["IPSL-CM6", "CNRM"]  # "E3SM", "CESM2",  "NorESM",for m, model in enumerate(models_shortlist):    for i in range(members_averages[m]):        # fig, ax = plt.subplots(figsize=(7, 8))        if members_averages[m] > 1:            i += 1        for f, filepath in enumerate([f"climate_run_output_baseline_W5E5.000.nc", f"climate_run_output_baseline_W5E5.000_comitted.nc"]):            markers = ["o", "o", ".", "v", "s", "x"]            sample_id = f"{model}.00{i}"            filepath = [                f'climate_run_output_perturbed_{sample_id}.nc',                f'climate_run_output_perturbed_{sample_id}_comitted_error_test.nc'            ][f]            # Load data            climate_run_opath_noirr = os.path.join(sum_dir, filepath)            if f == 0:                # index = :                climate_run_output_noirr_clim = xr.open_dataset(                    climate_run_opath_noirr)  # .volume#[index]|                # rgi_sel = "RGI60-13.22268"#"RGI60-13.53308"                clim_sel = climate_run_output_noirr_clim.where(                    climate_run_output_noirr_clim.rgi_id.isin(filtered_data), drop=True)                ax.plot(clim_sel["time"].values, clim_sel["volume"] * factors[v],                        color=colors["noirr"][0])  # , label=f"{sample_id}")                # ax.plot(clim_sel["time"][-5:].values, clim_sel["volume"].sum(dim="rgi_id")                #         [-5:] * factors[v], color=colors["noirr"][0])  # , label=f"{sample_id}")                # print(sample_id)                # print(clim_sel["time"][-1].values)                # print(clim_sel["volume"][-1].values)                data_rows.append(zip([sample_id], [clim_sel["volume"].sum(                    dim="rgi_id")[-1].values * factors[v]]))            else:                index = 0                climate_run_output_noirr_com = xr.open_dataset(                    climate_run_opath_noirr)  # .volume[index]                # "RGI60-13.28636" test no volume in clim simulation, RGI60-13.36584 for all clim sims                rgi_sel = "RGI60-13.22268"                clim_sel = climate_run_output_noirr_com.where(                    climate_run_output_noirr_com.rgi_id.isin(filtered_data), drop=True)                ax.plot(clim_sel["time"].values, clim_sel["volume"] * factors[v],                        color=colors_models[model][0])  # , label=sample_id)                # ax.plot(clim_sel["time"][0:5].values, clim_sel["volume"].sum(dim="rgi_id")[                #     0:5] * factors[v], marker=markers[i], color=colors_models[model][0], label=sample_id)                data_rows_2.append(                    zip([sample_id], [clim_sel["volume"].sum(dim="rgi_id")[0].values * factors[v]]))                final_time = clim_sel["time"][5].values                final_volume = clim_sel["volume"].sum(dim="rgi_id")[1].values                # plt.text(                #     final_time,  # x-coordinate                #     final_volume + 0.05,  # y-coordinate (slightly above the final value)                #     sample_id,  # Text to display                #     fontsize=10,                #     ha='center',  # Horizontal alignment                #     va='bottom')  # Verti                # volume_at_2014 = climate_run_output_noirr['volume'].sel(time=2014)                # # Identify where the volume is NaN                # nan_mask = volume_at_2014.isnull()                # # Get the corresponding rgi_ids where volume is NaN                # nan_rgi_ids = climate_run_output_noirr['rgi_id'].where(nan_mask, drop=True)                # # Convert to a list or array for display                # nan_rgi_ids_list = nan_rgi_ids.values.tolist()                # # Print the result                # print(sample_id, nan_rgi_ids_list)plt.legend()plt.show()output_df = pd.DataFrame(data_rows)output_df_2 = pd.DataFrame(data_rows_2)# # Save or display the resulting DataFrameoutput_csv_path = os.path.join(    wd_path, "masters", f"{rgi_sel}_differences.csv")# output_df.to_csv(output_csv_path, index=False)# Calculate difference# dif = climate_run_output_noirr_clim - climate_run_output_noirr_com# # Extract data where difference is NaN# nan_mask = np.isnan(dif)# rgi_ids_nan = climate_run_output_noirr_clim.rgi_id.where(nan_mask, drop=True)# climate_clim_nan = climate_run_output_noirr_clim.where(nan_mask, drop=True)# climate_com_nan = climate_run_output_noirr_com.where(nan_mask, drop=True)# Store the data in the list#         for rgi_id, clim_val, com_val in zip(rgi_ids_nan.values, climate_clim_nan.values, climate_com_nan.values):#             data_rows.append({#                 "sample_id": sample_id,#                 "rgi_id": rgi_id,#                 "dif_value": np.nan,#                 "noirr_clim_value": clim_val,#                 "noirr_com_value": com_val#             })# # Create a DataFrame from the collected rows# output_df = pd.DataFrame(data_rows)# # Save or display the resulting DataFrame# output_csv_path = os.path.join(wd_path, "masters", "climate_nan_differences.csv")# output_df.to_csv(output_csv_path, index=False)# Display the DataFrame to the user# import ace_tools as tools; tools.display_dataframe_to_user(name="Climate NaN Differences Dataset", dataframe=output_df)# %% Connect output for W5E5factors = [10**-9, 10**-6]# baseline_path = os.path.join(#     wd_path, "summary", filepath)# baseline = xr.open_dataset(baseline_path)subset_gdirs = gdirs_test_filtered[:100]rgi_ids_test = []for gdir in subset_gdirs:    rgi_ids_test.append(gdir.rgi_id)# nan_mask = ['RGI60-13.22268', 'RGI60-13.53308',#             'RGI60-13.36584', 'RGI60-13.54076', 'RGI60-14.14436']nan_mask = []  # ['RGI60-13.22268', 'RGI60-13.53308',# 'RGI60-13.36584', 'RGI60-13.54076', 'RGI60-14.14436']subset_gdirs = [rgi_id for rgi_id in rgi_ids_test if rgi_id not in nan_mask]wd_path = f'{folder_path}/03. Modelled perturbation-glacier interactions - R13-15 A+5km2_test/'sum_dir = f'{wd_path}/summary'# for m, model in enumerate(["W5E5"]): #models_shortlist#     for i in range(1):#members_averages[m]):#         for f, filepath in enumerate(["climate_run_output_baseline_W5E5.000_test.nc", "climate_run_output_baseline_W5E5.000_comitted.nc"]): #[f"climate_run_output_baseline_W5E5.000.nc", f"climate_run_output_baseline_W5E5.000_comitted.nc"]#             sample_id=f"{model}.00{i}"#             print(sample_id)#             # filepath = [f'climate_run_output_perturbed_{sample_id}.nc',#             #             f'climate_run_output_perturbed_{sample_id}_comitted_test.nc'][f]#             # load and plot the data from the climate output run and counterfactual#             climate_run_opath_noirr = os.path.join(#                 sum_dir, filepath)#             if f==0:#                 index=-1#                 climate_run_output_noirr_clim = xr.open_dataset(#                     climate_run_opath_noirr).volume[index]#                 climate_run_output_noirr_clim = climate_run_output_noirr_clim.where(#                     climate_run_output_noirr_clim.rgi_id.isin(rgi_ids_test), drop=True)#             else:#                 index=0#                 climate_run_output_noirr_com = xr.open_dataset(#                     climate_run_opath_noirr).volume[index]#         dif = climate_run_output_noirr_clim-climate_run_output_noirr_com#         print(climate_run_output_noirr_clim)#         print(climate_run_output_noirr_com)#         plt.figure()#         plt.scatter(dif.rgi_id, dif*factors[0], color=colors['noirr'][0])#         plt.title(f"{sample_id} base[-1] - com[0]")#         plt.show()# plt.xlabel('rgi_ids')# plt.ylabel('volume [km$^3$]')# Create an empty list to store the rows for the final table# data_rows = []# data_rows_2 = []v = 0# # Loop through models and files as per your logicfig, ax = plt.subplots(figsize=(7, 8))# members_averages = [1, 5]# models_shortlist = ["IPSL-CM6", "CNRM"]  # "E3SM", "CESM2",  "NorESM",for m, model in enumerate(["W5E5"]):  # models_shortlist    for i in range(1):  # members_averages[m]):        # fig, ax = plt.subplots(figsize=(7, 8))        if members_averages[m] > 1:            i += 1        for f, filepath in enumerate([f"climate_run_output_baseline_W5E5.000_test.nc", f"climate_run_output_baseline_W5E5.000_comitted_cst.nc"]):            markers = ["o", "o", ".", "v", "s", "x"]            sample_id = f"{model}.00{i}"            # filepath = [            #     f'climate_run_output_perturbed_{sample_id}.nc',            #     f'climate_run_output_perturbed_{sample_id}_comitted_error_test.nc'            # ][f]            # Load data            climate_run_opath_noirr = os.path.join(sum_dir, filepath)            if f == 0:                # index = :                climate_run_output_noirr_clim = xr.open_dataset(                    climate_run_opath_noirr)  # .volume#[index]|                # rgi_sel = "RGI60-13.22268"#"RGI60-13.53308"                clim_sel = climate_run_output_noirr_clim                # .where(                #     ~climate_run_output_noirr_clim.rgi_id.isin(nan_mask), drop=True)                ax.plot(clim_sel["time"].values, clim_sel["volume"].sum(dim='rgi_id') * factors[v],                        color=colors["noirr"][0])  # , label=f"{sample_id}")                # ax.plot(clim_sel["time"][-5:].values, clim_sel["volume"].sum(dim="rgi_id")                #         [-5:] * factors[v], color=colors["noirr"][0])  # , label=f"{sample_id}")                # print(sample_id)                # print(clim_sel["time"][-1].values)                # print(clim_sel["volume"][-1].values)                # data_rows.append(zip([sample_id], [clim_sel["volume"].sum(                #     dim="rgi_id")[-1].values * factors[v]]))            else:                index = 0                climate_run_output_noirr_com = xr.open_dataset(                    climate_run_opath_noirr)  # .volume[index]                # "RGI60-13.28636" test no volume in clim simulation, RGI60-13.36584 for all clim sims                # rgi_sel = "RGI60-13.22268"                clim_sel = climate_run_output_noirr_com.where(                    ~climate_run_output_noirr_com.rgi_id.isin(nan_mask), drop=True)                ax.plot(clim_sel["time"].values, clim_sel["volume"].sum(dim='rgi_id') * factors[v],                        color=colors["noirr"][1])  # , label=sample_id)                # ax.plot(clim_sel["time"][0:5].values, clim_sel["volume"].sum(dim="rgi_id")[                #     0:5] * factors[v], marker=markers[i], color=colors_models[model][0], label=sample_id)                # data_rows_2.append(                #     zip([sample_id], [clim_sel["volume"].sum(dim="rgi_id")[0].values * factors[v]]))                # final_time = clim_sel["time"][5].values                # final_volume = clim_sel["volume"].sum(dim="rgi_id")[1].values                # plt.text(                #     final_time,  # x-coordinate                #     final_volume + 0.05,  # y-coordinate (slightly above the final value)                #     sample_id,  # Text to display                #     fontsize=10,                #     ha='center',  # Horizontal alignment                #     va='bottom')  # Verti                # volume_at_2014 = climate_run_output_noirr['volume'].sel(time=2014)                # # Identify where the volume is NaN                # nan_mask = volume_at_2014.isnull()                # # Get the corresponding rgi_ids where volume is NaN                # nan_rgi_ids = climate_run_output_noirr['rgi_id'].where(nan_mask, drop=True)                # # Convert to a list or array for display                # nan_rgi_ids_list = nan_rgi_ids.values.tolist()                # # Print the result                # print(sample_id, nan_rgi_ids_list)ax.set_ylim(0, 220)plt.legend()plt.show()# output_df = pd.DataFrame(data_rows)# output_df_2 = pd.DataFrame(data_rows_2)# # # Save or display the resulting DataFrame# output_csv_path = os.path.join(# %% Check climate run output for area - for new test run without perturbations# %% Test error id volume and length evolution# log_path = os.path.join(#     log_dir, f'stats_perturbed_{sample_id}_comitted_random.csv')# log_path_cf = os.path.join(#     log_dir, f'stats_perturbed_{sample_id}_comitted_random_counterfactual.csv')log_errors = os.path.join(log_dir, f'error_ids_dates_cf.csv')log = pd.read_csv(log_errors)for r, rgiid in enumerate(log.rgi_id):    sample_id = "IPSL-CM6.000"    test_value = f"RGI60-{rgiid}"    selected_gdir = list(        filter(lambda gd: gd is not None and gd.rgi_id == test_value, gdirs_3r_a5))    print(selected_gdir)    if not selected_gdir:        print("error:", rgiid)    else:        workflow.execute_entity_task(            tasks.init_present_time_glacier, selected_gdir)  # gdirs_3r_a5)        # calculate length of run based on run failure year and starting date        nyears = log.year[r]-2014        print(nyears)        nyears = max(5, nyears)        # out_id = f'_perturbed_{sample_id}_counterfactual'        out_id = f'_perturbed_{sample_id}_committed_random_test_evolution_cf'        out_id_climate_run = f'_perturbed_{sample_id}'        workflow.execute_entity_task(tasks.run_random_climate, selected_gdir,  # gdirs_3r_a5,                                     nyears=nyears,  # nr of years to simulate                                     ys=y0_comitted,  # start year of simulation                                     halfsize=halfsize,  # half size applied to random climate distriubtion                                     y0=y0_comitted-halfsize,                                     ye=None, bias=0,  # bias to correction of climate data set to 0                                     seed=2,  # initializing the random nr generator with number, so every time the same number applies                                     precipitation_factor=None, store_monthly_step=False,                                     store_model_geometry=True, store_fl_diagnostics=True,                                     climate_filename='gcm_data',  # using the perturbed gcm data                                     # climate_input_filesuffix='_perturbed_{}_counterfactual'.format(sample_id),                                     climate_input_filesuffix='_perturbed_{}'.format(                                         sample_id),                                     output_filesuffix=out_id,  # adding file suffix                                     init_model_filesuffix=out_id_climate_run,                                     init_model_yr=y0_comitted,                                     continue_on_error=True  # the year of the initial run you wnat to start from                                     )        # opath = os.path.join(        #     # sum_dir, f'climate_run_output_perturbed_{sample_id}_counterfactual.nc')        #     sum_dir, f'climate_run_output_perturbed_{sample_id}_comitted_random_evolution_test_{rgiid}.nc')        # log_path = os.path.join(        #     log_dir, f'stats_perturbed_{sample_id}_comitted_random_evolution_test_{rgiid}.csv')        # ds_ptb = utils.compile_run_output(        #     selected_gdir, path=opath, input_filesuffix=out_id)  # gdirs_3r_a5, compile the run output        # df_stats = utils.compile_glacier_statistics(        #     selected_gdir, path=log_path)# %% Plot the output datalog_errors = os.path.join(log_dir, f'error_ids_dates_cf.csv')log = pd.read_csv(log_errors)cmap = plt.get_cmap('tab20', 20)colors = [cmap(i) for i in range(20)]for var in ['length_m', 'area_m2', 'volume_m3']:    fig, axes = plt.subplots(2, 2)    axes = axes.flatten()    for i, rgiid in enumerate(log.rgi_id.values):        ax = axes[i]        sample_id = log.model.values[i]        test_value = f"RGI60-{rgiid}"        gdir = list(filter(lambda gd: gd is not None and gd.rgi_id ==                           test_value, gdirs_3r_a5))        if not gdir:            print(f"{rgiid} error:", gdir)        else:            gdir = gdir[0]            with xr.open_dataset(gdir.get_filepath('model_diagnostics', filesuffix='_perturbed_{}_committed_random_test_evolution_cf'.format(sample_id))) as ds:                # with xr.open_dataset(gdir.get_filepath('model_diagnostics', filesuffix='_perturbed_{}_counterfactual'.format(sample_id))) as ds:                # Load the data into a dataframe                ds = ds.load()  # isel(time=slice(0, -1)).load()            try:                ds[var].plot(                    ax=ax, color=colors[i])            except Exception as e:                print(e)            with xr.open_dataset(gdir.get_filepath('model_diagnostics', filesuffix='_baseline_W5E5.000_committed')) as ds:                # with xr.open_dataset(gdir.get_filepath('model_diagnostics', filesuffix='_baseline_W5E5.000')) as ds:                # Load the data into a dataframe                ds = ds.load()  # isel(time=slice(0, -1)).load()            try:                ds[var].plot(ax=ax,                             linestyle='dotted', color=colors[i])            except Exception as e:                print(e)            with xr.open_dataset(gdir.get_filepath('model_diagnostics', filesuffix='_perturbed_{}_committed_random_counterfactual'.format("CESM2.000"))) as ds:                # with xr.open_dataset(gdir.get_filepath('model_diagnostics', filesuffix='_perturbed_{}_counterfactual'.format("CESM2.000"))) as ds:                # Load the data into a dataframe                ds = ds.load()  # isel(time=slice(0, -1)).load()            try:                ds[var].plot(ax=ax,                             linestyle='dashed', color=colors[i])            except Exception as e:                print(e)    # ax.set_xlim([2014, 2250])    solid_line = mlines.Line2D(        [], [], color='grey', linestyle='solid', label=sample_id)    dashed_line = mlines.Line2D(        [], [], color='grey', linestyle='dashed', label="CESM2.000")    dotted_line = mlines.Line2D(        [], [], color='grey', linestyle='dotted', label='W5E%.000')    # Add legend to figure    fig.legend(handles=[solid_line, dashed_line, dotted_line],               loc='lower center', bbox_to_anchor=(0.5, -0.1), ncols=3)    for ax in axes:        ax.label_outer()    # ax.set_title('Area No Irrigation')    plt.show()# %%log_errors = os.path.join(log_dir, f'error_ids_dates_cf.csv')log = pd.read_csv(log_errors)cmap = plt.get_cmap('tab20', 20)colors = [cmap(i) for i in range(20)]for var in ['prcp', 'temp']:    fig, axes = plt.subplots(2, 2, figsize=(10, 5))    axes = axes.flatten()    for i, rgiid in enumerate(log.rgi_id.values):        ax = axes[i]        ax.set_xlim([datetime.datetime(1985, 1, 1),                    datetime.datetime(2014, 1, 1)])        sample_id = log.model.values[i]        test_value = f"RGI60-{rgiid}"        gdir = list(filter(lambda gd: gd is not None and gd.rgi_id ==                           test_value, gdirs_3r_a5))        if not gdir:            print(f"{rgiid} error:", gdir)        else:            gdir = gdir[0]            # with xr.open_dataset(gdir.get_filepath('climate_historical', filesuffix='_baseline_W5E5.000_committed_random')) as ds:            # with xr.open_dataset(gdir.get_filepath('gcm_data', filesuffix='_perturbed_{}_committed_random_test_evolution'.format(sample_id))) as ds:            with xr.open_dataset(gdir.get_filepath('gcm_data', filesuffix='_perturbed_{}'.format(sample_id))) as ds:                # Load the data into a dataframe                ds = ds.load()  # isel(time=slice(0, -1)).load()            try:                ds[var].plot(                    ax=ax, color='red')  # colors[i])            except Exception as e:                print(e)            # with xr.open_dataset(gdir.get_filepath('gcm_data', filesuffix='_perturbed_{}_committed_random'.format("CESM2.000"))) as ds:            with xr.open_dataset(gdir.get_filepath('gcm_data', filesuffix='_perturbed_{}'.format("CESM2.000"))) as ds:                # Load the data into a dataframe                ds = ds.load()  # isel(time=slice(0, -1)).load()            try:                ds[var].plot(ax=ax,                             color='pink')  # colors[i])            except Exception as e:                print(e)            with xr.open_dataset(gdir.get_filepath('climate_historical', filesuffix='')) as ds:                # Load the data into a dataframe                ds = ds.load()  # isel(time=slice(0, -1)).load()            try:                ds[var].plot(ax=ax,                             linestyle='dotted', color='black')  # colors[i])            except Exception as e:                print(e)            # ax.set_xlim([1985, 2014])    solid_line = mlines.Line2D(        [], [], color='red', linestyle='solid', label=sample_id)    dashed_line = mlines.Line2D(        [], [], color='pink', linestyle='solid', label="CESM2.000")    dotted_line = mlines.Line2D(        [], [], color='black', linestyle='dotted', label='W5E%.000')    # Add legend to figure    fig.legend(handles=[solid_line, dashed_line, dotted_line],               loc='lower center', bbox_to_anchor=(0.5, -0.1), ncols=3)    for ax in axes:        ax.label_outer()    # ax.set_title('Area No Irrigation')    plt.show()