# -*- coding: utf-8 -*-# %% Cell 0: Load data packages#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Wed Jul  3 15:36:52 2024@author: magalipondsThis script runs makes plots of the selected 3 regions (13-14-15) with Areas larger than 5km2 (3r_a5)"""# -*- coding: utf-8 -*-import oggm# from OGGM_data_processing import process_perturbation_data# import mpl_axes_alignerimport concurrent.futuresfrom shapely.geometry import LineString, MultiLineStringimport astimport stringfrom matplotlib.lines import Line2Dimport oggmfrom oggm import utils, cfg, workflow, tasks, DEFAULT_BASE_URL, graphics, global_tasksfrom oggm.core import massbalance, flowlinefrom oggm.utils import floatyear_to_date, hydrodate_to_calendardatefrom oggm.sandbox import distribute_2dfrom oggm.sandbox.edu import run_constant_climate_with_biasimport geopandas as gpdimport matplotlib.pyplot as pltimport matplotlib.cm as cmimport matplotlibimport matplotlib.colors as clrsfrom matplotlib.colors import ListedColormap, BoundaryNormfrom matplotlib.patches import ConnectionPatchimport xarray as xrimport osimport seaborn as snsimport salemfrom matplotlib.ticker import FuncFormatterimport pandas as pdimport numpy as npfrom matplotlib import animationfrom IPython.display import HTML, displayimport matplotlib.pyplot as pltimport cartopy.crs as ccrsimport cartopy.feature as cfeatureimport geopandas as gpdimport pandas as pdfrom scipy.optimize import curve_fitfrom scipy import statsfrom matplotlib.legend_handler import HandlerTuplefrom matplotlib.colors import LightSourcefrom tqdm import tqdmimport pickleimport sysimport textwrapimport matplotlib.patches as mpatchesimport matplotlib.lines as mlinesfrom matplotlib.colors import LinearSegmentedColormap, TwoSlopeNorm, Normalize, ListedColormapfrom mpl_toolkits.axes_grid1.inset_locator import inset_axesfrom shapely.geometry import Pointimport matplotlib.gridspec as gridspecfrom cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTERfrom matplotlib.patches import Rectangle, ConnectionPatch# function_directory = "/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/src/03. Glacier simulations"# sys.path.append(function_directory)# %% Cell 1: Set base parameters# colors = {#     "irr": ["#000000", "#777777"],#     "noirr": ["#6363FF", "#B1B1FF"],#     # much lighter versions of noirr colors#     "noirr_com": ["#A6A6FF", "#E0E0FF"],#     # much lighter grey fade of irr colors#     "irr_com": ["#C0C0C0", "#E0E0E0"],#     "cf": ["#FF5722", "#FFA780"],#     "Yellow": ["#FFC107", "#FFE08A"]# }xkcd_colors = clrs.XKCD_COLORScolors = {    "irr": ["#000000", "#555555"],  # Black and dark gray    # Darker brown and golden yellow for contrast    # "noirr": ["#f5bf03","#fbeaac"],#["#8B5A00", "#D4A017"], #fdde6c    "noirr": ["dimgrey","darkgrey"],#["#8B5A00", "#D4A017"], #fdde6c    # "noirr_com": ["#E3C565", "#F6E3B0"],  # Lighter, distinguishable tan shades #    "noirr_com": ["#380282", "#ceaefa"],  # Lighter, distinguishable tan shades #    "irr_com": ["#B5B5B5", "#D0D0D0"],  # Light gray, no change    "cf": ["#004C4C", "#40E0D0"],    "cf_com": ["#008B8B", "#40E0D0"],    "cline": ["dimgrey", '#380282']}region_colors = {13: 'blue', 14: 'crimson', 15: 'orange'}colors_models = {    "W5E5": ["#000000"],  # "#000000"],  # Black    # Darker to lighter shades of purple    "E3SM": ["#785EF0", "#8F7BF1", "#A6A8F2"],    # Darker to lighter shades of pink    "CESM2": ["#DC267F", "#E58A9E", "#F0A2B6", "#F7BCC4"],    # Darker to lighter shades of orange    "CNRM": ["#FE6100", "#FE7D33", "#FE9A66", "#FEB799", "#FECDB5", "#FEF1E1"],    "IPSL-CM6": ["#FFB000"],    "NorESM": ["#FFC107", "#FFE08A"]  # Dark purple to lighter shades}members = [1, 3, 4, 6, 4, 1]members_averages = [1, 2, 3, 5, 3]models = ["IPSL-CM6", "E3SM", "CESM2", "CNRM", "NorESM", "W5E5"]models_shortlist = ["IPSL-CM6", "E3SM", "CESM2", "CNRM", "NorESM"]timeframe = "monthly"y0_clim = 1985ye_clim = 2014fig_path = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/04. Figures/99. Final Figures/'# fig_path = '/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/04. Figures/02. OGGM simulations/01. Modelled output/3r_a5/'folder_path = '/Users/magaliponds/Documents/00. Programming'wd_path = f'{folder_path}/03. Modelled perturbation-glacier interactions - R13-15 A+5km2/'sum_dir = os.path.join(wd_path, 'summary')# %% Cell 1b: Load gdirswd_path_pkls = f'{wd_path}/pkls_subset_success/'gdirs_3r_a5 = []for filename in os.listdir(wd_path_pkls):    if filename.endswith('.pkl'):        # f'{gdir.rgi_id}.pkl')        file_path = os.path.join(wd_path_pkls, filename)        with open(file_path, 'rb') as f:            gdir = pickle.load(f)            gdirs_3r_a5.append(gdir)# %% Cell 3a: Plot the specific mass balances using boxplots, different subsets, weighted by region - print median# Function to plot the boxplotsdef plot_boxplot(data, position, label, color, alpha, is_noirr, offset):    bp = ax.boxplot(data, patch_artist=True, labels=label if is_noirr else [""],  # only set labels for Noirr                    vert=False, widths=0.7,                    boxprops=dict(facecolor=color, alpha=alpha,                                  edgecolor='none'),                    medianprops=dict(color='black', linewidth=2),                    positions=[position], showfliers=False, zorder=2)    # Get the median value from the boxplot    median_value = bp['medians'][0].get_xdata()[0]    ax.text(median_value + 100, position, f'{median_value:.1f}',  # Place above for Irr            va='center', ha='center', fontsize=10, color='black', fontweight='bold',            # bbox=dict(boxstyle='round,pad=0.001',            #           facecolor='white', edgecolor='none'),            zorder=3)    return bp# Initialize plotfig, ax = plt.subplots(figsize=(10, 10))df = pd.read_csv(    f"{wd_path}masters/master_gdirs_r3_a5_rgi_date_A_V_RGIreg_B.csv")# df = pd.read_csv(#     f"{wd_path}masters/master_gdirs_r3_a5_rgi_date_A_V_RGIreg_B_hugo.csv")master_ds = df[(~df['sample_id'].str.endswith('0')) |  # Exclude all the model averages ending with 0 except for IPSL               (df['sample_id'].str.startswith('IPSL'))]# Normalize values# divide all the B values with 1000 to transform to m w.e. average over 30 yrs# master_ds[['B_noirr', 'B_irr', 'B_delta']] /= 1000master_ds = master_ds[['rgi_id', 'rgi_region', 'rgi_subregion', 'full_name', 'cenlon', 'cenlat', 'rgi_date',                       'rgi_area_km2', 'rgi_volume_km3', 'sample_id', 'B_noirr', 'B_irr', 'B_delta_irr', 'B_cf', 'B_delta_cf']]# Define custom aggregation functions for grouping over the 11 member dataaggregation_functions = {    'rgi_region': 'first',    'rgi_subregion': 'first',    'full_name': 'first',    'cenlon': 'first',    'cenlat': 'first',    'rgi_date': 'first',    'rgi_area_km2': 'first',    'rgi_volume_km3': 'first',    'B_noirr': 'mean',    'B_irr': 'mean',    'B_delta_irr': 'mean',    'B_cf': 'mean',    'B_delta_cf': 'mean',    'sample_id': 'first'}master_ds_avg = master_ds.groupby(['rgi_id'], as_index=False).agg({  # calculate the 11 member average for noirr and delta, for irr the first value can be taken as they are all the same    'B_delta_irr': 'mean',    'B_delta_cf': 'mean',    'B_noirr': 'mean',    'B_cf': 'mean',    # lamda is anonmous functions, returns 11 member average    'sample_id': lambda _: "11 member average",    # take first value for all columns that are not in the list    **{col: 'first' for col in master_ds.columns if col not in ['B_noirr', 'B_delta', 'sample_id']}})# Aggregate dataset, area-weighted BDelta Birr and Bnoirr,master_ds_area_weighted = master_ds_avg.groupby(['rgi_subregion'], as_index=False).agg({    'B_delta_irr': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_delta_cf': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_irr': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_noirr': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_cf': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'rgi_area_km2': 'sum',  # Sum for area    'rgi_volume_km3': 'sum',  # Sum for volume    # 'sample_id': lambda _: "11 member average",    # take first value for all columns that are not in the list    **{col: 'first' for col in master_ds.columns if col not in ['B_noirr', 'B_irr', 'B_delta', 'sample_id', 'rgi_area_km2', 'rgi_volume_km3']}})use_weights = True# Define regions and subregions to loop throughregions = [13, 14, 15]subregions = [9, 3, 3]  # Subregions count for each regionregion_colors = {13: 'blue', 14: 'crimson', 15: 'orange'}v_space_noi = 0.8  # Vertical space between irr and noirr boxplotsv_space_irr = 1.6  # Vertical space between irr and noirr boxplots# Storage for combined dataall_noirr, all_irr = [], []position_counter = 1cumulative_index = 14# Example usage: Main loop through regions and subregionsfor r, region in enumerate(reversed(regions)):    for sub in reversed(range(list(reversed(subregions))[r])):        # Filter subregion-specific data        subregion_ds = master_ds_avg[master_ds_avg['rgi_subregion'].str.contains(            f"{region}.0{sub+1}")]        # Calculate mean values for Noirr and Irr        noirr_mean = master_ds_area_weighted['B_noirr'][cumulative_index]        irr_mean = master_ds_area_weighted['B_irr'][cumulative_index]        # Set color and label based on the region        # color = region_colors[region]        label = [f"{region}-0{sub+1}"]        # Plot Noirr and Irr boxplots        # box_cf = plot_boxplot(            # subregion_ds['B_cf'], position_counter, "", color=colors['cf'][0], alpha=0.5, is_noirr=False)        box_noirr = plot_boxplot(            subregion_ds['B_noirr'], position_counter + v_space_noi, label, color=colors['noirr'][0], alpha=0.5, is_noirr=True, offset=0.8)        box_irr = plot_boxplot(            subregion_ds['B_irr'], position_counter + v_space_irr, label="", color=colors['irr'][0], alpha=0.5, is_noirr=False, offset=-0.8)        # Annotate the number of glaciers and delta between the two columns        num_glaciers = len(subregion_ds)        delta = noirr_mean - irr_mean        # Display number of glaciers and delta        plt.text(850, position_counter + (v_space_noi / 2),                 f'{num_glaciers} ',  # \nΔ = {delta:.2f}',                 va='center', ha='center', fontsize=10, color='black',                 backgroundcolor="white", fontstyle="italic", zorder=1)        # Increment position counter for the next subregion        position_counter += 4        cumulative_index -= 1overall_area_weighted_mean = {    'B_delta_irr': (master_ds_avg['B_delta_irr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_irr': (master_ds_avg['B_irr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_noirr': (master_ds_avg['B_noirr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_delta_cf': (master_ds_avg['B_delta_cf'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_cf': (master_ds_avg['B_irr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'total_area_km2': master_ds_avg['rgi_area_km2'].sum(),  # Total area sum    # Total volume sum    'total_volume_km3': master_ds_avg['rgi_volume_km3'].sum()}# Plot overall average boxplots for Irr and Noirr# avg_cf = plot_boxplot(master_ds_avg['B_cf'], position_counter, [    # "Average"], color=colors['cf'][1], alpha=1, is_noirr=False)avg_noi = plot_boxplot(master_ds_avg['B_noirr'], position_counter + v_space_noi, [    "Average"], color=colors['noirr'][1], alpha=1, is_noirr=True, offset=0.8)avg_irr = plot_boxplot(master_ds_avg['B_irr'],  position_counter +                       v_space_irr, "", color=colors['irr'][1], alpha=1, is_noirr=False,offset=-0.8)# Annotate the number of glaciers for the overall averageplt.text(850, position_counter + (v_space_noi / 2), f'{len(master_ds_avg)}',  # Display total number of glaciers         va='center', ha='center', fontsize=10, color='black',         fontstyle='italic', backgroundcolor="white", zorder=1)plt.text(850, position_counter + 2, "# of glaciers",  # Plot number of glaciers title         va='center', ha='center', fontsize=10, color='black', fontstyle='italic', backgroundcolor="white", zorder=1)# Create custom legend elements for mean (dot) and median (stripe)mean_dot = Line2D([0], [0], marker='o', color='w',                  label='Area-weighted Mean (dot)', markerfacecolor='black', markersize=10)median_stripe = Line2D([0], [0], color='black', lw=2, label='Median (stripe)')# Add a legend for regions, mean (dot), and median (stripe)region_legend_patches = [mpatches.Patch(color=colors['irr'][1], label='AllForcings'),                         mpatches.Patch(                             color=colors['noirr'][1], label='NoIrr'),                         # mpatches.Patch(                             # color=colors['cf'][1], label='NoForcings'),                         ]# Append the custom legend items for the mean dot and median striperegion_legend_patches += [median_stripe]# Create the legend with the updated patchesfig.legend(handles=region_legend_patches, loc='center right',           bbox_to_anchor=(1.25, 0.5), ncols=1)# ax.legend(handles=region_legend_patches, loc='lower center',#           bbox_to_anchor=(0.5, -0.15), ncols=3)ax.axvline(x=0, color='black', linestyle='--', linewidth=1, zorder=0)ax.set_xlabel('Mean B_noirr and B_irr')ax.set_ylabel('Regions and Subregions')ax.set_xlim(-1350, 1000)# Extend the ylims for more paddingy_min, y_max = ax.get_ylim()  # Get current y-axis limitspadding = 1  # Adjust this value as neededax.set_ylim(y_min - padding, y_max + padding)# Adjust layout and display the plotplt.tight_layout()fig_folder = os.path.join(fig_path, "03. Mass Balance", "Boxplot")os.makedirs(fig_folder, exist_ok=True)plt.savefig(    f"{fig_folder}/Gaussian_distribution_total_region_by_region_median.png")plt.show()# %% Cell 4b: Plot the specific mass balances using boxplots, different subsets, weighted by region - print area weighted mean# Initialize plotfig, ax = plt.subplots(figsize=(10, 10))df = pd.read_csv(    f"{wd_path}masters/master_gdirs_r3_a5_rgi_date_A_V_RGIreg_B.csv")# df = pd.read_csv(#     f"{wd_path}masters/master_gdirs_r3_a5_rgi_date_A_V_RGIreg_B_hugo.csv")master_ds = df[(~df['sample_id'].str.endswith('0')) |  # Exclude all the model averages ending with 0 except for IPSL               (df['sample_id'].str.startswith('IPSL'))]# Normalize values# divide all the B values with 1000 to transform to m w.e. average over 30 yrs# master_ds[['B_noirr', 'B_irr', 'B_delta']] /= 1000master_ds = master_ds[['rgi_id', 'rgi_region', 'rgi_subregion', 'full_name', 'cenlon', 'cenlat', 'rgi_date',                       'rgi_area_km2', 'rgi_volume_km3', 'sample_id', 'B_noirr', 'B_irr', 'B_delta_irr', 'B_cf', 'B_delta_cf']]master_ds_avg = master_ds.groupby(['rgi_id'], as_index=False).agg({  # calculate the 11 member average for noirr and delta, for irr the first value can be taken as they are all the same    'B_delta_irr': 'mean',    'B_noirr': 'mean',    # lamda is anonmous functions, returns 11 member average    'sample_id': lambda _: "11 member average",    # take first value for all columns that are not in the list    **{col: 'first' for col in master_ds.columns if col not in ['B_noirr', 'B_delta', 'sample_id']}})# Aggregate dataset, area-weighted BDelta Birr and Bnoirr,master_ds_area_weighted = master_ds_avg.groupby(['rgi_subregion'], as_index=False).agg({    'B_delta_irr': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_irr': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_delta_cf': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_cf': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'B_noirr': lambda x: (x * master_ds.loc[x.index, 'rgi_area_km2']).sum() / master_ds.loc[x.index, 'rgi_area_km2'].sum(),    'rgi_area_km2': 'sum',  # Sum for area    'rgi_volume_km3': 'sum',  # Sum for volume    # 'sample_id': lambda _: "11 member average",    # take first value for all columns that are not in the list    **{col: 'first' for col in master_ds.columns if col not in ['B_noirr', 'B_irr', 'B_delta_irr', 'B_cf', 'B_delta_cf', 'sample_id', 'rgi_area_km2', 'rgi_volume_km3']}})use_weights = True# Define regions and subregions to loop throughregions = [13, 14, 15]subregions = [9, 3, 3]  # Subregions count for each regionregion_colors = {13: 'blue', 14: 'crimson', 15: 'orange'}v_space_noirr = 0.75  # Vertical space between irr and noirr boxplotsv_space_irr = 1.5  # Vertical space between irr and noirr boxplots# Storage for combined dataall_noirr, all_irr = [], []position_counter = 1def plot_boxplot_awm(data, mean_value, position, label, color, alpha, is_noirr, offset):    # Create the boxplot    box = ax.boxplot(data, patch_artist=True, labels=label if is_noirr else [""],  # Only set labels for Noirr                     vert=False, widths=0.7,                     boxprops=dict(facecolor=color, alpha=alpha,                                   edgecolor='none'),                     medianprops=dict(color='black'),                     positions=[position], showfliers=False, zorder=2)    # Plot black dot at the mean position    # 'ko' for black dot ('k' = black, 'o' = dot)    ax.plot(mean_value, position, 'ko', zorder=3)    # Annotate text: above the boxplot for Irr, below for Noirr    print(mean_value)    plt.text(mean_value, position-offset, f'{mean_value:.1f}',  # Place above for Irr             va='center', ha='center', fontsize=10, color='black', fontweight="bold",             # bbox=dict(boxstyle='round,pad=0.001',             #           facecolor='white', edgecolor='none'),             zorder=3)    return boxcumulative_index = 14# Example usage: Main loop through regions and subregionsfor r, region in enumerate(reversed(regions)):    for sub in reversed(range(list(reversed(subregions))[r])):        # Filter subregion-specific data        print(region)        print(sub)        # print(sub+subregions[r]-1)        subregion_ds = master_ds_avg[master_ds_avg['rgi_subregion'].str.contains(            f"{region}.0{sub+1}")]        # Calculate mean values for Noirr and Irr        noirr_mean = master_ds_area_weighted['B_noirr'][cumulative_index]        irr_mean = master_ds_area_weighted['B_irr'][cumulative_index]        # cf_mean = master_ds_area_weighted['B_cf'][cumulative_index]        # Set color and label based on the region        color = region_colors[region]        label = [f"{region}-0{sub+1}"]        # Plot Noirr and Irr boxplots        # box_cf = plot_boxplot_awm(            # subregion_ds['B_cf'].values, cf_mean, position_counter, label, color=colors["cf"][1], alpha=1, is_noirr=False)        box_noirr = plot_boxplot_awm(            subregion_ds['B_noirr'].values, noirr_mean, position_counter + v_space_noirr, label, color=colors["noirr"][1], alpha=1, is_noirr=True, offset=0.8)        box_irr = plot_boxplot_awm(            subregion_ds['B_irr'], irr_mean, position_counter + v_space_irr, "", color=colors["irr"][1], alpha=1.0, is_noirr=False,offset=-0.8)        # Annotate the number of glaciers and delta between the two columns        num_glaciers = len(subregion_ds)        delta = noirr_mean - irr_mean        # Display number of glaciers and delta        plt.text(850, position_counter + (v_space_noirr / 2),                 f'{num_glaciers} ',  # \nΔ = {delta:.2f}',                 va='center', ha='center', fontsize=10, color='black',                 backgroundcolor="white", fontstyle="italic", zorder=1)        # Increment position counter for the next subregion        position_counter += 3        cumulative_index -= 1overall_area_weighted_mean = {    'B_delta_irr': (master_ds_avg['B_delta_irr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_irr': (master_ds_avg['B_irr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_noirr': (master_ds_avg['B_noirr'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_delta_cf': (master_ds_avg['B_delta_cf'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'B_cf': (master_ds_avg['B_cf'] * master_ds_avg['rgi_area_km2']).sum() / master_ds_avg['rgi_area_km2'].sum(),    'total_area_km2': master_ds_avg['rgi_area_km2'].sum(),  # Total area sum    # Total volume sum    'total_volume_km3': master_ds_avg['rgi_volume_km3'].sum()}# Plot overall average boxplots for Irr and Noirr# avg_cf = plot_boxplot_awm(master_ds_avg['B_cf'], overall_area_weighted_mean['B_cf'], position_counter +                          # v_space_noirr, ["Average"], color=colors['cf'][1], alpha=1, is_noirr=True)avg_noirr = plot_boxplot_awm(master_ds_avg['B_noirr'], overall_area_weighted_mean['B_noirr'], position_counter, [    "High\nMountain\nAsia"], color=colors['noirr'][1], alpha=1, is_noirr=True, offset=0.8)avg_irr = plot_boxplot_awm(master_ds_avg['B_irr'], overall_area_weighted_mean['B_irr'], position_counter +                           v_space_noi, "", color=colors['irr'][1], alpha=1.0, is_noirr=False, offset=-0.8)# Annotate the number of glaciers for the overall averageplt.text(850, position_counter + (v_space_noirr / 2), f'{len(master_ds_avg)}',  # Display total number of glaciers         va='center', ha='center', fontsize=10, color='black',         fontstyle='italic', backgroundcolor="white", zorder=1)plt.text(850, position_counter + 2, "# of glaciers",  # Plot number of glaciers title         va='center', ha='center', fontsize=10, color='black', fontstyle='italic', backgroundcolor="white", zorder=1)# Create custom legend elements for mean (dot) and median (stripe)mean_dot = Line2D([0], [0], marker='o', color='w',                  label='Area-weighted mean (dot)', markerfacecolor='black', markersize=10)median_stripe = Line2D([0], [0], color='black', lw=2, label='Median (stripe)')# Add a legend for regions, mean (dot), and median (stripe)region_legend_patches = [mpatches.Patch(color=colors['irr'][1], label='Historic (W5E5)'),                         mpatches.Patch(                             color=colors['noirr'][1], label='Historic NoIrr'),                         # mpatches.Patch(                         #     color=colors['cf'][1], label='NoForcings'),                         ]# Append the custom legend items for the mean dot and median striperegion_legend_patches += [mean_dot]# Create the legend with the updated patchesfig.legend(handles=region_legend_patches, loc='lower center',          ncols=3, bbox_to_anchor=(0.5, -0.02))# ax.legend(handles=region_legend_patches, loc='lower center',#           bbox_to_anchor=(0.5, -0.15), ncols=3)l=0for label in ax.get_yticklabels():    if l==30:        label.set_fontweight('bold')    l+=1ax.axvline(x=0, color='black', linestyle='--', linewidth=1, zorder=0)ax.set_xlabel('Mean B [mm yr$^{-1}$]')ax.set_ylabel('Regions and Subregions')ax.set_xlim(-1350, 1000)# Extend the ylims for more paddingy_min, y_max = ax.get_ylim()  # Get current y-axis limitspadding = 1  # Adjust this value as neededax.set_ylim(y_min - padding, y_max + padding)        # Adjust layout and display the plotplt.tight_layout()fig_folder = os.path.join(fig_path, "03. Mass Balance", "Boxplot")os.makedirs(fig_folder, exist_ok=True)plt.savefig(    f"{fig_folder}/Gaussian_distribution_total_region_by_region_areaweighted_mean.png")plt.show()    #%% Cell 5: Prepare data for reference comparisondef draw_std_boxplot(ax, x, y, yerr, box_width=0.5, color='gray', ls='-', alpha=0.4, edgecolor='black', label='', show_mean_dot=True, dot_kwargs=None, ):    """    Draws a simplified boxplot: a box from (mean - std) to (mean + std).        Parameters:        ax         : matplotlib Axes object to draw on        x, y       : arrays of x and mean y values        yerr       : array of standard deviations (same length as y)        box_width  : width of the box (in x-units)        color      : fill color of the box        alpha      : transparency of the box        edgecolor  : edge color of the box        show_mean_dot : if True, plot the mean as a dot        dot_kwargs : dict of kwargs for the mean dot style    """    if dot_kwargs is None:        dot_kwargs = dict(color='black', zorder=3)    x0=0    for xi, yi, si in zip(x, y, yerr):        if x0==0:            label=label        else:            label="_nolegend_"        x0+=1        rect = mpatches.Rectangle(            (xi - box_width / 2, yi - si),  # bottom-left corner            box_width,            2 * si,            linewidth=0,            edgecolor=edgecolor,            facecolor=color,            alpha=alpha, label=label        )        ax.add_patch(rect)        if show_mean_dot:            ax.hlines(yi,                      xi - box_width/2 ,                      xi + box_width /2, color=color, lw=3, ls=ls)            area_rgi_year = 2007ref_path ="/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/01. Input files/04. Reference Data"dussaillant_b_file = f"{ref_path}/Dussaillant_DOI-WGMS-FoG-2025-02/data/mass_balance.csv"    dussaillant_mb = pd.read_csv(dussaillant_b_file, index_col=0)dussaillant_id_file = f"{ref_path}/Dussaillant_DOI-WGMS-FoG-2025-02/data/glacier.csv"    dussaillant_id = pd.read_csv(dussaillant_id_file, index_col=0)zemp_file_1314 = f"{ref_path}/Zemp_etal_DataTables1a-t_results_clusters/Zemp_etal_results_cluster_13&14.csv"    zemp_file_1315 = f"{ref_path}/Zemp_etal_DataTables1a-t_results_clusters/Zemp_etal_results_cluster_13&15.csv"    zemp_file_13 = f"{ref_path}/Zemp_etal_DataTables2a-t_results_regions_global/Zemp_etal_results_region_13_ASC.csv"zemp_file_14 = f"{ref_path}/Zemp_etal_DataTables2a-t_results_regions_global/Zemp_etal_results_region_14_ASW.csv"zemp_file_15 = f"{ref_path}/Zemp_etal_DataTables2a-t_results_regions_global/Zemp_etal_results_region_15_ASE.csv"ds_zemp_1314 = pd.read_csv(zemp_file_1314, skiprows=16) # annual: annual mass-balance variability (m w.e. yr-1)ds_zemp_1315 = pd.read_csv(zemp_file_1315, skiprows=16)def area_weighted_avg(group):    return np.average(group[' AW_mwe'], weights=group[' Area_AW_ref_km2'])ds_zemp_13 = pd.read_csv(zemp_file_13, skiprows=27) # annual: annual mass-balance variability (m w.e. yr-1)ds_zemp_14 = pd.read_csv(zemp_file_14, skiprows=27)ds_zemp_15 = pd.read_csv(zemp_file_15, skiprows=27) # annual: annual mass-balance variability (m w.e. yr-1)ds_zemp_reg = pd.concat([ds_zemp_13, ds_zemp_14, ds_zemp_15])ds_zemp_tot_reg = ds_zemp_reg.groupby('Year').apply(area_weighted_avg).reset_index(name='annual_mya')  # create area weighted mean by year over the three regionsds_zemp_tot_reg[' annual_mya'] = np.average(ds_zemp_reg[' AW_mwe']) #calculate multi-year averagesds_zemp_tot_reg[' sig_annual_mya'] = np.average(ds_zemp_reg [' sig_Glac_mwe'])#calculate multi-year averagesds_zemp_tot_reg[' annual_mya_ref'] = np.average(ds_zemp_reg[ds_zemp_reg['Year'].between(2000, 2019)][' AW_mwe'])#calculate multi-year averagesds_zemp_tot_reg[' sig_annual_mya_ref'] = np.average(ds_zemp_reg[ds_zemp_reg['Year'].between(2000, 2019)][' sig_Glac_mwe'])#calculate multi-year averagesds_zemp_tot_area = sum((ds_zemp_reg[ds_zemp_reg['Year']==area_rgi_year])[' Area_AW_ref_km2']) #calculate multi-year averagesds_zemp_tot = pd.concat([ds_zemp_1314, ds_zemp_1315]).groupby(['Year']).mean().reset_index("Year")ds_zemp_tot[' annual_mya'] = np.average(ds_zemp_tot[' annual'])ds_zemp_tot[' sig_annual_mya'] = np.average(ds_zemp_tot [' sig_annual'])ds_zemp_tot[' annual_mya_ref'] = np.average(ds_zemp_tot[ds_zemp_tot['Year'].between(2000, 2019)][' annual'])ds_zemp_tot[' sig_annual_mya_ref'] = np.average(ds_zemp_tot[ds_zemp_tot['Year'].between(2000, 2019)][' sig_annual'])# ds_zemp_1314 = ds_zemp_1314[ds_zemp_1314['Year']>=1985] # annual: annual mass-balance variability (m w.e. yr-1)# ds_zemp_tot = pd.concat([ds_zemp_1315,ds_zemp_1314]).groupby(['Year'], as_index=False).sum()glambie_path = f"{ref_path}/GlaMBIE_Data_DOI_10.5904_wgms-glambie-2024-07/glambie_results_20240716/calendar_years"glambie_ds_13 = pd.read_csv(f"{glambie_path}/13_central_asia.csv")glambie_ds_14 = pd.read_csv(f"{glambie_path}/14_south_asia_west.csv")glambie_ds_15 = pd.read_csv(f"{glambie_path}/15_south_asia_east.csv")glambie_tot = pd.concat([glambie_ds_13,glambie_ds_14,glambie_ds_15])#.groupby(['start_dates'], as_index=False).sum()def weighted_avg(group, value_col, weight_col='glacier_area'):    return np.average(group[value_col], weights=group[weight_col])# Apply to multiple columnsglambie_weighted = glambie_tot.groupby('start_dates').apply(    lambda g: pd.Series({        'combined_mwe': weighted_avg(g, 'combined_mwe'),        'combined_mwe_errors': weighted_avg(g, 'combined_mwe_errors')    })).reset_index()#calculate multi year average for glambieglambie_weighted['combined_mwe_mya'] = np.average(glambie_weighted['combined_mwe'])glambie_weighted['combined_mwe_errors_mya'] = np.average(glambie_weighted['combined_mwe_errors'])glambie_weighted['total_area'] = glambie_tot.groupby('start_dates')['glacier_area'].sum().valuesglambie_weighted['combined_mwe_mya_ref'] = np.average(glambie_weighted[glambie_weighted['start_dates'].between(2000, 2019)]['combined_mwe'])glambie_weighted['combined_mwe_errors_mya_ref'] = np.average(glambie_weighted[glambie_weighted['start_dates'].between(2000, 2019)]['combined_mwe_errors'])oggm_hugo_ds = pd.read_csv(f"{wd_path}masters/master_gdirs_r3_a5_rgi_date_A_V_RGIreg_B_hugo.csv") df = oggm_hugo_ds.dropna(subset=['rgi_area_km2', 'errB_hugo','B_hugo', 'B_irr', 'B_noirr'])df_hugo = pd.read_csv(f"{wd_path}masters/master_hugo_only_all_glaciers_13_14_15.csv").rename(columns={'B': 'B_hugo','errB': 'errB_hugo'})i_path_base = os.path.join(sum_dir, 'specific_massbalance_timeseries_W5E5.000.csv')i_path_base_ext = os.path.join(sum_dir, 'specific_massbalance_timeseries_extended_W5E5.000.csv')mb_base = pd.read_csv(i_path_base).rename(columns={'Mass_Balance':'B_irr'})mb_base_ext = pd.read_csv(i_path_base_ext).rename(columns={'Mass_Balance':'B_irr_ref'})mb_base['Year'] = mb_base['Year'].str.strip('[]').str.split().apply(lambda x: np.array(x, dtype=int)).apply(tuple)mb_base['B_irr'] = mb_base['B_irr'].str.strip('[]').str.split().apply(lambda x: np.array(x, dtype=float)).apply(tuple)mb_base_filtered = mb_base[mb_base['Year'].str.len() == mb_base['B_irr'].str.len()].copy()mb_base_filtered = mb_base_filtered.drop_duplicates(subset=['Year', 'B_irr']).copy()mb_base_exploded = mb_base_filtered.explode(['Year', 'B_irr']).reset_index(drop=True)mb_base_ext['Year'] = mb_base_ext['Year'].str.strip('[]').str.split().apply(lambda x: np.array(x, dtype=int)).apply(tuple)mb_base_ext['B_irr_ref'] = mb_base_ext['B_irr_ref'].str.strip('[]').str.split().apply(lambda x: np.array(x, dtype=float)).apply(tuple)mb_base_filtered_ext = mb_base_ext[mb_base_ext['Year'].str.len() == mb_base_ext['B_irr_ref'].str.len()].copy()mb_base_filtered_ext = mb_base_filtered_ext.drop_duplicates(subset=['Year', 'B_irr_ref']).copy()mb_base_exploded_ext = mb_base_filtered_ext.explode(['Year', 'B_irr_ref']).reset_index(drop=True)area_df = df[['rgi_id', 'rgi_area_km2']].drop_duplicates()mb_base_exploded = mb_base_exploded.merge(area_df, on='rgi_id', how='left')mb_base_exploded_ext = mb_base_exploded_ext.merge(area_df, on='rgi_id', how='left')mb_base_exploded = mb_base_exploded.set_index(['rgi_id','Year']).to_xarray()mb_base_exploded_ext = mb_base_exploded_ext.set_index(['rgi_id','Year']).to_xarray()mb_base_exploded['rgi_area_km2'] = mb_base_exploded['rgi_area_km2'].isel(Year=0)mb_base_exploded_ext['rgi_area_km2'] = mb_base_exploded_ext['rgi_area_km2'].isel(Year=0)weighted_B_irr_ts = (mb_base_exploded['B_irr'] * mb_base_exploded['rgi_area_km2']).sum(dim='rgi_id') / mb_base_exploded['rgi_area_km2'].sum(dim='rgi_id')/1000weighted_B_irr_ref_ts = (mb_base_exploded_ext['B_irr_ref'] * mb_base_exploded_ext['rgi_area_km2']).sum(dim='rgi_id') / mb_base_exploded_ext['rgi_area_km2'].sum(dim='rgi_id')/1000# # Calculate weighted meansweighted_errB_hugo = np.average(df_hugo['errB_hugo'], weights=df_hugo['Area'])weighted_B_hugo = np.average(df_hugo['B_hugo'], weights=df_hugo['Area'])weighted_B_irr = np.average(df['B_irr'], weights=df['rgi_area_km2'])/1000weighted_B_noirr = np.average(df['B_noirr'], weights=df['rgi_area_km2'])/1000# Load dussaillant dataref_path ="/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/01. Input files/04. Reference Data"dussaillant_b_file = f"{ref_path}/Dussaillant_DOI-WGMS-FoG-2025-02/data/mass_balance.csv"    dussaillant_mb = pd.read_csv(dussaillant_b_file, index_col=0)[['glacier_name','glacier_id', 'year', 'annual_balance','area']]dussaillant_id_file = f"{ref_path}/Dussaillant_DOI-WGMS-FoG-2025-02/data/glacier.csv"    dussaillant_id = pd.read_csv(dussaillant_id_file, index_col=0)dussaillant_rgiid = dussaillant_id#[['id','rgi60_ids', 'gtng_region']]dussaillant_rgiid.rename(columns={'id': 'glacier_id', 'rgi60_ids': 'rgi_id'}, inplace=True)dussaillant_merged = pd.merge(dussaillant_mb, dussaillant_rgiid, on='glacier_id')dussaillant_merged['gtng_region'] = dussaillant_merged['gtng_region'].astype(str)dussaillant_merged['area']=dussaillant_merged['area']*(10**-6)filtered_df = dussaillant_merged[    dussaillant_merged['gtng_region'].str.startswith(('13', '14', '15'))]#.set_index(['year', 'glacier_id']).to_xarray()# filtered_df = filtered_df[filtered_df['glacier_id'] != 971]filtered_df = filtered_df[filtered_df['glacier_id'] != 18251]weighted_B_dus_ts = (    filtered_df    .groupby('year')    .apply(lambda g: (g['annual_balance'] * g['area']).sum() / g['area'].sum())    .reset_index(name='awm_B'))mean_per_glacier = filtered_df.groupby('glacier_id')['annual_balance'].mean()mean_B_dus = weighted_B_dus_ts.mean()weighted_B_dus_ref = weighted_B_dus_ts[weighted_B_dus_ts['year'].between(2000, 2019)]#oggm: irr and noirr mass balane 1985-2014 30 yr average m w.e. yr-1 #%% Process Hugonnet data#some csvfiles might require dezippingbase_path="/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/04. Reference/01. Climate data/Hugonnet/"reg_13 = pd.read_csv(f"{base_path}Hugonnet_time_series_13/dh_13_rgi60_pergla_rates.csv", usecols=['rgiid', 'period', 'area', 'dhdt', 'err_dhdt'])reg_14 = pd.read_csv(f"{base_path}Hugonnet_time_series_14/dh_14_rgi60_pergla_rates.csv", usecols=['rgiid', 'period', 'area', 'dhdt', 'err_dhdt'])reg_15 = pd.read_csv(f"{base_path}Hugonnet_time_series_15/dh_15_rgi60_pergla_rates.csv", usecols=['rgiid', 'period', 'area', 'dhdt', 'err_dhdt'])dfs_hugo = [reg_13, reg_14, reg_15]total_df_hugo = pd.concat(dfs_hugo)total_area = total_df_hugo['area'].sum()total_df_hugo[['start_date', 'end_date']] = total_df_hugo['period'].str.split('_', expand=True)total_df_hugo['start_date'] = pd.to_datetime(total_df_hugo['start_date'])total_df_hugo['end_date'] = pd.to_datetime(total_df_hugo['end_date'])# Filter for exactly 1-year differencetotal_df_hugo_1yr = total_df_hugo[((total_df_hugo['end_date'] - total_df_hugo['start_date']).dt.days >= 365) &             ((total_df_hugo['end_date'] - total_df_hugo['start_date']).dt.days <= 366)]total_df_hugo_1yr = total_df_hugo_1yr[total_df_hugo_1yr['area']>=5*(10**6)]def weighted_avg(group, value_col, weight_col='area'):    return np.average(group[value_col], weights=group[weight_col])avg_df_hugo = total_df_hugo_1yr.groupby('period', as_index=False).apply(    lambda g: pd.Series({        'dhdt':weighted_avg(g, 'dhdt'),        'err_dhdt': weighted_avg(g, 'err_dhdt'),    })).reset_index()avg_df_hugo =avg_df_hugo[['dhdt','err_dhdt']]*0.917 #multiply with the ice densitybase_path="/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/04. Reference/01. Climate data/Hugonnet/"avg_df_hugo.to_csv(f"{base_path}/Hugonnet_Area_Weighted_Timeseries.csv")weighted_B_hugo = avg_df_hugo[['dhdt','err_dhdt']].mean()#%% Cell 8b Plot figure comparison reference datafig,axes=plt.subplots(2,1, figsize=(15,7.5), sharex=True) axes = axes.flatten()years_hugo=np.arange(2000,2020)#Include Hugonnet - only has multi year averages, errors communicated over this 20yr period axes[0].plot(years_hugo, np.ones(len(years_hugo))*weighted_B_hugo['dhdt'], color='crimson',  lw=3, linestyle=':', label="Hugonnet et al., reg 13-15, A>5km$^{2}$, avg., ref period",zorder=10)draw_std_boxplot(axes[0],years_hugo, np.ones(len(years_hugo))*weighted_B_hugo['dhdt'], np.ones(len(years_hugo))*weighted_B_hugo['err_dhdt']/20, box_width=1,  color='crimson', ls='-', alpha=0.4, label="Hugonnet et al., reg 13-15, A>5km$^{2}$, std, ref period")axes[1].plot(years_hugo, avg_df_hugo['dhdt'], color='crimson', ls='-', lw=3, label="Hugonnet et al., reg 13-15, A>5km$^{2}$, avg., ref period")#Include zemp - include mean+ errors as boxplot over study timeperiod, then mean line across reference period (20002019) and finally timeline in panel belowdraw_std_boxplot(axes[0], ds_zemp_tot_reg.Year, ds_zemp_tot[' annual_mya'], ds_zemp_tot_reg[' sig_annual_mya'], box_width=1, color='blue', ls='-',alpha=0.3, label="Zemp et al. std, reg 13-15")axes[0].plot( ds_zemp_tot_reg[ds_zemp_tot_reg['Year'].between(2000, 2019)].Year, ds_zemp_tot_reg[ds_zemp_tot['Year'].between(2000, 2019)][' annual_mya_ref'], color='blue', ls=':',lw=3, label="Zemp et al., reg 13-15 avg, ref period", zorder=100)axes[1].plot(ds_zemp_tot_reg.Year, ds_zemp_tot_reg['annual_mya'], color='blue', ls='-',label="Zemp et al., reg 13-15, avg", lw=2) #ds_zemp_tot[' sig_annual'], box_width=1, #Include GLamBIE data  - include mean+ errors as boxplot over study timeperiod, then mean line across reference period (20002019) and finally timeline in panel belowdraw_std_boxplot(axes[0], glambie_weighted.start_dates, glambie_weighted['combined_mwe_mya'], glambie_weighted['combined_mwe_errors_mya'], box_width=1, color='orange', alpha=0.3, label="GlaMBIE, reg. 13-15")axes[0].plot(glambie_weighted[glambie_weighted['start_dates'].between(2000, 2019)].start_dates, np.ones(20)*glambie_weighted[glambie_weighted['start_dates'].between(2000, 2019)].combined_mwe.mean(), color='orange', ls=':', lw=4, label="GlamBIE et al., 2024",zorder=10)axes[1].plot(glambie_weighted.start_dates, glambie_weighted['combined_mwe'], color='orange', ls='-', lw=3, label="GlamBIE et al., 2024")# axes.plot(glambie_ds_13.start_dates,glambie_ds_13.combined_mwe, color=region_colors[13], ls=":",marker= ".",label="GlaMBIE, reg 13")# axes.plot(glambie_ds_14.start_dates,glambie_ds_14.combined_mwe, color=region_colors[14], ls=":", marker= ".",label="GlaMBIE, reg 14")# axes.plot(glambie_ds_15.start_dates,glambie_ds_15.combined_mwe, color=region_colors[15], ls=":", marker= ".",label="GlaMBIE, reg 15")#Include dussaillant data axes[0].plot(weighted_B_dus_ts.year, np.ones(len(weighted_B_dus_ts))*weighted_B_dus_ts['awm_B'].mean(), color='turquoise', ls='-', lw=3, label="Dussaillant et al., 2025")axes[0].plot(weighted_B_dus_ref.year, np.ones(len(weighted_B_dus_ref))*weighted_B_dus_ref['awm_B'].mean(), color='turquoise', ls=':', lw=3, label="Dussaillant et al., 2025")axes[1].plot(weighted_B_dus_ts.year, weighted_B_dus_ts['awm_B'], color='turquoise', ls='-', lw=3, label="Dussaillant et al., 2025")# axes.plot( [1985,2013], np.ones(2)*weighted_B_irr, color=colors['irr'1][0], ls='--', label="Modelled Historic (W5E5), reg 13-15, A>5km$^{2}$")# draw_std_boxplot(axes, weighted_B_irr_ts.Year, weighted_B_irr_ts.values, np.zeros(len(weighted_B_irr)), box_width=1, color='grey', ls='-',alpha=0.4, label="Modelled Historic (W5E5), reg 13-15, A>5km$^{2}$")# axes.plot(weighted_B_irr_ts.Year, weighted_B_irr_ts.values, color=colors['irr'][0], ls='-', label="Modelled Historic (W5E5), reg 13-15, A>5km$^{2}$")axes[0].plot(weighted_B_irr_ts.Year, np.ones(len(weighted_B_irr_ts))*weighted_B_irr_ts.mean().values, color=colors['irr'][0], ls='-', lw=3, label="Modelled Historic (W5E5), reg 13-15, A>5km$^{2}$")# axes.plot(weighted_B_irr_ref_ts.Year, weighted_B_irr_ref_ts.values, color=colors['irr'][0], ls='--', label="Modelled Historic ref (W5E5), reg 13-15, A>5km$^{2}$")axes[0].plot(weighted_B_irr_ref_ts.Year, np.ones(len(weighted_B_irr_ref_ts))*weighted_B_irr_ref_ts.mean().values, color=colors['irr'][0], ls=':', lw=3, label="Modelled Historic ref (W5E5), reg 13-15, A>5km$^{2}$, ref period")axes[1].plot(weighted_B_irr_ts.Year, weighted_B_irr_ts.values, color=colors['irr'][0], ls='-', lw=2, label="Modelled Historic ref (W5E5), reg 13-15, A>5km$^{2}$ avg.,  ref period")# axes.plot( [1985,2014], np.ones(2)*weighted_B_noirr, color=colors['noirr'][0], ls='--', label="Modelled Historic NoIrr (W5E5), reg 13-15, A>5km$^{2}$")axes[0].set_title('Multi year average')axes[1].set_title('Annual timeseries')dataset_legend = [    mpatches.Patch(facecolor='crimson', label='Hugonnet et al.'),    mpatches.Patch(facecolor='orange', label='GlaMBIE'),    mpatches.Patch(facecolor='blue', label='Zemp et al.'),    mpatches.Patch(facecolor='turquoise', label='Dussaillant et al.'),    mpatches.Patch(facecolor=colors['irr'][0], label='"Modelled Historic ref (W5E5)}$'),#, reg 13-15, A>5km$^{2]# Legend for line styles (gray lines)style_legend = [    Line2D([0], [0], color='grey', lw=5, alpha=0.5, label='Average ± std'),  # thick grey    Line2D([0], [0], color='grey', lw=2, ls=':', label='Average (2000–2019)'),   # dotted    Line2D([0], [0], color='grey', lw=2, ls='-', label='Average (full period)'), # solid]# Combine both legendsall_legend_items = dataset_legend + style_legend# Add to the figure (adjust location as needed)legend1 = fig.legend(    handles=dataset_legend,    loc='lower center',    bbox_to_anchor=(0.5,-0.15 ),    ncol=5,    frameon=False,    fontsize=12)# Second row legend: line styleslegend2 = fig.legend(    handles=style_legend,    loc='lower center',    bbox_to_anchor=(0.5, -0.20),    ncol=3,    frameon=False,    fontsize=12)# Optional: make space for both legend rowsfig.subplots_adjust(bottom=0)area_glambie = round(glambie_weighted[glambie_weighted['start_dates'] == float(area_rgi_year)]['total_area'].values[0])area_hugo = round(df_hugo.Area.sum())area_dus = round(filtered_df.groupby('glacier_id')['area'].first().sum())basis=-0.7amp=3.5area_oggm = round(df[df['sample_id']=='CESM2.000'].rgi_area_km2.sum())axes[1].text(1957, basis-0*amp, 'Total Area (km$^2$):',fontsize=14, fontweight='bold')axes[1].text(1957, basis-0.05*amp, f'Zemp et al.: {round(ds_zemp_tot_area)} ({area_rgi_year})',fontsize=14)axes[1].text(1957, basis-0.1*amp, f'GlaMBIE.: {area_glambie} ({area_rgi_year})',fontsize=14)axes[1].text(1957, basis-0.15*amp, f'Hugonne et al.: {area_hugo} (rgi date)',fontsize=14)axes[1].text(1957, basis-0.2*amp, f'Dussaillant et al.: {area_dus} (date ?)',fontsize=14, color='red')axes[1].text(1957, basis-0.25*amp, f'Modelled area: {area_oggm} (rgi date)',fontsize=14)axes[0].set_ylabel("∆B m w.e. yr$^{-1}$")axes[1].set_ylabel("∆B m w.e. yr$^{-1}$")axes[1].set_xlabel("Year")# fig.legend(loc='lower center', bbox_to_anchor=(0.5,-0.2), ncols =2)fig.subplots_adjust(wspace=0.05)plt.xlim(1956,2024)plt.show()plt.savefig(f'{fig_path}/Ref_B_Comparison_Figure.png')            #%% Plot location of reference data if availablenorm = matplotlib.colors.TwoSlopeNorm(vmin=oggm_hugo_ds['B_hugo'].min(),                             vcenter=0,                             vmax=oggm_hugo_ds['B_hugo'].max())fig, ax = plt.subplots(figsize=(12, 8))# sns.scatterplot(data=oggm_hugo_ds, x='cenlon', y='cenlat',#                 size='Area', hue='B_hugo', alpha=1, sizes=(10, 200),palette='RdBu')scatter = ax.scatter(    x=oggm_hugo_ds['cenlon'],    y=oggm_hugo_ds['cenlat'],    c=oggm_hugo_ds['B_hugo'],    s=oggm_hugo_ds['Area'] /5,  # adjust size scaling as needed    cmap='RdBu',    norm=norm,    alpha=0.9, label='Hugonnet')filtered_df = dussaillant_merged[    dussaillant_merged['gtng_region'].str.startswith(('13', '14', '15'))]scatter_dus = ax.scatter(x=filtered_df['longitude'], y=filtered_df['latitude'],                c='black', s=filtered_df['area']/5, alpha=1, label='Dussaillant')#, sizes=(10, 200))plt.colorbar(scatter, ax=ax,  label='B_hugo')hugonnet_legend = mlines.Line2D([], [], color='gray', marker='o', linestyle='None',                                markersize=10, label='Hugonnet (colored by B_hugo)')dussaillant_legend = mlines.Line2D([], [], color='black', marker='o', linestyle='None',                                   markersize=10, label='Dussaillant')ax.legend(handles=[hugonnet_legend, dussaillant_legend])#%%mean_balance = filtered_df['annual_balance'].mean(dim='year')mean_area = filtered_df['area'].mean(dim='year')mean_lon = filtered_df['longitude'].mean(dim='year')mean_lat = filtered_df['latitude'].mean(dim='year')plt.figure(figsize=(6,4))scatter_dus = plt.scatter(x=mean_lon, y=mean_lat,                c=mean_balance, s=mean_area, alpha=1, label='Dussaillant', norm=norm, cmap='RdBu')#, sizes=(10, 200))plt.colorbar(scatter_dus, label='B_dusaillant')plt.legend()