""" This script runs the OGGM step by step guide to a preprocessed directory"""#%% Cell 1: Load the required directoriesimport oggmfrom oggm import cfg, utils, workflow, tasks, DEFAULT_BASE_URLimport geopandas as gpdimport numpy as npimport osfrom oggm.shop import rgitopofrom oggm import GlacierDirectoryfrom oggm.core import massbalance, flowline# Libsimport xarray as xrimport matplotlib.pyplot as pltimport matplotlib.cm as cmfrom oggm.shop import cru, w5e5from oggm.tasks import process_w5e5_dataimport matplotlib.pyplot as pltfrom oggm import graphicsimport pandas as pdimport loggingimport shutilimport argparseimport timeimport loggingimport json#%% Cell 1: Initiate OGGM using own climate datadef initiate_OGGM(timeframe, model, member, reset, wd_path, y0):    cfg.initialize(logging_level='WARNING')    cfg.PARAMS['baseline_climate']='CUSTOM'                # Open working directory (where OGGM will write its output)    if model=="W5E5":        cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=reset)    else:        cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=False)        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"    cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.{y0}_2014.{timeframe}.perturbed.climate.input.degC.nc"        return    #%% Print iput datamodel="W5E5"member="0"timeframe="monthly"y0 = 1901base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"ds = xr.open_dataset(f"{base_folder_in}/{model}.00{member}.{y0}_2014.{timeframe}.perturbed.climate.input.degC.nc")print(ds.prcp.values)#%% Cell 2: Create a function to compile glacier stats for baseline climatedef compile_statistics(sample_id, sum_dir):        opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    utils.compile_glacier_statistics(gdirs, path=opath_g)    opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))    utils.compile_climate_statistics(gdirs, path=opath_c)    opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))    utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_b)        return#%% Cell 2b: Function to plot statisticsdef plot_glacier_stats(sample_id, sum_dir):    opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))    opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))    opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))        glacier_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_g))    climate_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_c))    massbalance_stats=xr.Dataset.from_dataframe(pd.read_csv(opath_b).reset_index().rename(columns={'index':'year'}))    for (i,rgi_id) in enumerate(rgi_ids):        plot = plt.plot(massbalance_stats.year[79:]+1901, massbalance_stats[f'{rgi_id}'][79:], color=colors[i])               #print the years of climate info available        # y0=gdirs[i].get_climate_info()['baseline_yr_0']        # ye=gdirs[i].get_climate_info()['baseline_yr_1']+1        # print(y0, ye)    return plot#%% Cell 9: Create a functio to add new files to basenamesdef add_to_basenames(basename, filename, docstr=''):    """Add an entry to the list of BASENAMES.    BASENAMES are access keys to files available at the gdir level.    Parameters    ----------    basename : str        the key (e.g. 'dem', 'model_flowlines')    filename : str        the associated filename (e.g. 'dem.tif', 'model_flowlines.pkl')    docstr : str        the associated docstring (for documentation)    """    global BASENAMES    if '.' not in filename:        raise ValueError('The filename needs a proper file suffix!')    cfg.BASENAMES[basename] = (filename, docstr)# cfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')   #%% Cell 7: conduct dynamic spinup def run_dynamic_spinup(sum_dir, gdirs, sample_id, y0, ye):            dynamic_spinup = "area/dmdtda"    err_dmdtda_scaling_factor=0.2    # dynamic_spinup_start_year=y0        # if y0 > dynamic_spinup_start_year:    #     dynamic_spinup_start_year = y0        minimise_for = dynamic_spinup.split('/')[0]    ### CHECK IF IT CREATES A NEW FILE IN GLACIER DIRECTORY    melt_f_max = cfg.PARAMS['melt_f_max']    workflow.execute_entity_task(        tasks.run_dynamic_melt_f_calibration, gdirs,        err_dmdtda_scaling_factor=err_dmdtda_scaling_factor,        ys=y0, ye=ye, #ye must be 2020 to match Hugonnet        melt_f_max=melt_f_max,        kwargs_run_function={'minimise_for': minimise_for},        ignore_errors=True,        kwargs_fallback_function={'minimise_for': minimise_for},        output_filesuffix='_dynamic_spinup_{}'.format(sample_id))    # Now compile the output    opath = os.path.join(sum_dir,'spinup_historical_run_output_{}.nc'.format(sample_id))    utils.compile_run_output(gdirs, path=opath,                             input_filesuffix='_dynamic_spinup_{}'.format(sample_id))        # Glacier statistics we recompute here for error analysis    opath = os.path.join(sum_dir, 'spinup_glacier_statistics_{}.csv'.format(sample_id))    utils.compile_glacier_statistics(gdirs, path=opath)    return#%% Cell 8: Provide modelling parameters for OGGM# Use W5E5 data# folder_path='/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/05. OGGM Working Directories'folder_path='/Users/magaliponds/Documents/00. Programming'wd_path=f'{folder_path}/06. Modelled perturbation-glacier interactions/'y0_clim=1985ye_clim=2014y0_spinup=1980ye_spinup=2020cmap=cm.get_cmap('bone')colors=[cmap(i / 9) for i in range(10)]# Specify the RGI region you are interested in, for example, region 13 (Central Asia)rgi_reg = '13'  # this must fit to example glacier(s), if starting from level 0rgi_ids = ["RGI60-13.40102", # Area >10km2    "RGI60-13.39195", # Area >10km2    "RGI60-13.36881", # Area >10km2    "RGI60-13.38969", # Area >10km2    "RGI60-13.37184", # Area >10km2    "RGI60-13.00967", # Area <10km2    "RGI60-13.40982", # Area <10km2    "RGI60-13.41891", # WGMS observation    "RGI60-13.23659", # WGMS observation] base_url = ('https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5/')prepro_level=3sum_dir=os.path.join(wd_path, 'summary')#Provide output names:#%% Cell 9: Run Dyanmic spinupmembers=[1,3,4,6,1]models = ["W5E5","E3SM","CESM2","CNRM","IPSL-CM6"]timeframe="monthly"download_gdirs=Falsereset=False    years = np.arange(y0_clim, ye_clim)         cfg.initialize(logging_level='WARNING')cfg.PARAMS['baseline_climate']='CUSTOM'cfg.PATHS['working_dir'] = utils.mkdir(wd_path, reset=reset)for m, model in enumerate(["W5E5"]):    for i in range(1):            #Create a sample-id tag to list model restuls        sample_id= f"{model}.00{i}" #provide label for all run output                #initiate the model with custom climate data (model-member combination)        # Dowload or reopen the gdirs        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"        cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1901_2014.{timeframe}.perturbed.climate.input.degC.nc"        if download_gdirs==True:            gdirs = workflow.init_glacier_directories(rgi_ids, from_prepro_level=prepro_level, prepro_base_url=base_url)        else:            gdirs = workflow.init_glacier_directories(rgi_ids)        os.makedirs(sum_dir, exist_ok=True)            utils.compile_task_log(gdirs)                    # Process the climate data        workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs, output_filesuffix=f'_{sample_id}_ext') #process climate data for all gdirs            #run the model with the baseline            #perform one run to compare to the old behaviour        workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                                 min_ys=y0_clim, ye=ye_clim,                                 output_filesuffix='_historical_reference')        # Now compile the output        opath = os.path.join(sum_dir, f'historical_run_output_{sample_id}.nc')        utils.compile_run_output(gdirs, path=opath, input_filesuffix='_historical_reference')            workflow.execute_entity_task(tasks.run_dynamic_spinup, gdirs,                                      init_model_filesuffix=None, init_model_yr=None,                                      init_model_fls=None, climate_input_filesuffix=f'_{sample_id}_ext',                                      evolution_model=None, mb_model_historical=None,                                      mb_model_spinup=None, spinup_period=20, spinup_start_yr=None,                                      min_spinup_period=10, spinup_start_yr_max=None,                                      target_yr=None, target_value=None, minimise_for='area',                                      precision_percent=20, #precision_absolute=1,                                      min_ice_thickness=None, first_guess_t_bias=-2,                                      t_bias_max_step_length=2, maxiter=30,                                      output_filesuffix='_dynamic_spinup',                                      store_model_geometry=True, store_fl_diagnostics=True,                                      store_model_evolution=True, ignore_errors=False,                                      return_t_bias_best=False, ye=None,                                      model_flowline_filesuffix='',                                      add_fixed_geometry_spinup=False)        dynamic_spinup = "area/dmdtda"        err_dmdtda_scaling_factor=0.2        melt_f_max = cfg.PARAMS['melt_f_max']        workflow.execute_entity_task(            tasks.run_dynamic_melt_f_calibration, gdirs,            err_dmdtda_scaling_factor=err_dmdtda_scaling_factor,            ys=1901, ye=2020, #ye must be 2020 to match Hugonnet            melt_f_max=melt_f_max,            kwargs_run_function={'minimise_for': 'area'},            ignore_errors=True,            kwargs_fallback_function={'minimise_for': 'area'},            output_filesuffix='_dynamic_spinup_{}'.format(sample_id))        # Now compile the output                opath = os.path.join(sum_dir,'spinup_historical_run_output_{}.nc'.format(sample_id))        utils.compile_run_output(gdirs, path=opath,                                 input_filesuffix='_dynamic_spinup_{}'.format(sample_id))                opath_g = os.path.join(sum_dir, 'glacier_statistics_ref_{}.csv'.format(sample_id))        utils.compile_glacier_statistics(gdirs, path=opath_g)#%%members=[1, 3,4,6,1]models = ["IPSL-CM6","E3SM","CESM2","CNRM", "W5E5"]timeframe = "monthly"for m, model in enumerate(models):    for i in range(members[m]):        # Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)        sample_id= f"{model}.00{i}" #provide label for all run output        print(sample_id)        gdirs = workflow.init_glacier_directories(rgi_ids)        base_folder_in = f"/Users/magaliponds/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/1. VUB/02. Coding/01. IRRMIP/03. Data/03. Output files/01. Climate data/05. OGGM Climate input files/{timeframe}/{model}/{member}"        cfg.PATHS['climate_file'] = f"{base_folder_in}/{model}.00{member}.1985_2014.{timeframe}.perturbed.climate.input.degC.nc"                workflow.execute_entity_task(tasks.process_custom_climate_data, gdirs, output_filesuffix=f'_{sample_id}') #process climate data for all gdirs        workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                                       ys=y0_clim, ye=ye_clim,                                       # min_ys=y0_clim, max_ys=ye_clim,                                       # init_model_yr=1985.01,                                      # init_model_filesuffix='_dynamic_spinup_W5E5.000',                                      climate_filename='climate_historical',                                      climate_input_filesuffix='_{}'.format(sample_id),                                      fixed_geometry_spinup_yr=None,                                      store_model_geometry=None,                                      # use_inversion_flowlines=True,                                      # init_model_filesuffix=None,                                       # init_model_fls="model_flowlines_dyn_melt_f_calib.pkl",                                      temperature_bias=None, precipitation_factor=None,                                      mb_model=None, #mb_model_class=<class 'oggm.core.massbalance.MonthlyTIModel'>,                                      output_filesuffix='_{}_output_climate_run'.format(sample_id),                                      mb_elev_feedback='monthly',                                      store_monthly_step=True                                      )                opath = os.path.join(sum_dir,'climate_run_output_{}.nc'.format(sample_id))        utils.compile_run_output(gdirs, path=opath,input_filesuffix='_{}_output_climate_run'.format(sample_id))                        # compile_statistics(sample_id, sum_dir)                workflow.execute_entity_task(tasks.fixed_geometry_mass_balance, gdirs,                                              # use_inversion_flowlines=False,                                             ys=y0_clim, ye=ye_clim,                                              monthly_step=False, #not available yet                                             climate_filename='climate_historical',                                             climate_input_filesuffix='_{}'.format(sample_id))                data = []        for gdir in gdirs:            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)                        # Compute the specific MB for this glacier            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib')            years = np.arange(1985, 2015)            mb_ts = mbmod.get_specific_mb(fls=fls, year=years)                        # Append the data to the list            for year, mb in zip(years, mb_ts):                data.append({                    'Glacier': gdir.rgi_id,                    'Year': year,                    'Mass Balance': mb                })                # Create a DataFrame from the list        df = pd.DataFrame(data)                    opath = os.path.join(os.path.join(sum_dir,'specific_mb_{}.csv'.format(sample_id)))        df.to_csv(opath)            # plt.plot(years, mb_ts);            # plt.ylabel('Specific MB (mm w.e.)');            # plt.xlabel('Year');                opath_mb = os.path.join(sum_dir, 'compiled_mass_balance_output_{}.nc'.format(sample_id))        utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_mb, climate_filename='climate_historical',                                                  ys=y0_clim, ye=ye_clim,                                                   climate_input_filesuffix='_{}'.format(sample_id)                                                   # ys=y0_clim, ye=ye_clim,                                                  # use_inversion_flowlines=False                                                  )                # opath_g = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))        # utils.compile_glacier_statistics(gdirs, path=opath_g)        # opath_c = os.path.join(sum_dir, 'climate_statistics_{}.csv'.format(sample_id))        # utils.compile_climate_statistics(gdirs, path=opath_c)        # opath_b = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))        # utils.compile_fixed_geometry_mass_balance(gdirs, path=opath_b,         #                                           climate_filename='climate_historical',        #                                           climate_input_filesuffix='_{}'.format(sample_id))                        # Add the extended files        # pf = os.path.join(sum_dir, 'climate_run_output_{}.nc'.format(sample_id))        # # We have copied the files above        # mf = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}.csv'.format(sample_id))        # sf = os.path.join(sum_dir, 'glacier_statistics_{}.csv'.format(sample_id))        # mf_data = pd.read_csv(mf)        # # mf_data = mf_data.rename({'Unnamed: 0': "time"})        # mf_data = mf_data.query('1985 <= `Unnamed: 0` < 2015')        # mf_shortened = os.path.join(sum_dir, 'fixed_geometry_mass_balance_{}_shortened.csv'.format(sample_id))        # mf_data.to_csv(mf_shortened)                        # opath = os.path.join(sum_dir, 'historical_run_output_extended_{}.nc'.format(sample_id))                # utils.extend_past_climate_run(past_run_file=pf,        #                               fixed_geometry_mb_file=mf_shortened,        #                               glacier_statistics_file=sf,        #                               path=opath)                        #uncomment the below if hydrological output is preferred                # workflow.execute_entity_task(tasks.run_with_hydro, gdirs,        #                               run_task=tasks.run_from_climate_data,         #                               store_monthly_hydro=True,        #                               ys=y0_clim, ye=ye_clim,         #                               init_model_yr=y0_clim,        #                               climate_filename='climate_historical',        #                               climate_input_filesuffix='_{}'.format(sample_id),        #                               output_filesuffix='_{}_output_climate_run_whydro'.format(sample_id),        #                               mb_elev_feedback='annual',        #                               store_monthly_step=False        #                               )                #obtain mass balance data, using the historical climate                        # Generate and compile the statistics                            if m ==0:             opath = os.path.join(sum_dir, f'climate_run_test.nc')            opath_test = os.path.join(sum_dir, f'fixed_geometry_mass_balance_climate_test.csv')            # utils.compile_run_output(gdirs, path=opath, input_filesuffix="test")            utils.compile_fixed_geometry_mass_balance(gdirs,path=opath_test, climate_filename='climate_historical',                                                      climate_input_filesuffix='')            statistics_path = os.path.join(sum_dir, f'climate_run_glacier_statistics_test.csv')            utils.compile_glacier_statistics(gdirs, path=statistics_path)            # compile_statistics("test", sum_dir)#%%for ds in [pf]:    data = xr.open_dataset(ds).time    print(ds, data)    for ds in [mf_shortened,sf]:    data = pd.read_csv(ds)    if ds==mf_shortened:        data = data['Unnamed: 0']        print(ds, data)                #%%for gd in gdirs:    for m, model in enumerate(models):        for i in range(members[m]):                          print(model, i)              params = gd.read_json('mb_calib')              print("melt_f: ", params['melt_f'])              print("temp_bias: ", params['temp_bias'])              print("prcp_fac: ", params['prcp_fac'])#%% derive mass balacne for the different climate filesfor (i, gdir) in enumerate(gdirs):    plt.figure()    for m, model in enumerate(models):        for i in range(members[m]):            #Create a sample-id tag to list model restuls                        sample_id= f"{model}.00{i}" #provide label for all run output                        #initiate the model with custom climate data (model-member combination)            initiate_OGGM(timeframe, model, i, reset, wd_path)             gdirs = workflow.init_glacier_directories(rgi_ids)                        mbdf = utils.get_geodetic_mb_dataframe()            mb = pd.DataFrame({'years': years})            mb['years'] = pd.to_datetime(mb['years'], format='%Y')                                            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)             # First check the parameters used for running the flmod model per flowline            # for flmod in mbmod.flowline_mb_models:                # print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')                            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl            # fls=xr.open_dataset(os.path.join(wd_path, "per_glacier", rgi_id[:-6], rgi_id[:-3],rgi_id, "fl_diagnostics_CESM2.002_output_climate_run.nc"))            B = mbmod.get_specific_mb(fls=fls, year=years)            mb['B'] = B            plt.plot(mb.years, mb.B)                                                                                       #%% Cell 8a: Plot historical run output extended for all modelsmembers=[1,3,4,6,1]models = "W5E5","E3SM","CESM2","CNRM","IPSL-CM6"for r, rgi_id in enumerate(rgi_ids):    plt.figure()    for m, model in enumerate(models):        for i in range(members[m]):            #Create a sample-id tag to list model restuls            sample_id= f"{model}.00{i}" #p            # Why no valid volume file??             opath = os.path.join(sum_dir, f'fixed_geometry_mass_balance_climate_{sample_id}.csv')            pd.read_csv(opath)            ds_diag_ext = pd.read_csv(opath)            ds_diag_ext = xr.Dataset.from_dataframe(ds_diag_ext)            ds_diag_ext=ds_diag_ext[rgi_id]            # ds_diag_ext = xr.open_dataset(opath).sel(rgi_id=rgi_id)            # print(ds_diag_ext.data_vars)                            # print(ds_diag_ext.data_vars)            ds_diag_ext.plot(label=sample_id)            plt.legend(loc='upper left', ncols=2)                        # plt.title(f'Volume evolution {sample_id}');            # plt.xticks(rotation=90)            # # plt.show()#%% path = os.path.join(wd_path, 'per_glacier', 'RGI60-13', 'RGI60-13.41', 'RGI60-13.41891', 'climate_run_CNRM.000_output_climate_run.nc')ds = xr.open_dataset(path)ds.data_vars#%%path = os.path.join(sum_dir, 'climate_run_CNRM.000.nc')ds = xr.open_dataset(path)ds.data_varsplotds=ds.where(ds.rgi_id=="RGI60-13.23659")plt.plot(plotds.time, plotds.volume)#%% Cell11b: Plot flowlines# for (i,gdir) in enumerate(gdirs):#     gfig, axs = plt.subplots()#     fls = gdir.read_pickle('model_flowlines')#     graphics.plot_modeloutput_section(fls, ax=axs)    # fig, axs = plt.subplots(3, 3, figsize=(15, 10))# for i, gdir in enumerate(gdirs):#     # Determine the position of the subplot (i.e., row and column)#     row = i // 3#     col = i % 3    #     # Get the specific axis for the subplot#     ax = axs[row, col]    #     # Read the pickle file and plot#     fls = gdir.read_pickle('model_flowlines')#     fls2 = gdir.read_pickle('model_flowlines_dyn_melt_f_calib')#     graphics.plot_modeloutput_section(fls, ax=ax)#     # ax.set_title(gdir.rgi_id)# # Adjust layout to prevent overlapping# # plt.tight_layout()# # Show the combined plot# plt.show()    #%%  Cell 12: Plot MB comparisoncfg.add_to_basenames('model_flowlines_dyn_melt_f_calib.pkl', 'model_flowlines.pkl', 'Adding the dynamic melt calibration flowlines')cfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(3,3, figsize=(20, 12), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):            mbmod = massbalance.MultipleFlowlineMassBalance(gdir)     # First check the parameters used for running the flmod model per flowline    for flmod in mbmod.flowline_mb_models:        print(gdir.rgi_id, ' - melt_f:', flmod.melt_f, ', temp bias:', f'{flmod.temp_bias:.2f}', ', prcp factor:', f'{flmod.prcp_fac:.2f}')            fls = gdir.read_pickle('model_flowlines_dyn_melt_f_calib.pkl') #model_flowlines_dyn_melt_f_calib.pkl    B = mbmod.get_specific_mb(fls=fls, year=years)    mb['B'] = B        # Load & plot Hugonnet data for 2000-2010    mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]    mean_mb_2010_2020 = mb_2010_2020['B'].mean()    sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000       # Load & plot Hugonnet data for 2000-2010    _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]    axes_mb[i].fill_between([2000, 2020], [_mb-_err, _mb-_err], [_mb+_err, _mb+_err], alpha=0.5, color='C0')    axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2010')        # Plot (mean) modelled data     axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')    # axes_mb[i].plot([2010, 2020], [mean_mb_2020, mean_mb_2020], color='C1', linestyle='dashed', label='OGGM modelled mean 2010-2020')    axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs    axes_mb[i].set_title(gdir.rgi_id, fontsize=20)    axes_mb[i].annotate(panels[i],xy=(0.98, 0.98), xycoords='axes fraction',                                    fontsize=24, weight='medium', ha='right', va='top')#,                                    #bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white'))    # axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        if i % 3 == 0:  # Only set ylabel on the left column        axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)    axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=3)plt.show()#%%  Cell 12a: Plot MB comparison - zoom in to 2 glaciers with changes before and after dynamic spinupcfg.PARAMS['store_model_geometry']=Truembdf = utils.get_geodetic_mb_dataframe()years = np.arange(1985, 2020) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_mb, axes_mb = plt.subplots(1,2, figsize=(10, 3), sharex=True)axes_mb = axes_mb.flatten()  # Flatten the 2D array of axes to simplify indexingchanged_ids = ['RGI60-13.00967', 'RGI60-13.40982']changed_gdirs = [gdir for gdir in gdirs if gdir.rgi_id in changed_ids]for (i, gdir) in enumerate(changed_gdirs):    # for j, model_type in enumerate(['model_flowlines', 'model_flowlines_dyn_melt_f_calib']):        mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         fls = gdir.read_pickle('model_flowlines')         B = mbmod.get_specific_mb(fls=fls, year=years)        mb['B'] = B                # Load & plot Hugonnet data for 2000-2010        mb_2010_2020 = mb[(mb['years'] >= '2000-01-01') & (mb['years'] < '2020-01-01')]        mean_mb_2010_2020 = mb_2010_2020['B'].mean()        sel = mbdf.loc[gdir.rgi_id].set_index('period') * 1000                # Load & plot Hugonnet data for 2000-2020        _mb, _err = sel.loc['2000-01-01_2020-01-01'][['dmdtda', 'err_dmdtda']]        axes_mb[i].fill_between([2000, 2020], [_mb - _err, _mb - _err], [_mb + _err, _mb + _err], alpha=0.5, color='C0')        axes_mb[i].plot([2000, 2020], [_mb, _mb], color='C0', label='Hugonnet 2000-2020')        # Plot (mean) modelled data        axes_mb[i].plot([2000, 2020], [mean_mb_2010_2020, mean_mb_2010_2020], color='k', linestyle='dashed', label='OGGM modelled mean 2000-2020')        axes_mb[i].plot(years, mb.B, c='k', label='OGGM Modelled')        # Format graphs        axes_mb[i].set_title(f"{gdir.rgi_id} ", fontsize=20)        if (i) % 2 == 0:  # Only set ylabel on the left column            axes_mb[i].set_ylabel('B [mm w.e.]', fontsize=16)        axes_mb[i].tick_params(axis='both', which='major', labelsize=16) plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.1, -0.3), ncols=3)plt.show()#%%  Cell 12b: PlotFlowlines in 9x9 subplotcfg.PARAMS['store_model_geometry']=Truepanels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']mbdf = utils.get_geodetic_mb_dataframe()years = np.arange(2010, 2015) mb = pd.DataFrame({'years': years})mb['years'] = pd.to_datetime(mb['years'], format='%Y')fig_fls, axes_fls = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_fls = axes_fls.flatten()  # Flatten the 2D array of axes to simplify indexingfor (i, gdir) in enumerate(gdirs):    for j in years:                mbmod = massbalance.MultipleFlowlineMassBalance(gdir)         # First check the parameters used for running the flmod model per flowline                    fls = gdir.read_pickle('model_flowlines')         heights, widths, mb = mbmod.get_annual_mb_on_flowlines(fls, year=j)        # units kg ice per second to mm w.e. per year:        mb = mb * cfg.SEC_IN_YEAR * cfg.PARAMS['ice_density']                 # Plot        axes_fls[i].plot(mb, heights, '-', label=j);                            if i==3:        axes_fls[i].set_ylabel('Elevation (m a.s.l.)'); plt.xlabel('MB (mm w.e. yr$^{-1}$)'); plt.legend();plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)plt.legend(loc='lower center', bbox_to_anchor=(-0.75, -0.5), ncols=10)plt.show()#%% Cell 13: Run model for glacier statistics# We want to use these flowline files for the AAR (see later)cfg.PARAMS['store_fl_diagnostics'] = True# Run from outline inventory year (2003 for HEF) to 2017 (end of CRU data in hydro year convention, see below)workflow.execute_entity_task(tasks.run_from_climate_data, gdirs,                             ys=ys, ye=ye, #store_monthly_step=store_monthly_step,                             climate_filename='climate_historical',                             climate_input_filesuffix='_{}_processed_output'.format(sample_id),                             output_filesuffix='_{}_output_run_after_spinup'.format(sample_id),                             mb_elev_feedback='monthly',                             store_monthly_step=True                             )#%% cell 13a: Plot volume evolution of the glaciers# add_to_basenames('model_diagnostics_W5E5_spinup_historical.nc', #basename#                   'model_diagnostics.nc') #filename) #docstr=''                 fig_vol, axes_vol = plt.subplots(3,3, figsize=(20, 12), sharex=True, sharey=True)axes_vol = axes_vol.flatten() for (i,gdir) in enumerate(gdirs):    ds_diag = xr.open_dataset(gdir.get_filepath('model_diagnostics'))    axes_vol[i].plot(ds_diag.calendar_year,ds_diag.volume_m3); axes_vol[i].set_title(f'{gdir.rgi_id}');    if i==3:        axes_vol[i].set_ylabel('Volume [m$^3$]')